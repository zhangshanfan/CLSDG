{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e7267b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-08T11:50:09.914419Z",
     "start_time": "2022-05-08T11:50:08.150854Z"
    }
   },
   "outputs": [],
   "source": [
    "import settings\n",
    "from link_prediction import Link_pred_Runner\n",
    "dataname = 'email'       # 'wiki' or 'email' or 'cora' or 'citeseer'\n",
    "model = 'arga_vae'     # 'arga_ae' or 'arga_vae'\n",
    "task = 'link_prediction'         # 'clustering' or 'link_prediction'\n",
    "settings = settings.get_settings(dataname, model, task)\n",
    "runner = Link_pred_Runner(settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a0fa53c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-08T11:50:44.729061Z",
     "start_time": "2022-05-08T11:50:10.945653Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\zhangshanfan\\Desktop\\对比方法\\ARGA-master\\ARGA\\arga\\model.py:143: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\zhangshanfan\\Desktop\\对比方法\\ARGA-master\\ARGA\\arga\\model.py:145: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\zhangshanfan\\Desktop\\对比方法\\ARGA-master\\ARGA\\arga\\model.py:147: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\zhangshanfan\\Desktop\\对比方法\\ARGA-master\\ARGA\\arga\\layers.py:27: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\zhangshanfan\\Desktop\\对比方法\\ARGA-master\\ARGA\\arga\\layers.py:101: The name tf.sparse_tensor_dense_matmul is deprecated. Please use tf.sparse.sparse_dense_matmul instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\zhangshanfan\\Desktop\\对比方法\\ARGA-master\\ARGA\\arga\\layers.py:79: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\zhangshanfan\\Desktop\\对比方法\\ARGA-master\\ARGA\\arga\\model.py:126: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\zhangshanfan\\Desktop\\对比方法\\ARGA-master\\ARGA\\arga\\constructor.py:94: The name tf.sparse_tensor_to_dense is deprecated. Please use tf.sparse.to_dense instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\zhangshanfan\\.conda\\envs\\tf1.x\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\zhangshanfan\\Desktop\\对比方法\\ARGA-master\\ARGA\\arga\\optimizer.py:67: calling weighted_cross_entropy_with_logits (from tensorflow.python.ops.nn_impl) with targets is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "targets is deprecated, use labels instead\n",
      "WARNING:tensorflow:From C:\\Users\\zhangshanfan\\Desktop\\对比方法\\ARGA-master\\ARGA\\arga\\optimizer.py:68: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\zhangshanfan\\Desktop\\对比方法\\ARGA-master\\ARGA\\arga\\optimizer.py:70: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\zhangshanfan\\Desktop\\对比方法\\ARGA-master\\ARGA\\arga\\optimizer.py:75: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n",
      "\n",
      "Epoch: 0001 train_loss= 2.26280 val_roc= 0.65086 val_ap= 0.61959\n",
      "Epoch: 0002 train_loss= 2.27839 val_roc= 0.65355 val_ap= 0.62576\n",
      "Epoch: 0003 train_loss= 2.34289 val_roc= 0.67036 val_ap= 0.63973\n",
      "Epoch: 0004 train_loss= 2.33758 val_roc= 0.69299 val_ap= 0.66059\n",
      "Epoch: 0005 train_loss= 2.27632 val_roc= 0.71624 val_ap= 0.68129\n",
      "Epoch: 0006 train_loss= 2.32002 val_roc= 0.73792 val_ap= 0.70020\n",
      "Epoch: 0007 train_loss= 2.33294 val_roc= 0.75363 val_ap= 0.71429\n",
      "Epoch: 0008 train_loss= 2.28064 val_roc= 0.76425 val_ap= 0.72525\n",
      "Epoch: 0009 train_loss= 2.33606 val_roc= 0.77144 val_ap= 0.72878\n",
      "Epoch: 0010 train_loss= 2.17885 val_roc= 0.77636 val_ap= 0.73462\n",
      "Test AP score: 0.7624711511178204\n",
      "Test ROC score: 0.7782257385741941\n",
      "Epoch: 0011 train_loss= 2.26323 val_roc= 0.77970 val_ap= 0.73854\n",
      "Epoch: 0012 train_loss= 2.20862 val_roc= 0.78207 val_ap= 0.74230\n",
      "Epoch: 0013 train_loss= 2.16697 val_roc= 0.78370 val_ap= 0.74389\n",
      "Epoch: 0014 train_loss= 2.19509 val_roc= 0.78432 val_ap= 0.74417\n",
      "Epoch: 0015 train_loss= 2.21779 val_roc= 0.78518 val_ap= 0.74499\n",
      "Epoch: 0016 train_loss= 2.16280 val_roc= 0.78541 val_ap= 0.74516\n",
      "Epoch: 0017 train_loss= 2.11226 val_roc= 0.78518 val_ap= 0.74499\n",
      "Epoch: 0018 train_loss= 2.09100 val_roc= 0.78532 val_ap= 0.74607\n",
      "Epoch: 0019 train_loss= 2.07179 val_roc= 0.78470 val_ap= 0.74586\n",
      "Epoch: 0020 train_loss= 2.08640 val_roc= 0.78426 val_ap= 0.74556\n",
      "Test AP score: 0.7827250991000867\n",
      "Test ROC score: 0.79117751031058\n",
      "Epoch: 0021 train_loss= 2.00367 val_roc= 0.78401 val_ap= 0.74538\n",
      "Epoch: 0022 train_loss= 2.04844 val_roc= 0.78376 val_ap= 0.74556\n",
      "Epoch: 0023 train_loss= 2.00066 val_roc= 0.78324 val_ap= 0.74513\n",
      "Epoch: 0024 train_loss= 1.98684 val_roc= 0.78275 val_ap= 0.74457\n",
      "Epoch: 0025 train_loss= 1.92264 val_roc= 0.78212 val_ap= 0.74382\n",
      "Epoch: 0026 train_loss= 1.89858 val_roc= 0.78156 val_ap= 0.74370\n",
      "Epoch: 0027 train_loss= 1.83612 val_roc= 0.78148 val_ap= 0.74384\n",
      "Epoch: 0028 train_loss= 1.84689 val_roc= 0.78113 val_ap= 0.74380\n",
      "Epoch: 0029 train_loss= 1.81881 val_roc= 0.78016 val_ap= 0.74304\n",
      "Epoch: 0030 train_loss= 1.78264 val_roc= 0.77953 val_ap= 0.74332\n",
      "Test AP score: 0.7822074130745116\n",
      "Test ROC score: 0.7873933170608535\n",
      "Epoch: 0031 train_loss= 1.75019 val_roc= 0.77925 val_ap= 0.74268\n",
      "Epoch: 0032 train_loss= 1.71155 val_roc= 0.77870 val_ap= 0.74244\n",
      "Epoch: 0033 train_loss= 1.69416 val_roc= 0.77807 val_ap= 0.74224\n",
      "Epoch: 0034 train_loss= 1.66551 val_roc= 0.77748 val_ap= 0.74229\n",
      "Epoch: 0035 train_loss= 1.65133 val_roc= 0.77672 val_ap= 0.74199\n",
      "Epoch: 0036 train_loss= 1.62288 val_roc= 0.77613 val_ap= 0.74172\n",
      "Epoch: 0037 train_loss= 1.57273 val_roc= 0.77526 val_ap= 0.74134\n",
      "Epoch: 0038 train_loss= 1.56501 val_roc= 0.77494 val_ap= 0.74140\n",
      "Epoch: 0039 train_loss= 1.53891 val_roc= 0.77423 val_ap= 0.74113\n",
      "Epoch: 0040 train_loss= 1.55497 val_roc= 0.77348 val_ap= 0.74085\n",
      "Test AP score: 0.7824482186511805\n",
      "Test ROC score: 0.784474370844205\n",
      "Epoch: 0041 train_loss= 1.50841 val_roc= 0.77314 val_ap= 0.74095\n",
      "Epoch: 0042 train_loss= 1.48409 val_roc= 0.77269 val_ap= 0.74094\n",
      "Epoch: 0043 train_loss= 1.45421 val_roc= 0.77234 val_ap= 0.74102\n",
      "Epoch: 0044 train_loss= 1.41660 val_roc= 0.77228 val_ap= 0.74111\n",
      "Epoch: 0045 train_loss= 1.43330 val_roc= 0.77176 val_ap= 0.74104\n",
      "Epoch: 0046 train_loss= 1.39075 val_roc= 0.77190 val_ap= 0.74130\n",
      "Epoch: 0047 train_loss= 1.40326 val_roc= 0.77179 val_ap= 0.74182\n",
      "Epoch: 0048 train_loss= 1.39171 val_roc= 0.77179 val_ap= 0.74238\n",
      "Epoch: 0049 train_loss= 1.33933 val_roc= 0.77167 val_ap= 0.74285\n",
      "Epoch: 0050 train_loss= 1.34965 val_roc= 0.77179 val_ap= 0.74337\n",
      "Test AP score: 0.7844924862232888\n",
      "Test ROC score: 0.7842050332463597\n",
      "Epoch: 0051 train_loss= 1.30417 val_roc= 0.77195 val_ap= 0.74384\n",
      "Epoch: 0052 train_loss= 1.29214 val_roc= 0.77205 val_ap= 0.74416\n",
      "Epoch: 0053 train_loss= 1.26081 val_roc= 0.77214 val_ap= 0.74428\n",
      "Epoch: 0054 train_loss= 1.27115 val_roc= 0.77222 val_ap= 0.74473\n",
      "Epoch: 0055 train_loss= 1.26098 val_roc= 0.77256 val_ap= 0.74499\n",
      "Epoch: 0056 train_loss= 1.27131 val_roc= 0.77283 val_ap= 0.74531\n",
      "Epoch: 0057 train_loss= 1.23419 val_roc= 0.77298 val_ap= 0.74557\n",
      "Epoch: 0058 train_loss= 1.19942 val_roc= 0.77298 val_ap= 0.74554\n",
      "Epoch: 0059 train_loss= 1.21565 val_roc= 0.77295 val_ap= 0.74532\n",
      "Epoch: 0060 train_loss= 1.20091 val_roc= 0.77305 val_ap= 0.74537\n",
      "Test AP score: 0.7872024453321905\n",
      "Test ROC score: 0.7855921218752631\n",
      "Epoch: 0061 train_loss= 1.18409 val_roc= 0.77309 val_ap= 0.74538\n",
      "Epoch: 0062 train_loss= 1.17887 val_roc= 0.77317 val_ap= 0.74581\n",
      "Epoch: 0063 train_loss= 1.16263 val_roc= 0.77355 val_ap= 0.74578\n",
      "Epoch: 0064 train_loss= 1.14934 val_roc= 0.77375 val_ap= 0.74592\n",
      "Epoch: 0065 train_loss= 1.14701 val_roc= 0.77394 val_ap= 0.74598\n",
      "Epoch: 0066 train_loss= 1.14897 val_roc= 0.77402 val_ap= 0.74609\n",
      "Epoch: 0067 train_loss= 1.12118 val_roc= 0.77405 val_ap= 0.74662\n",
      "Epoch: 0068 train_loss= 1.11979 val_roc= 0.77414 val_ap= 0.74715\n",
      "Epoch: 0069 train_loss= 1.12379 val_roc= 0.77425 val_ap= 0.74721\n",
      "Epoch: 0070 train_loss= 1.12631 val_roc= 0.77446 val_ap= 0.74734\n",
      "Test AP score: 0.791404293012796\n",
      "Test ROC score: 0.7896254524029964\n",
      "Epoch: 0071 train_loss= 1.08071 val_roc= 0.77492 val_ap= 0.74818\n",
      "Epoch: 0072 train_loss= 1.09348 val_roc= 0.77551 val_ap= 0.74802\n",
      "Epoch: 0073 train_loss= 1.06205 val_roc= 0.77615 val_ap= 0.74882\n",
      "Epoch: 0074 train_loss= 1.05280 val_roc= 0.77690 val_ap= 0.74934\n",
      "Epoch: 0075 train_loss= 1.06155 val_roc= 0.77740 val_ap= 0.75018\n",
      "Epoch: 0076 train_loss= 1.06721 val_roc= 0.77834 val_ap= 0.75114\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0077 train_loss= 1.04242 val_roc= 0.77878 val_ap= 0.75183\n",
      "Epoch: 0078 train_loss= 1.02024 val_roc= 0.77945 val_ap= 0.75244\n",
      "Epoch: 0079 train_loss= 1.01836 val_roc= 0.77991 val_ap= 0.75191\n",
      "Epoch: 0080 train_loss= 1.01149 val_roc= 0.78045 val_ap= 0.75193\n",
      "Test AP score: 0.7978815168290891\n",
      "Test ROC score: 0.7955475128356199\n",
      "Epoch: 0081 train_loss= 1.00206 val_roc= 0.78098 val_ap= 0.75276\n",
      "Epoch: 0082 train_loss= 0.99987 val_roc= 0.78126 val_ap= 0.75337\n",
      "Epoch: 0083 train_loss= 0.99087 val_roc= 0.78122 val_ap= 0.75401\n",
      "Epoch: 0084 train_loss= 0.99314 val_roc= 0.78147 val_ap= 0.75448\n",
      "Epoch: 0085 train_loss= 0.97077 val_roc= 0.78214 val_ap= 0.75570\n",
      "Epoch: 0086 train_loss= 0.97370 val_roc= 0.78255 val_ap= 0.75666\n",
      "Epoch: 0087 train_loss= 0.97319 val_roc= 0.78318 val_ap= 0.75839\n",
      "Epoch: 0088 train_loss= 0.95807 val_roc= 0.78409 val_ap= 0.75946\n",
      "Epoch: 0089 train_loss= 0.95054 val_roc= 0.78405 val_ap= 0.76200\n",
      "Epoch: 0090 train_loss= 0.93337 val_roc= 0.78367 val_ap= 0.76285\n",
      "Test AP score: 0.8003695405823628\n",
      "Test ROC score: 0.7965137614678899\n",
      "Epoch: 0091 train_loss= 0.93972 val_roc= 0.78325 val_ap= 0.76346\n",
      "Epoch: 0092 train_loss= 0.93851 val_roc= 0.78244 val_ap= 0.76290\n",
      "Epoch: 0093 train_loss= 0.93166 val_roc= 0.78141 val_ap= 0.76222\n",
      "Epoch: 0094 train_loss= 0.91296 val_roc= 0.78083 val_ap= 0.76224\n",
      "Epoch: 0095 train_loss= 0.90659 val_roc= 0.78020 val_ap= 0.76193\n",
      "Epoch: 0096 train_loss= 0.90000 val_roc= 0.77974 val_ap= 0.76140\n",
      "Epoch: 0097 train_loss= 0.88693 val_roc= 0.77910 val_ap= 0.76113\n",
      "Epoch: 0098 train_loss= 0.90607 val_roc= 0.77944 val_ap= 0.76143\n",
      "Epoch: 0099 train_loss= 0.89127 val_roc= 0.77957 val_ap= 0.76105\n",
      "Epoch: 0100 train_loss= 0.88575 val_roc= 0.78055 val_ap= 0.76276\n",
      "Test AP score: 0.7907311565064528\n",
      "Test ROC score: 0.789965491120276\n",
      "Epoch: 0101 train_loss= 0.88086 val_roc= 0.78172 val_ap= 0.76302\n",
      "Epoch: 0102 train_loss= 0.89303 val_roc= 0.78313 val_ap= 0.76400\n",
      "Epoch: 0103 train_loss= 0.87059 val_roc= 0.78371 val_ap= 0.76403\n",
      "Epoch: 0104 train_loss= 0.86195 val_roc= 0.78372 val_ap= 0.76383\n",
      "Epoch: 0105 train_loss= 0.86990 val_roc= 0.78372 val_ap= 0.76368\n",
      "Epoch: 0106 train_loss= 0.86014 val_roc= 0.78293 val_ap= 0.76324\n",
      "Epoch: 0107 train_loss= 0.85087 val_roc= 0.78120 val_ap= 0.76204\n",
      "Epoch: 0108 train_loss= 0.85299 val_roc= 0.77999 val_ap= 0.76164\n",
      "Epoch: 0109 train_loss= 0.84610 val_roc= 0.77894 val_ap= 0.76141\n",
      "Epoch: 0110 train_loss= 0.84314 val_roc= 0.77776 val_ap= 0.76047\n",
      "Test AP score: 0.7823471282373653\n",
      "Test ROC score: 0.7856089554751284\n",
      "Epoch: 0111 train_loss= 0.83519 val_roc= 0.77680 val_ap= 0.75974\n",
      "Epoch: 0112 train_loss= 0.83297 val_roc= 0.77579 val_ap= 0.75932\n",
      "Epoch: 0113 train_loss= 0.83186 val_roc= 0.77480 val_ap= 0.75890\n",
      "Epoch: 0114 train_loss= 0.81976 val_roc= 0.77341 val_ap= 0.75750\n",
      "Epoch: 0115 train_loss= 0.82014 val_roc= 0.77096 val_ap= 0.75646\n",
      "Epoch: 0116 train_loss= 0.82172 val_roc= 0.76768 val_ap= 0.75434\n",
      "Epoch: 0117 train_loss= 0.81361 val_roc= 0.76495 val_ap= 0.75291\n",
      "Epoch: 0118 train_loss= 0.81343 val_roc= 0.76296 val_ap= 0.75166\n",
      "Epoch: 0119 train_loss= 0.81618 val_roc= 0.76061 val_ap= 0.75012\n",
      "Epoch: 0120 train_loss= 0.81683 val_roc= 0.75841 val_ap= 0.74943\n",
      "Test AP score: 0.7683714034162354\n",
      "Test ROC score: 0.7654423028364614\n",
      "Epoch: 0121 train_loss= 0.80944 val_roc= 0.75708 val_ap= 0.74844\n",
      "Epoch: 0122 train_loss= 0.80540 val_roc= 0.75558 val_ap= 0.74820\n",
      "Epoch: 0123 train_loss= 0.80691 val_roc= 0.75327 val_ap= 0.74683\n",
      "Epoch: 0124 train_loss= 0.79346 val_roc= 0.75192 val_ap= 0.74541\n",
      "Epoch: 0125 train_loss= 0.79923 val_roc= 0.75057 val_ap= 0.74498\n",
      "Epoch: 0126 train_loss= 0.80003 val_roc= 0.74912 val_ap= 0.74413\n",
      "Epoch: 0127 train_loss= 0.78958 val_roc= 0.74831 val_ap= 0.74297\n",
      "Epoch: 0128 train_loss= 0.78738 val_roc= 0.74757 val_ap= 0.74238\n",
      "Epoch: 0129 train_loss= 0.79017 val_roc= 0.74713 val_ap= 0.74262\n",
      "Epoch: 0130 train_loss= 0.77899 val_roc= 0.74724 val_ap= 0.74282\n",
      "Test AP score: 0.7595092092872134\n",
      "Test ROC score: 0.7497803215217574\n",
      "Epoch: 0131 train_loss= 0.78935 val_roc= 0.74738 val_ap= 0.74317\n",
      "Epoch: 0132 train_loss= 0.78600 val_roc= 0.74701 val_ap= 0.74320\n",
      "Epoch: 0133 train_loss= 0.77966 val_roc= 0.74689 val_ap= 0.74334\n",
      "Epoch: 0134 train_loss= 0.78598 val_roc= 0.74689 val_ap= 0.74321\n",
      "Epoch: 0135 train_loss= 0.78837 val_roc= 0.74693 val_ap= 0.74306\n",
      "Epoch: 0136 train_loss= 0.78144 val_roc= 0.74705 val_ap= 0.74271\n",
      "Epoch: 0137 train_loss= 0.78144 val_roc= 0.74727 val_ap= 0.74220\n",
      "Epoch: 0138 train_loss= 0.78088 val_roc= 0.74774 val_ap= 0.74209\n",
      "Epoch: 0139 train_loss= 0.77353 val_roc= 0.74755 val_ap= 0.74255\n",
      "Epoch: 0140 train_loss= 0.77782 val_roc= 0.74751 val_ap= 0.74271\n",
      "Test AP score: 0.7601919066603384\n",
      "Test ROC score: 0.7486188031310497\n",
      "Epoch: 0141 train_loss= 0.77983 val_roc= 0.74770 val_ap= 0.74287\n",
      "Epoch: 0142 train_loss= 0.78254 val_roc= 0.74749 val_ap= 0.74179\n",
      "Epoch: 0143 train_loss= 0.78153 val_roc= 0.74796 val_ap= 0.74206\n",
      "Epoch: 0144 train_loss= 0.78064 val_roc= 0.74778 val_ap= 0.74157\n",
      "Epoch: 0145 train_loss= 0.77895 val_roc= 0.74822 val_ap= 0.74159\n",
      "Epoch: 0146 train_loss= 0.78182 val_roc= 0.74828 val_ap= 0.74247\n",
      "Epoch: 0147 train_loss= 0.78075 val_roc= 0.74804 val_ap= 0.74221\n",
      "Epoch: 0148 train_loss= 0.77972 val_roc= 0.74859 val_ap= 0.74243\n",
      "Epoch: 0149 train_loss= 0.77085 val_roc= 0.74900 val_ap= 0.74261\n",
      "Epoch: 0150 train_loss= 0.77079 val_roc= 0.74895 val_ap= 0.74199\n",
      "Test AP score: 0.7641914100789541\n",
      "Test ROC score: 0.7507634037538928\n",
      "Epoch: 0151 train_loss= 0.77101 val_roc= 0.74901 val_ap= 0.74154\n",
      "Epoch: 0152 train_loss= 0.77190 val_roc= 0.74907 val_ap= 0.74170\n",
      "Epoch: 0153 train_loss= 0.77211 val_roc= 0.74946 val_ap= 0.74225\n",
      "Epoch: 0154 train_loss= 0.77529 val_roc= 0.74951 val_ap= 0.74311\n",
      "Epoch: 0155 train_loss= 0.77768 val_roc= 0.74939 val_ap= 0.74377\n",
      "Epoch: 0156 train_loss= 0.76841 val_roc= 0.74950 val_ap= 0.74390\n",
      "Epoch: 0157 train_loss= 0.76815 val_roc= 0.74988 val_ap= 0.74396\n",
      "Epoch: 0158 train_loss= 0.77380 val_roc= 0.75026 val_ap= 0.74430\n",
      "Epoch: 0159 train_loss= 0.77603 val_roc= 0.75027 val_ap= 0.74442\n",
      "Epoch: 0160 train_loss= 0.77474 val_roc= 0.75059 val_ap= 0.74484\n",
      "Test AP score: 0.7671220586645157\n",
      "Test ROC score: 0.7522649608618803\n",
      "Epoch: 0161 train_loss= 0.77154 val_roc= 0.75138 val_ap= 0.74551\n",
      "Epoch: 0162 train_loss= 0.76770 val_roc= 0.75155 val_ap= 0.74576\n",
      "Epoch: 0163 train_loss= 0.76335 val_roc= 0.75162 val_ap= 0.74624\n",
      "Epoch: 0164 train_loss= 0.76814 val_roc= 0.75153 val_ap= 0.74646\n",
      "Epoch: 0165 train_loss= 0.76100 val_roc= 0.75134 val_ap= 0.74639\n",
      "Epoch: 0166 train_loss= 0.77075 val_roc= 0.75155 val_ap= 0.74736\n",
      "Epoch: 0167 train_loss= 0.77585 val_roc= 0.75169 val_ap= 0.74744\n",
      "Epoch: 0168 train_loss= 0.76987 val_roc= 0.75168 val_ap= 0.74706\n",
      "Epoch: 0169 train_loss= 0.76332 val_roc= 0.75181 val_ap= 0.74732\n",
      "Epoch: 0170 train_loss= 0.77070 val_roc= 0.75154 val_ap= 0.74746\n",
      "Test AP score: 0.7698908273316185\n",
      "Test ROC score: 0.7537294840501642\n",
      "Epoch: 0171 train_loss= 0.76135 val_roc= 0.75157 val_ap= 0.74811\n",
      "Epoch: 0172 train_loss= 0.76980 val_roc= 0.75151 val_ap= 0.74803\n",
      "Epoch: 0173 train_loss= 0.76735 val_roc= 0.75193 val_ap= 0.74915\n",
      "Epoch: 0174 train_loss= 0.77348 val_roc= 0.75214 val_ap= 0.74932\n",
      "Epoch: 0175 train_loss= 0.76650 val_roc= 0.75266 val_ap= 0.75007\n",
      "Epoch: 0176 train_loss= 0.76957 val_roc= 0.75296 val_ap= 0.75131\n",
      "Epoch: 0177 train_loss= 0.76595 val_roc= 0.75324 val_ap= 0.75172\n",
      "Epoch: 0178 train_loss= 0.76271 val_roc= 0.75343 val_ap= 0.75181\n",
      "Epoch: 0179 train_loss= 0.77065 val_roc= 0.75366 val_ap= 0.75204\n",
      "Epoch: 0180 train_loss= 0.76558 val_roc= 0.75366 val_ap= 0.75160\n",
      "Test AP score: 0.7718204914199871\n",
      "Test ROC score: 0.7554061105967511\n",
      "Epoch: 0181 train_loss= 0.76315 val_roc= 0.75396 val_ap= 0.75186\n",
      "Epoch: 0182 train_loss= 0.76119 val_roc= 0.75446 val_ap= 0.75221\n",
      "Epoch: 0183 train_loss= 0.75990 val_roc= 0.75495 val_ap= 0.75273\n",
      "Epoch: 0184 train_loss= 0.76438 val_roc= 0.75604 val_ap= 0.75335\n",
      "Epoch: 0185 train_loss= 0.76453 val_roc= 0.75715 val_ap= 0.75394\n",
      "Epoch: 0186 train_loss= 0.76734 val_roc= 0.75760 val_ap= 0.75452\n",
      "Epoch: 0187 train_loss= 0.76947 val_roc= 0.75812 val_ap= 0.75495\n",
      "Epoch: 0188 train_loss= 0.76092 val_roc= 0.75875 val_ap= 0.75514\n",
      "Epoch: 0189 train_loss= 0.75883 val_roc= 0.75983 val_ap= 0.75581\n",
      "Epoch: 0190 train_loss= 0.76492 val_roc= 0.76049 val_ap= 0.75638\n",
      "Test AP score: 0.7759341073011372\n",
      "Test ROC score: 0.7607457284740342\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0191 train_loss= 0.76086 val_roc= 0.76134 val_ap= 0.75693\n",
      "Epoch: 0192 train_loss= 0.76104 val_roc= 0.76208 val_ap= 0.75743\n",
      "Epoch: 0193 train_loss= 0.75675 val_roc= 0.76258 val_ap= 0.75768\n",
      "Epoch: 0194 train_loss= 0.76337 val_roc= 0.76319 val_ap= 0.75829\n",
      "Epoch: 0195 train_loss= 0.76614 val_roc= 0.76339 val_ap= 0.75836\n",
      "Epoch: 0196 train_loss= 0.75752 val_roc= 0.76398 val_ap= 0.75876\n",
      "Epoch: 0197 train_loss= 0.76422 val_roc= 0.76429 val_ap= 0.75892\n",
      "Epoch: 0198 train_loss= 0.76428 val_roc= 0.76414 val_ap= 0.75873\n",
      "Epoch: 0199 train_loss= 0.76481 val_roc= 0.76462 val_ap= 0.75969\n",
      "Epoch: 0200 train_loss= 0.75673 val_roc= 0.76492 val_ap= 0.75931\n",
      "Test AP score: 0.7785816615560124\n",
      "Test ROC score: 0.7647723255618214\n"
     ]
    }
   ],
   "source": [
    "runner.erun()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8bd9e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf1.15",
   "language": "python",
   "name": "tf1.15"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
