{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65775001",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-05T07:49:55.304007Z",
     "start_time": "2022-05-05T07:49:53.596467Z"
    }
   },
   "outputs": [],
   "source": [
    "import settings\n",
    "from link_prediction import Link_pred_Runner\n",
    "dataname = 'wiki'       # 'wiki' or 'power' or 'pages-food' or 'dublin'\n",
    "model = 'arga_ae'     # 'arga_ae' or 'arga_vae'\n",
    "task = 'link_prediction'         # 'clustering' or 'link_prediction'\n",
    "settings = settings.get_settings(dataname, model, task)\n",
    "runner = Link_pred_Runner(settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "254bd93d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-05T07:52:41.353852Z",
     "start_time": "2022-05-05T07:49:56.405897Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\zhangshanfan\\Desktop\\对比方法\\ARGA-master\\ARGA\\arga\\model.py:143: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\zhangshanfan\\Desktop\\对比方法\\ARGA-master\\ARGA\\arga\\model.py:145: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\zhangshanfan\\Desktop\\对比方法\\ARGA-master\\ARGA\\arga\\model.py:147: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\zhangshanfan\\Desktop\\对比方法\\ARGA-master\\ARGA\\arga\\layers.py:27: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\zhangshanfan\\Desktop\\对比方法\\ARGA-master\\ARGA\\arga\\layers.py:101: The name tf.sparse_tensor_dense_matmul is deprecated. Please use tf.sparse.sparse_dense_matmul instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\zhangshanfan\\Desktop\\对比方法\\ARGA-master\\ARGA\\arga\\layers.py:79: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\zhangshanfan\\.conda\\envs\\tf1.x\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\zhangshanfan\\Desktop\\对比方法\\ARGA-master\\ARGA\\arga\\optimizer.py:28: calling weighted_cross_entropy_with_logits (from tensorflow.python.ops.nn_impl) with targets is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "targets is deprecated, use labels instead\n",
      "WARNING:tensorflow:From C:\\Users\\zhangshanfan\\Desktop\\对比方法\\ARGA-master\\ARGA\\arga\\optimizer.py:37: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\zhangshanfan\\Desktop\\对比方法\\ARGA-master\\ARGA\\arga\\optimizer.py:38: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "Epoch: 0001 train_loss= 0.73041 val_roc= 0.65575 val_ap= 0.61031\n",
      "Epoch: 0002 train_loss= 0.73036 val_roc= 0.65422 val_ap= 0.62287\n",
      "Epoch: 0003 train_loss= 0.73004 val_roc= 0.66245 val_ap= 0.63042\n",
      "Epoch: 0004 train_loss= 0.72990 val_roc= 0.65135 val_ap= 0.61163\n",
      "Epoch: 0005 train_loss= 0.72963 val_roc= 0.64744 val_ap= 0.60080\n",
      "Epoch: 0006 train_loss= 0.72873 val_roc= 0.66603 val_ap= 0.63485\n",
      "Epoch: 0007 train_loss= 0.72809 val_roc= 0.68823 val_ap= 0.65990\n",
      "Epoch: 0008 train_loss= 0.72679 val_roc= 0.69068 val_ap= 0.68049\n",
      "Epoch: 0009 train_loss= 0.72533 val_roc= 0.69619 val_ap= 0.68357\n",
      "Epoch: 0010 train_loss= 0.72288 val_roc= 0.73175 val_ap= 0.73111\n",
      "Test AP score: 0.7478576775654131\n",
      "Test ROC score: 0.745638477727296\n",
      "Test ACC score: 0.59404659188956\n",
      "Test F1 score: 0.6939837398373983\n",
      "Epoch: 0011 train_loss= 0.71925 val_roc= 0.76000 val_ap= 0.76631\n",
      "Epoch: 0012 train_loss= 0.71376 val_roc= 0.77650 val_ap= 0.77986\n",
      "Epoch: 0013 train_loss= 0.70761 val_roc= 0.77414 val_ap= 0.78309\n",
      "Epoch: 0014 train_loss= 0.69690 val_roc= 0.76547 val_ap= 0.78178\n",
      "Epoch: 0015 train_loss= 0.68753 val_roc= 0.77047 val_ap= 0.77987\n",
      "Epoch: 0016 train_loss= 0.67822 val_roc= 0.78765 val_ap= 0.80385\n",
      "Epoch: 0017 train_loss= 0.66512 val_roc= 0.76401 val_ap= 0.78740\n",
      "Epoch: 0018 train_loss= 0.65606 val_roc= 0.77634 val_ap= 0.79886\n",
      "Epoch: 0019 train_loss= 0.65202 val_roc= 0.77811 val_ap= 0.79911\n",
      "Epoch: 0020 train_loss= 0.64864 val_roc= 0.77118 val_ap= 0.79862\n",
      "Test AP score: 0.8171733024192377\n",
      "Test ROC score: 0.7950533060469105\n",
      "Test ACC score: 0.5336496980155306\n",
      "Test F1 score: 0.6756675667566757\n",
      "Epoch: 0021 train_loss= 0.64355 val_roc= 0.77207 val_ap= 0.79292\n",
      "Epoch: 0022 train_loss= 0.64242 val_roc= 0.77479 val_ap= 0.79621\n",
      "Epoch: 0023 train_loss= 0.63966 val_roc= 0.77204 val_ap= 0.80159\n",
      "Epoch: 0024 train_loss= 0.63818 val_roc= 0.77692 val_ap= 0.80518\n",
      "Epoch: 0025 train_loss= 0.63212 val_roc= 0.76600 val_ap= 0.79885\n",
      "Epoch: 0026 train_loss= 0.63014 val_roc= 0.78683 val_ap= 0.81007\n",
      "Epoch: 0027 train_loss= 0.62701 val_roc= 0.78040 val_ap= 0.80395\n",
      "Epoch: 0028 train_loss= 0.62382 val_roc= 0.76855 val_ap= 0.79865\n",
      "Epoch: 0029 train_loss= 0.62042 val_roc= 0.77294 val_ap= 0.80121\n",
      "Epoch: 0030 train_loss= 0.61769 val_roc= 0.76977 val_ap= 0.80087\n",
      "Test AP score: 0.8273984897007175\n",
      "Test ROC score: 0.7997165150106345\n",
      "Test ACC score: 0.5798101811906816\n",
      "Test F1 score: 0.6954346466541589\n",
      "Epoch: 0031 train_loss= 0.61400 val_roc= 0.77916 val_ap= 0.80583\n",
      "Epoch: 0032 train_loss= 0.60946 val_roc= 0.78277 val_ap= 0.80952\n",
      "Epoch: 0033 train_loss= 0.60647 val_roc= 0.78934 val_ap= 0.81160\n",
      "Epoch: 0034 train_loss= 0.60199 val_roc= 0.79404 val_ap= 0.81867\n",
      "Epoch: 0035 train_loss= 0.59778 val_roc= 0.79250 val_ap= 0.81722\n",
      "Epoch: 0036 train_loss= 0.59328 val_roc= 0.81009 val_ap= 0.82766\n",
      "Epoch: 0037 train_loss= 0.58734 val_roc= 0.80546 val_ap= 0.82241\n",
      "Epoch: 0038 train_loss= 0.58463 val_roc= 0.81140 val_ap= 0.83033\n",
      "Epoch: 0039 train_loss= 0.57940 val_roc= 0.81142 val_ap= 0.82902\n",
      "Epoch: 0040 train_loss= 0.57339 val_roc= 0.80372 val_ap= 0.82502\n",
      "Test AP score: 0.8515093509643755\n",
      "Test ROC score: 0.8316346319199035\n",
      "Test ACC score: 0.6639344262295082\n",
      "Test F1 score: 0.732394366197183\n",
      "Epoch: 0041 train_loss= 0.57014 val_roc= 0.81374 val_ap= 0.83206\n",
      "Epoch: 0042 train_loss= 0.56449 val_roc= 0.81144 val_ap= 0.82995\n",
      "Epoch: 0043 train_loss= 0.56189 val_roc= 0.81857 val_ap= 0.83426\n",
      "Epoch: 0044 train_loss= 0.55929 val_roc= 0.81643 val_ap= 0.83081\n",
      "Epoch: 0045 train_loss= 0.55743 val_roc= 0.81818 val_ap= 0.83240\n",
      "Epoch: 0046 train_loss= 0.55584 val_roc= 0.81727 val_ap= 0.83494\n",
      "Epoch: 0047 train_loss= 0.55417 val_roc= 0.81744 val_ap= 0.83559\n",
      "Epoch: 0048 train_loss= 0.55095 val_roc= 0.81991 val_ap= 0.83820\n",
      "Epoch: 0049 train_loss= 0.55113 val_roc= 0.82286 val_ap= 0.83931\n",
      "Epoch: 0050 train_loss= 0.54697 val_roc= 0.81970 val_ap= 0.83590\n",
      "Test AP score: 0.8588194651474974\n",
      "Test ROC score: 0.8380629220542835\n",
      "Test ACC score: 0.6906816220880069\n",
      "Test F1 score: 0.7445671535447096\n",
      "Epoch: 0051 train_loss= 0.54467 val_roc= 0.82624 val_ap= 0.84537\n",
      "Epoch: 0052 train_loss= 0.54230 val_roc= 0.82499 val_ap= 0.84280\n",
      "Epoch: 0053 train_loss= 0.54154 val_roc= 0.82354 val_ap= 0.84031\n",
      "Epoch: 0054 train_loss= 0.53792 val_roc= 0.83447 val_ap= 0.85331\n",
      "Epoch: 0055 train_loss= 0.53715 val_roc= 0.82842 val_ap= 0.84851\n",
      "Epoch: 0056 train_loss= 0.53478 val_roc= 0.82971 val_ap= 0.84500\n",
      "Epoch: 0057 train_loss= 0.53195 val_roc= 0.83236 val_ap= 0.84915\n",
      "Epoch: 0058 train_loss= 0.52976 val_roc= 0.83464 val_ap= 0.85232\n",
      "Epoch: 0059 train_loss= 0.52642 val_roc= 0.84316 val_ap= 0.85549\n",
      "Epoch: 0060 train_loss= 0.52531 val_roc= 0.83663 val_ap= 0.85779\n",
      "Test AP score: 0.8761387233420863\n",
      "Test ROC score: 0.8575234816840259\n",
      "Test ACC score: 0.7006039689387403\n",
      "Test F1 score: 0.7507183908045978\n",
      "Epoch: 0061 train_loss= 0.52259 val_roc= 0.83971 val_ap= 0.86165\n",
      "Epoch: 0062 train_loss= 0.52034 val_roc= 0.84015 val_ap= 0.85980\n",
      "Epoch: 0063 train_loss= 0.51839 val_roc= 0.83961 val_ap= 0.85976\n",
      "Epoch: 0064 train_loss= 0.51697 val_roc= 0.84046 val_ap= 0.86350\n",
      "Epoch: 0065 train_loss= 0.51404 val_roc= 0.84095 val_ap= 0.86039\n",
      "Epoch: 0066 train_loss= 0.51191 val_roc= 0.83775 val_ap= 0.86279\n",
      "Epoch: 0067 train_loss= 0.51099 val_roc= 0.84390 val_ap= 0.86994\n",
      "Epoch: 0068 train_loss= 0.50818 val_roc= 0.84279 val_ap= 0.86872\n",
      "Epoch: 0069 train_loss= 0.50742 val_roc= 0.84434 val_ap= 0.86956\n",
      "Epoch: 0070 train_loss= 0.50431 val_roc= 0.84162 val_ap= 0.86872\n",
      "Test AP score: 0.8923754111880635\n",
      "Test ROC score: 0.8697934386029431\n",
      "Test ACC score: 0.6954270923209663\n",
      "Test F1 score: 0.7482168330955777\n",
      "Epoch: 0071 train_loss= 0.50441 val_roc= 0.84392 val_ap= 0.86685\n",
      "Epoch: 0072 train_loss= 0.50160 val_roc= 0.84384 val_ap= 0.86798\n",
      "Epoch: 0073 train_loss= 0.49990 val_roc= 0.84381 val_ap= 0.86860\n",
      "Epoch: 0074 train_loss= 0.49709 val_roc= 0.84823 val_ap= 0.87243\n",
      "Epoch: 0075 train_loss= 0.49610 val_roc= 0.85436 val_ap= 0.87500\n",
      "Epoch: 0076 train_loss= 0.49463 val_roc= 0.84479 val_ap= 0.87076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0077 train_loss= 0.49388 val_roc= 0.84846 val_ap= 0.87633\n",
      "Epoch: 0078 train_loss= 0.49087 val_roc= 0.85308 val_ap= 0.87721\n",
      "Epoch: 0079 train_loss= 0.49122 val_roc= 0.85691 val_ap= 0.87886\n",
      "Epoch: 0080 train_loss= 0.48896 val_roc= 0.84680 val_ap= 0.87552\n",
      "Test AP score: 0.8986327363393021\n",
      "Test ROC score: 0.8784185885157312\n",
      "Test ACC score: 0.7040552200172563\n",
      "Test F1 score: 0.755174875089222\n",
      "Epoch: 0081 train_loss= 0.48876 val_roc= 0.85984 val_ap= 0.88094\n",
      "Epoch: 0082 train_loss= 0.48738 val_roc= 0.84968 val_ap= 0.87641\n",
      "Epoch: 0083 train_loss= 0.48515 val_roc= 0.85477 val_ap= 0.88275\n",
      "Epoch: 0084 train_loss= 0.48457 val_roc= 0.84271 val_ap= 0.87110\n",
      "Epoch: 0085 train_loss= 0.48359 val_roc= 0.85144 val_ap= 0.87399\n",
      "Epoch: 0086 train_loss= 0.48181 val_roc= 0.85410 val_ap= 0.88035\n",
      "Epoch: 0087 train_loss= 0.48059 val_roc= 0.86077 val_ap= 0.88480\n",
      "Epoch: 0088 train_loss= 0.47956 val_roc= 0.85746 val_ap= 0.88370\n",
      "Epoch: 0089 train_loss= 0.47789 val_roc= 0.85280 val_ap= 0.88249\n",
      "Epoch: 0090 train_loss= 0.47660 val_roc= 0.85765 val_ap= 0.88287\n",
      "Test AP score: 0.9064210454201521\n",
      "Test ROC score: 0.8877598953606878\n",
      "Test ACC score: 0.7217428817946505\n",
      "Test F1 score: 0.767902123065851\n",
      "Epoch: 0091 train_loss= 0.47548 val_roc= 0.86056 val_ap= 0.88628\n",
      "Epoch: 0092 train_loss= 0.47417 val_roc= 0.85799 val_ap= 0.88575\n",
      "Epoch: 0093 train_loss= 0.47298 val_roc= 0.85460 val_ap= 0.88412\n",
      "Epoch: 0094 train_loss= 0.47208 val_roc= 0.85976 val_ap= 0.88686\n",
      "Epoch: 0095 train_loss= 0.47127 val_roc= 0.85380 val_ap= 0.88447\n",
      "Epoch: 0096 train_loss= 0.47095 val_roc= 0.86253 val_ap= 0.88746\n",
      "Epoch: 0097 train_loss= 0.47021 val_roc= 0.85426 val_ap= 0.88315\n",
      "Epoch: 0098 train_loss= 0.47008 val_roc= 0.85672 val_ap= 0.88430\n",
      "Epoch: 0099 train_loss= 0.46868 val_roc= 0.86319 val_ap= 0.89157\n",
      "Epoch: 0100 train_loss= 0.46855 val_roc= 0.86046 val_ap= 0.88752\n",
      "Test AP score: 0.9095998397165513\n",
      "Test ROC score: 0.8916354805882015\n",
      "Test ACC score: 0.7157031924072477\n",
      "Test F1 score: 0.7635450304987442\n",
      "Epoch: 0101 train_loss= 0.46790 val_roc= 0.86031 val_ap= 0.88796\n",
      "Epoch: 0102 train_loss= 0.46723 val_roc= 0.86489 val_ap= 0.89203\n",
      "Epoch: 0103 train_loss= 0.46694 val_roc= 0.86883 val_ap= 0.89333\n",
      "Epoch: 0104 train_loss= 0.46669 val_roc= 0.86691 val_ap= 0.89587\n",
      "Epoch: 0105 train_loss= 0.46630 val_roc= 0.86758 val_ap= 0.89329\n",
      "Epoch: 0106 train_loss= 0.46526 val_roc= 0.86883 val_ap= 0.89452\n",
      "Epoch: 0107 train_loss= 0.46478 val_roc= 0.85785 val_ap= 0.88743\n",
      "Epoch: 0108 train_loss= 0.46434 val_roc= 0.86835 val_ap= 0.89344\n",
      "Epoch: 0109 train_loss= 0.46448 val_roc= 0.86528 val_ap= 0.89375\n",
      "Epoch: 0110 train_loss= 0.46352 val_roc= 0.86464 val_ap= 0.89505\n",
      "Test AP score: 0.9141385883121169\n",
      "Test ROC score: 0.895864677606547\n",
      "Test ACC score: 0.727351164797239\n",
      "Test F1 score: 0.7728253055355859\n",
      "Epoch: 0111 train_loss= 0.46256 val_roc= 0.86703 val_ap= 0.89670\n",
      "Epoch: 0112 train_loss= 0.46206 val_roc= 0.86802 val_ap= 0.89614\n",
      "Epoch: 0113 train_loss= 0.46167 val_roc= 0.86951 val_ap= 0.89779\n",
      "Epoch: 0114 train_loss= 0.46058 val_roc= 0.87083 val_ap= 0.89816\n",
      "Epoch: 0115 train_loss= 0.46051 val_roc= 0.86537 val_ap= 0.89421\n",
      "Epoch: 0116 train_loss= 0.45971 val_roc= 0.86549 val_ap= 0.89423\n",
      "Epoch: 0117 train_loss= 0.45922 val_roc= 0.87355 val_ap= 0.90013\n",
      "Epoch: 0118 train_loss= 0.45853 val_roc= 0.86945 val_ap= 0.89671\n",
      "Epoch: 0119 train_loss= 0.45787 val_roc= 0.87349 val_ap= 0.90036\n",
      "Epoch: 0120 train_loss= 0.45687 val_roc= 0.86836 val_ap= 0.89653\n",
      "Test AP score: 0.9184927528416725\n",
      "Test ROC score: 0.8990427170487783\n",
      "Test ACC score: 0.7178602243313201\n",
      "Test F1 score: 0.7665952890792291\n",
      "Epoch: 0121 train_loss= 0.45606 val_roc= 0.87332 val_ap= 0.89864\n",
      "Epoch: 0122 train_loss= 0.45535 val_roc= 0.87503 val_ap= 0.90384\n",
      "Epoch: 0123 train_loss= 0.45461 val_roc= 0.87318 val_ap= 0.90086\n",
      "Epoch: 0124 train_loss= 0.45392 val_roc= 0.87646 val_ap= 0.90524\n",
      "Epoch: 0125 train_loss= 0.45262 val_roc= 0.87579 val_ap= 0.90386\n",
      "Epoch: 0126 train_loss= 0.45252 val_roc= 0.87804 val_ap= 0.90495\n",
      "Epoch: 0127 train_loss= 0.45171 val_roc= 0.87204 val_ap= 0.90151\n",
      "Epoch: 0128 train_loss= 0.45060 val_roc= 0.87395 val_ap= 0.90180\n",
      "Epoch: 0129 train_loss= 0.45023 val_roc= 0.87987 val_ap= 0.90834\n",
      "Epoch: 0130 train_loss= 0.44959 val_roc= 0.87364 val_ap= 0.90431\n",
      "Test AP score: 0.9213494120770507\n",
      "Test ROC score: 0.9023480567357092\n",
      "Test ACC score: 0.7260569456427955\n",
      "Test F1 score: 0.7718289615522818\n",
      "Epoch: 0131 train_loss= 0.44863 val_roc= 0.87838 val_ap= 0.90627\n",
      "Epoch: 0132 train_loss= 0.44794 val_roc= 0.88378 val_ap= 0.90999\n",
      "Epoch: 0133 train_loss= 0.44768 val_roc= 0.88211 val_ap= 0.90902\n",
      "Epoch: 0134 train_loss= 0.44650 val_roc= 0.88129 val_ap= 0.90842\n",
      "Epoch: 0135 train_loss= 0.44627 val_roc= 0.88274 val_ap= 0.90956\n",
      "Epoch: 0136 train_loss= 0.44494 val_roc= 0.88642 val_ap= 0.91292\n",
      "Epoch: 0137 train_loss= 0.44452 val_roc= 0.88415 val_ap= 0.91224\n",
      "Epoch: 0138 train_loss= 0.44407 val_roc= 0.87406 val_ap= 0.90439\n",
      "Epoch: 0139 train_loss= 0.44304 val_roc= 0.88889 val_ap= 0.91537\n",
      "Epoch: 0140 train_loss= 0.44325 val_roc= 0.89115 val_ap= 0.91596\n",
      "Test AP score: 0.9235178347652181\n",
      "Test ROC score: 0.9028416243511224\n",
      "Test ACC score: 0.7204486626402071\n",
      "Test F1 score: 0.7680744452397995\n",
      "Epoch: 0141 train_loss= 0.44208 val_roc= 0.88221 val_ap= 0.91256\n",
      "Epoch: 0142 train_loss= 0.44111 val_roc= 0.88761 val_ap= 0.91639\n",
      "Epoch: 0143 train_loss= 0.44098 val_roc= 0.89327 val_ap= 0.91875\n",
      "Epoch: 0144 train_loss= 0.44029 val_roc= 0.87788 val_ap= 0.90963\n",
      "Epoch: 0145 train_loss= 0.43935 val_roc= 0.89037 val_ap= 0.91673\n",
      "Epoch: 0146 train_loss= 0.43924 val_roc= 0.89227 val_ap= 0.91788\n",
      "Epoch: 0147 train_loss= 0.43883 val_roc= 0.89442 val_ap= 0.91978\n",
      "Epoch: 0148 train_loss= 0.43808 val_roc= 0.89259 val_ap= 0.91881\n",
      "Epoch: 0149 train_loss= 0.43740 val_roc= 0.89475 val_ap= 0.92167\n",
      "Epoch: 0150 train_loss= 0.43708 val_roc= 0.88833 val_ap= 0.91665\n",
      "Test AP score: 0.9253540112090479\n",
      "Test ROC score: 0.904525560921356\n",
      "Test ACC score: 0.7187230371009491\n",
      "Test F1 score: 0.767142857142857\n",
      "Epoch: 0151 train_loss= 0.43675 val_roc= 0.88973 val_ap= 0.91582\n",
      "Epoch: 0152 train_loss= 0.43662 val_roc= 0.88878 val_ap= 0.91674\n",
      "Epoch: 0153 train_loss= 0.43582 val_roc= 0.88653 val_ap= 0.91682\n",
      "Epoch: 0154 train_loss= 0.43504 val_roc= 0.88942 val_ap= 0.91754\n",
      "Epoch: 0155 train_loss= 0.43465 val_roc= 0.89020 val_ap= 0.91701\n",
      "Epoch: 0156 train_loss= 0.43483 val_roc= 0.88877 val_ap= 0.91605\n",
      "Epoch: 0157 train_loss= 0.43448 val_roc= 0.89210 val_ap= 0.91912\n",
      "Epoch: 0158 train_loss= 0.43345 val_roc= 0.89256 val_ap= 0.91993\n",
      "Epoch: 0159 train_loss= 0.43323 val_roc= 0.88997 val_ap= 0.91781\n",
      "Epoch: 0160 train_loss= 0.43290 val_roc= 0.88615 val_ap= 0.91589\n",
      "Test AP score: 0.927680802803181\n",
      "Test ROC score: 0.9058127078399829\n",
      "Test ACC score: 0.7243313201035375\n",
      "Test F1 score: 0.7707212055974167\n",
      "Epoch: 0161 train_loss= 0.43288 val_roc= 0.90460 val_ap= 0.92556\n",
      "Epoch: 0162 train_loss= 0.43221 val_roc= 0.89279 val_ap= 0.91909\n",
      "Epoch: 0163 train_loss= 0.43205 val_roc= 0.89500 val_ap= 0.92068\n",
      "Epoch: 0164 train_loss= 0.43207 val_roc= 0.88977 val_ap= 0.91752\n",
      "Epoch: 0165 train_loss= 0.43136 val_roc= 0.89434 val_ap= 0.91921\n",
      "Epoch: 0166 train_loss= 0.43092 val_roc= 0.88972 val_ap= 0.91853\n",
      "Epoch: 0167 train_loss= 0.43064 val_roc= 0.89266 val_ap= 0.91916\n",
      "Epoch: 0168 train_loss= 0.43036 val_roc= 0.88650 val_ap= 0.91619\n",
      "Epoch: 0169 train_loss= 0.42985 val_roc= 0.88747 val_ap= 0.91671\n",
      "Epoch: 0170 train_loss= 0.43022 val_roc= 0.89230 val_ap= 0.91796\n",
      "Test AP score: 0.9282245946904202\n",
      "Test ROC score: 0.9067901652744288\n",
      "Test ACC score: 0.7320966350301984\n",
      "Test F1 score: 0.7754068716094034\n",
      "Epoch: 0171 train_loss= 0.42980 val_roc= 0.89748 val_ap= 0.92221\n",
      "Epoch: 0172 train_loss= 0.42923 val_roc= 0.89474 val_ap= 0.92156\n",
      "Epoch: 0173 train_loss= 0.42960 val_roc= 0.89019 val_ap= 0.91722\n",
      "Epoch: 0174 train_loss= 0.42887 val_roc= 0.89038 val_ap= 0.91752\n",
      "Epoch: 0175 train_loss= 0.42870 val_roc= 0.88720 val_ap= 0.91794\n",
      "Epoch: 0176 train_loss= 0.42793 val_roc= 0.89300 val_ap= 0.91962\n",
      "Epoch: 0177 train_loss= 0.42807 val_roc= 0.88393 val_ap= 0.91482\n",
      "Epoch: 0178 train_loss= 0.42812 val_roc= 0.89288 val_ap= 0.91807\n",
      "Epoch: 0179 train_loss= 0.42768 val_roc= 0.89840 val_ap= 0.92382\n",
      "Epoch: 0180 train_loss= 0.42783 val_roc= 0.88964 val_ap= 0.91808\n",
      "Test AP score: 0.9291522965191005\n",
      "Test ROC score: 0.9075703445518846\n",
      "Test ACC score: 0.734253666954271\n",
      "Test F1 score: 0.7768115942028986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0181 train_loss= 0.42744 val_roc= 0.89450 val_ap= 0.92197\n",
      "Epoch: 0182 train_loss= 0.42746 val_roc= 0.88495 val_ap= 0.91368\n",
      "Epoch: 0183 train_loss= 0.42734 val_roc= 0.88593 val_ap= 0.91639\n",
      "Epoch: 0184 train_loss= 0.42663 val_roc= 0.88851 val_ap= 0.91885\n",
      "Epoch: 0185 train_loss= 0.42635 val_roc= 0.88803 val_ap= 0.91675\n",
      "Epoch: 0186 train_loss= 0.42582 val_roc= 0.89099 val_ap= 0.91823\n",
      "Epoch: 0187 train_loss= 0.42561 val_roc= 0.89550 val_ap= 0.91882\n",
      "Epoch: 0188 train_loss= 0.42594 val_roc= 0.89260 val_ap= 0.91943\n",
      "Epoch: 0189 train_loss= 0.42530 val_roc= 0.88939 val_ap= 0.91833\n",
      "Epoch: 0190 train_loss= 0.42499 val_roc= 0.89880 val_ap= 0.92129\n",
      "Test AP score: 0.9293291968976104\n",
      "Test ROC score: 0.9059779748243293\n",
      "Test ACC score: 0.727351164797239\n",
      "Test F1 score: 0.7720057720057719\n",
      "Epoch: 0191 train_loss= 0.42481 val_roc= 0.88877 val_ap= 0.91791\n",
      "Epoch: 0192 train_loss= 0.42501 val_roc= 0.89007 val_ap= 0.91814\n",
      "Epoch: 0193 train_loss= 0.42472 val_roc= 0.88923 val_ap= 0.91694\n",
      "Epoch: 0194 train_loss= 0.42410 val_roc= 0.89565 val_ap= 0.92032\n",
      "Epoch: 0195 train_loss= 0.42440 val_roc= 0.89018 val_ap= 0.91775\n",
      "Epoch: 0196 train_loss= 0.42388 val_roc= 0.89598 val_ap= 0.91992\n",
      "Epoch: 0197 train_loss= 0.42369 val_roc= 0.89907 val_ap= 0.92465\n",
      "Epoch: 0198 train_loss= 0.42311 val_roc= 0.89027 val_ap= 0.91699\n",
      "Epoch: 0199 train_loss= 0.42311 val_roc= 0.89128 val_ap= 0.91963\n",
      "Epoch: 0200 train_loss= 0.42271 val_roc= 0.89248 val_ap= 0.91928\n",
      "Test AP score: 0.9276407962105847\n",
      "Test ROC score: 0.9026979462971635\n",
      "Test ACC score: 0.727351164797239\n",
      "Test F1 score: 0.7700145560407567\n"
     ]
    }
   ],
   "source": [
    "runner.erun()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c11174",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf1.15",
   "language": "python",
   "name": "tf1.15"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
