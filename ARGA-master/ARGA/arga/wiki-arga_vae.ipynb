{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e7267b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-05T07:41:07.232491Z",
     "start_time": "2022-05-05T07:41:05.548961Z"
    }
   },
   "outputs": [],
   "source": [
    "import settings\n",
    "from link_prediction import Link_pred_Runner\n",
    "dataname = 'wiki'       # 'wiki' or 'power' or 'pages-food' or 'dublin'\n",
    "model = 'arga_vae'     # 'arga_ae' or 'arga_vae'\n",
    "task = 'link_prediction'         # 'clustering' or 'link_prediction'\n",
    "settings = settings.get_settings(dataname, model, task)\n",
    "runner = Link_pred_Runner(settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a0fa53c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-05T07:43:35.034198Z",
     "start_time": "2022-05-05T07:41:08.472427Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\zhangshanfan\\Desktop\\对比方法\\ARGA-master\\ARGA\\arga\\model.py:143: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\zhangshanfan\\Desktop\\对比方法\\ARGA-master\\ARGA\\arga\\model.py:145: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\zhangshanfan\\Desktop\\对比方法\\ARGA-master\\ARGA\\arga\\model.py:147: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\zhangshanfan\\Desktop\\对比方法\\ARGA-master\\ARGA\\arga\\layers.py:27: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\zhangshanfan\\Desktop\\对比方法\\ARGA-master\\ARGA\\arga\\layers.py:101: The name tf.sparse_tensor_dense_matmul is deprecated. Please use tf.sparse.sparse_dense_matmul instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\zhangshanfan\\Desktop\\对比方法\\ARGA-master\\ARGA\\arga\\layers.py:79: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\zhangshanfan\\Desktop\\对比方法\\ARGA-master\\ARGA\\arga\\model.py:126: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\zhangshanfan\\Desktop\\对比方法\\ARGA-master\\ARGA\\arga\\constructor.py:94: The name tf.sparse_tensor_to_dense is deprecated. Please use tf.sparse.to_dense instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\zhangshanfan\\.conda\\envs\\tf1.x\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\zhangshanfan\\Desktop\\对比方法\\ARGA-master\\ARGA\\arga\\optimizer.py:67: calling weighted_cross_entropy_with_logits (from tensorflow.python.ops.nn_impl) with targets is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "targets is deprecated, use labels instead\n",
      "WARNING:tensorflow:From C:\\Users\\zhangshanfan\\Desktop\\对比方法\\ARGA-master\\ARGA\\arga\\optimizer.py:68: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\zhangshanfan\\Desktop\\对比方法\\ARGA-master\\ARGA\\arga\\optimizer.py:70: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\zhangshanfan\\Desktop\\对比方法\\ARGA-master\\ARGA\\arga\\optimizer.py:75: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n",
      "\n",
      "Epoch: 0001 train_loss= 2.39042 val_roc= 0.68728 val_ap= 0.66085\n",
      "Epoch: 0002 train_loss= 2.34471 val_roc= 0.70016 val_ap= 0.67026\n",
      "Epoch: 0003 train_loss= 2.33741 val_roc= 0.72556 val_ap= 0.69566\n",
      "Epoch: 0004 train_loss= 2.36630 val_roc= 0.75046 val_ap= 0.72670\n",
      "Epoch: 0005 train_loss= 2.32102 val_roc= 0.76750 val_ap= 0.75240\n",
      "Epoch: 0006 train_loss= 2.31870 val_roc= 0.77787 val_ap= 0.77007\n",
      "Epoch: 0007 train_loss= 2.28387 val_roc= 0.78541 val_ap= 0.78310\n",
      "Epoch: 0008 train_loss= 2.30361 val_roc= 0.78971 val_ap= 0.78988\n",
      "Epoch: 0009 train_loss= 2.29784 val_roc= 0.79266 val_ap= 0.79361\n",
      "Epoch: 0010 train_loss= 2.25109 val_roc= 0.79428 val_ap= 0.79548\n",
      "Test AP score: 0.8293414826305414\n",
      "Test ROC score: 0.827665246512085\n",
      "Test ACC score: 0.5\n",
      "Test F1 score: 0.6666666666666666\n",
      "Epoch: 0011 train_loss= 2.26283 val_roc= 0.79516 val_ap= 0.79680\n",
      "Epoch: 0012 train_loss= 2.22637 val_roc= 0.79556 val_ap= 0.79714\n",
      "Epoch: 0013 train_loss= 2.20701 val_roc= 0.79578 val_ap= 0.79719\n",
      "Epoch: 0014 train_loss= 2.20392 val_roc= 0.79579 val_ap= 0.79718\n",
      "Epoch: 0015 train_loss= 2.15862 val_roc= 0.79540 val_ap= 0.79689\n",
      "Epoch: 0016 train_loss= 2.18192 val_roc= 0.79514 val_ap= 0.79675\n",
      "Epoch: 0017 train_loss= 2.09326 val_roc= 0.79504 val_ap= 0.79678\n",
      "Epoch: 0018 train_loss= 2.13119 val_roc= 0.79497 val_ap= 0.79668\n",
      "Epoch: 0019 train_loss= 2.03646 val_roc= 0.79480 val_ap= 0.79661\n",
      "Epoch: 0020 train_loss= 2.05481 val_roc= 0.79477 val_ap= 0.79639\n",
      "Test AP score: 0.8256363597350692\n",
      "Test ROC score: 0.8248851133902735\n",
      "Test ACC score: 0.5\n",
      "Test F1 score: 0.6666666666666666\n",
      "Epoch: 0021 train_loss= 2.00751 val_roc= 0.79473 val_ap= 0.79636\n",
      "Epoch: 0022 train_loss= 1.94719 val_roc= 0.79456 val_ap= 0.79628\n",
      "Epoch: 0023 train_loss= 1.93805 val_roc= 0.79452 val_ap= 0.79634\n",
      "Epoch: 0024 train_loss= 1.90005 val_roc= 0.79458 val_ap= 0.79649\n",
      "Epoch: 0025 train_loss= 1.90162 val_roc= 0.79441 val_ap= 0.79643\n",
      "Epoch: 0026 train_loss= 1.88313 val_roc= 0.79428 val_ap= 0.79632\n",
      "Epoch: 0027 train_loss= 1.81929 val_roc= 0.79415 val_ap= 0.79628\n",
      "Epoch: 0028 train_loss= 1.79367 val_roc= 0.79417 val_ap= 0.79644\n",
      "Epoch: 0029 train_loss= 1.76119 val_roc= 0.79410 val_ap= 0.79661\n",
      "Epoch: 0030 train_loss= 1.72227 val_roc= 0.79406 val_ap= 0.79677\n",
      "Test AP score: 0.8240748223642687\n",
      "Test ROC score: 0.8222181360415282\n",
      "Test ACC score: 0.5\n",
      "Test F1 score: 0.6666666666666666\n",
      "Epoch: 0031 train_loss= 1.70307 val_roc= 0.79401 val_ap= 0.79685\n",
      "Epoch: 0032 train_loss= 1.66766 val_roc= 0.79403 val_ap= 0.79717\n",
      "Epoch: 0033 train_loss= 1.62493 val_roc= 0.79398 val_ap= 0.79746\n",
      "Epoch: 0034 train_loss= 1.61132 val_roc= 0.79399 val_ap= 0.79781\n",
      "Epoch: 0035 train_loss= 1.60307 val_roc= 0.79408 val_ap= 0.79808\n",
      "Epoch: 0036 train_loss= 1.56749 val_roc= 0.79416 val_ap= 0.79839\n",
      "Epoch: 0037 train_loss= 1.56329 val_roc= 0.79422 val_ap= 0.79877\n",
      "Epoch: 0038 train_loss= 1.50046 val_roc= 0.79435 val_ap= 0.79916\n",
      "Epoch: 0039 train_loss= 1.52187 val_roc= 0.79452 val_ap= 0.79969\n",
      "Epoch: 0040 train_loss= 1.46697 val_roc= 0.79468 val_ap= 0.80025\n",
      "Test AP score: 0.8251729577074618\n",
      "Test ROC score: 0.8201307098068089\n",
      "Test ACC score: 0.5\n",
      "Test F1 score: 0.6666666666666666\n",
      "Epoch: 0041 train_loss= 1.48576 val_roc= 0.79469 val_ap= 0.80061\n",
      "Epoch: 0042 train_loss= 1.43375 val_roc= 0.79461 val_ap= 0.80102\n",
      "Epoch: 0043 train_loss= 1.42585 val_roc= 0.79460 val_ap= 0.80161\n",
      "Epoch: 0044 train_loss= 1.43515 val_roc= 0.79439 val_ap= 0.80182\n",
      "Epoch: 0045 train_loss= 1.39085 val_roc= 0.79432 val_ap= 0.80261\n",
      "Epoch: 0046 train_loss= 1.36312 val_roc= 0.79411 val_ap= 0.80316\n",
      "Epoch: 0047 train_loss= 1.34108 val_roc= 0.79389 val_ap= 0.80344\n",
      "Epoch: 0048 train_loss= 1.34014 val_roc= 0.79341 val_ap= 0.80380\n",
      "Epoch: 0049 train_loss= 1.31024 val_roc= 0.79297 val_ap= 0.80421\n",
      "Epoch: 0050 train_loss= 1.29859 val_roc= 0.79237 val_ap= 0.80456\n",
      "Test AP score: 0.8297341929194146\n",
      "Test ROC score: 0.8188621740350678\n",
      "Test ACC score: 0.5090595340811044\n",
      "Test F1 score: 0.6691860465116278\n",
      "Epoch: 0051 train_loss= 1.29274 val_roc= 0.79177 val_ap= 0.80464\n",
      "Epoch: 0052 train_loss= 1.26584 val_roc= 0.79133 val_ap= 0.80481\n",
      "Epoch: 0053 train_loss= 1.24580 val_roc= 0.79098 val_ap= 0.80504\n",
      "Epoch: 0054 train_loss= 1.24018 val_roc= 0.79046 val_ap= 0.80526\n",
      "Epoch: 0055 train_loss= 1.22514 val_roc= 0.79010 val_ap= 0.80548\n",
      "Epoch: 0056 train_loss= 1.22389 val_roc= 0.78965 val_ap= 0.80550\n",
      "Epoch: 0057 train_loss= 1.18590 val_roc= 0.78930 val_ap= 0.80565\n",
      "Epoch: 0058 train_loss= 1.18086 val_roc= 0.78894 val_ap= 0.80579\n",
      "Epoch: 0059 train_loss= 1.16011 val_roc= 0.78858 val_ap= 0.80581\n",
      "Epoch: 0060 train_loss= 1.16224 val_roc= 0.78817 val_ap= 0.80585\n",
      "Test AP score: 0.8317810833225048\n",
      "Test ROC score: 0.8153268005726277\n",
      "Test ACC score: 0.5090595340811044\n",
      "Test F1 score: 0.6682215743440234\n",
      "Epoch: 0061 train_loss= 1.14529 val_roc= 0.78773 val_ap= 0.80574\n",
      "Epoch: 0062 train_loss= 1.13012 val_roc= 0.78744 val_ap= 0.80597\n",
      "Epoch: 0063 train_loss= 1.12871 val_roc= 0.78729 val_ap= 0.80601\n",
      "Epoch: 0064 train_loss= 1.11155 val_roc= 0.78697 val_ap= 0.80602\n",
      "Epoch: 0065 train_loss= 1.09794 val_roc= 0.78667 val_ap= 0.80592\n",
      "Epoch: 0066 train_loss= 1.09324 val_roc= 0.78640 val_ap= 0.80560\n",
      "Epoch: 0067 train_loss= 1.07761 val_roc= 0.78625 val_ap= 0.80558\n",
      "Epoch: 0068 train_loss= 1.07013 val_roc= 0.78603 val_ap= 0.80516\n",
      "Epoch: 0069 train_loss= 1.06144 val_roc= 0.78568 val_ap= 0.80489\n",
      "Epoch: 0070 train_loss= 1.04128 val_roc= 0.78542 val_ap= 0.80451\n",
      "Test AP score: 0.832077116083872\n",
      "Test ROC score: 0.8108132252298662\n",
      "Test ACC score: 0.5189818809318378\n",
      "Test F1 score: 0.671188439988204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0071 train_loss= 1.04225 val_roc= 0.78536 val_ap= 0.80417\n",
      "Epoch: 0072 train_loss= 1.01345 val_roc= 0.78516 val_ap= 0.80368\n",
      "Epoch: 0073 train_loss= 1.00965 val_roc= 0.78481 val_ap= 0.80314\n",
      "Epoch: 0074 train_loss= 1.00704 val_roc= 0.78478 val_ap= 0.80259\n",
      "Epoch: 0075 train_loss= 0.99727 val_roc= 0.78515 val_ap= 0.80210\n",
      "Epoch: 0076 train_loss= 0.98991 val_roc= 0.78507 val_ap= 0.80156\n",
      "Epoch: 0077 train_loss= 0.97875 val_roc= 0.78490 val_ap= 0.80097\n",
      "Epoch: 0078 train_loss= 0.96211 val_roc= 0.78528 val_ap= 0.80070\n",
      "Epoch: 0079 train_loss= 0.95913 val_roc= 0.78546 val_ap= 0.80032\n",
      "Epoch: 0080 train_loss= 0.95085 val_roc= 0.78682 val_ap= 0.80017\n",
      "Test AP score: 0.831792836485004\n",
      "Test ROC score: 0.8171413873940002\n",
      "Test ACC score: 0.5504745470232959\n",
      "Test F1 score: 0.6825106642291286\n",
      "Epoch: 0081 train_loss= 0.92655 val_roc= 0.78805 val_ap= 0.80029\n",
      "Epoch: 0082 train_loss= 0.92463 val_roc= 0.78999 val_ap= 0.80053\n",
      "Epoch: 0083 train_loss= 0.91213 val_roc= 0.79192 val_ap= 0.80111\n",
      "Epoch: 0084 train_loss= 0.91072 val_roc= 0.79292 val_ap= 0.80113\n",
      "Epoch: 0085 train_loss= 0.89836 val_roc= 0.79392 val_ap= 0.80129\n",
      "Epoch: 0086 train_loss= 0.88221 val_roc= 0.79434 val_ap= 0.80136\n",
      "Epoch: 0087 train_loss= 0.87822 val_roc= 0.79372 val_ap= 0.80095\n",
      "Epoch: 0088 train_loss= 0.87000 val_roc= 0.79321 val_ap= 0.80052\n",
      "Epoch: 0089 train_loss= 0.86917 val_roc= 0.79268 val_ap= 0.80019\n",
      "Epoch: 0090 train_loss= 0.84958 val_roc= 0.79178 val_ap= 0.79957\n",
      "Test AP score: 0.829447436479218\n",
      "Test ROC score: 0.8183753064325334\n",
      "Test ACC score: 0.6479723899913719\n",
      "Test F1 score: 0.7239512855209742\n",
      "Epoch: 0091 train_loss= 0.84660 val_roc= 0.79035 val_ap= 0.79882\n",
      "Epoch: 0092 train_loss= 0.83731 val_roc= 0.78846 val_ap= 0.79750\n",
      "Epoch: 0093 train_loss= 0.83085 val_roc= 0.78643 val_ap= 0.79646\n",
      "Epoch: 0094 train_loss= 0.82730 val_roc= 0.78447 val_ap= 0.79529\n",
      "Epoch: 0095 train_loss= 0.82391 val_roc= 0.78238 val_ap= 0.79398\n",
      "Epoch: 0096 train_loss= 0.81191 val_roc= 0.78079 val_ap= 0.79319\n",
      "Epoch: 0097 train_loss= 0.81108 val_roc= 0.77936 val_ap= 0.79233\n",
      "Epoch: 0098 train_loss= 0.79994 val_roc= 0.77831 val_ap= 0.79175\n",
      "Epoch: 0099 train_loss= 0.79831 val_roc= 0.77781 val_ap= 0.79167\n",
      "Epoch: 0100 train_loss= 0.79406 val_roc= 0.77735 val_ap= 0.79159\n",
      "Test AP score: 0.8180277988991593\n",
      "Test ROC score: 0.7998840153326072\n",
      "Test ACC score: 0.6747195858498706\n",
      "Test F1 score: 0.7328136073706591\n",
      "Epoch: 0101 train_loss= 0.78561 val_roc= 0.77710 val_ap= 0.79158\n",
      "Epoch: 0102 train_loss= 0.79092 val_roc= 0.77686 val_ap= 0.79156\n",
      "Epoch: 0103 train_loss= 0.78636 val_roc= 0.77664 val_ap= 0.79143\n",
      "Epoch: 0104 train_loss= 0.77916 val_roc= 0.77670 val_ap= 0.79166\n",
      "Epoch: 0105 train_loss= 0.77491 val_roc= 0.77705 val_ap= 0.79231\n",
      "Epoch: 0106 train_loss= 0.76975 val_roc= 0.77765 val_ap= 0.79286\n",
      "Epoch: 0107 train_loss= 0.77562 val_roc= 0.77789 val_ap= 0.79293\n",
      "Epoch: 0108 train_loss= 0.76979 val_roc= 0.77822 val_ap= 0.79334\n",
      "Epoch: 0109 train_loss= 0.76418 val_roc= 0.77887 val_ap= 0.79398\n",
      "Epoch: 0110 train_loss= 0.75917 val_roc= 0.77967 val_ap= 0.79472\n",
      "Test AP score: 0.8200577681370332\n",
      "Test ROC score: 0.8014801072895397\n",
      "Test ACC score: 0.6781708369283865\n",
      "Test F1 score: 0.732616487455197\n",
      "Epoch: 0111 train_loss= 0.76013 val_roc= 0.78049 val_ap= 0.79529\n",
      "Epoch: 0112 train_loss= 0.75689 val_roc= 0.78155 val_ap= 0.79616\n",
      "Epoch: 0113 train_loss= 0.75473 val_roc= 0.78201 val_ap= 0.79650\n",
      "Epoch: 0114 train_loss= 0.74917 val_roc= 0.78262 val_ap= 0.79724\n",
      "Epoch: 0115 train_loss= 0.75288 val_roc= 0.78272 val_ap= 0.79736\n",
      "Epoch: 0116 train_loss= 0.74515 val_roc= 0.78297 val_ap= 0.79761\n",
      "Epoch: 0117 train_loss= 0.74432 val_roc= 0.78351 val_ap= 0.79823\n",
      "Epoch: 0118 train_loss= 0.74449 val_roc= 0.78416 val_ap= 0.79887\n",
      "Epoch: 0119 train_loss= 0.74022 val_roc= 0.78447 val_ap= 0.79917\n",
      "Epoch: 0120 train_loss= 0.74121 val_roc= 0.78466 val_ap= 0.79953\n",
      "Test AP score: 0.8228095928155443\n",
      "Test ROC score: 0.8046715467575287\n",
      "Test ACC score: 0.680327868852459\n",
      "Test F1 score: 0.7331652862801584\n",
      "Epoch: 0121 train_loss= 0.73909 val_roc= 0.78504 val_ap= 0.80002\n",
      "Epoch: 0122 train_loss= 0.73555 val_roc= 0.78524 val_ap= 0.80031\n",
      "Epoch: 0123 train_loss= 0.72883 val_roc= 0.78546 val_ap= 0.80065\n",
      "Epoch: 0124 train_loss= 0.72822 val_roc= 0.78656 val_ap= 0.80172\n",
      "Epoch: 0125 train_loss= 0.73102 val_roc= 0.78725 val_ap= 0.80242\n",
      "Epoch: 0126 train_loss= 0.72935 val_roc= 0.78758 val_ap= 0.80284\n",
      "Epoch: 0127 train_loss= 0.72772 val_roc= 0.78784 val_ap= 0.80308\n",
      "Epoch: 0128 train_loss= 0.72714 val_roc= 0.78809 val_ap= 0.80327\n",
      "Epoch: 0129 train_loss= 0.72678 val_roc= 0.78833 val_ap= 0.80344\n",
      "Epoch: 0130 train_loss= 0.72622 val_roc= 0.78898 val_ap= 0.80384\n",
      "Test AP score: 0.8254684504059632\n",
      "Test ROC score: 0.807325496303454\n",
      "Test ACC score: 0.6833477135461605\n",
      "Test F1 score: 0.7363505747126436\n",
      "Epoch: 0131 train_loss= 0.72310 val_roc= 0.78997 val_ap= 0.80463\n",
      "Epoch: 0132 train_loss= 0.72871 val_roc= 0.79006 val_ap= 0.80476\n",
      "Epoch: 0133 train_loss= 0.72461 val_roc= 0.79000 val_ap= 0.80479\n",
      "Epoch: 0134 train_loss= 0.72205 val_roc= 0.78983 val_ap= 0.80485\n",
      "Epoch: 0135 train_loss= 0.71896 val_roc= 0.78951 val_ap= 0.80472\n",
      "Epoch: 0136 train_loss= 0.72575 val_roc= 0.78990 val_ap= 0.80499\n",
      "Epoch: 0137 train_loss= 0.72196 val_roc= 0.79033 val_ap= 0.80533\n",
      "Epoch: 0138 train_loss= 0.71820 val_roc= 0.79022 val_ap= 0.80518\n",
      "Epoch: 0139 train_loss= 0.72187 val_roc= 0.78992 val_ap= 0.80504\n",
      "Epoch: 0140 train_loss= 0.72288 val_roc= 0.78993 val_ap= 0.80522\n",
      "Test AP score: 0.8263451990916629\n",
      "Test ROC score: 0.807703674808175\n",
      "Test ACC score: 0.6816220880069025\n",
      "Test F1 score: 0.7351040918880115\n",
      "Epoch: 0141 train_loss= 0.72362 val_roc= 0.79070 val_ap= 0.80587\n",
      "Epoch: 0142 train_loss= 0.72436 val_roc= 0.79177 val_ap= 0.80666\n",
      "Epoch: 0143 train_loss= 0.71764 val_roc= 0.79263 val_ap= 0.80746\n",
      "Epoch: 0144 train_loss= 0.72569 val_roc= 0.79330 val_ap= 0.80810\n",
      "Epoch: 0145 train_loss= 0.71991 val_roc= 0.79406 val_ap= 0.80875\n",
      "Epoch: 0146 train_loss= 0.72030 val_roc= 0.79429 val_ap= 0.80884\n",
      "Epoch: 0147 train_loss= 0.72136 val_roc= 0.79462 val_ap= 0.80896\n",
      "Epoch: 0148 train_loss= 0.71868 val_roc= 0.79500 val_ap= 0.80907\n",
      "Epoch: 0149 train_loss= 0.72886 val_roc= 0.79588 val_ap= 0.80973\n",
      "Epoch: 0150 train_loss= 0.72115 val_roc= 0.79661 val_ap= 0.81017\n",
      "Test AP score: 0.8304727091122117\n",
      "Test ROC score: 0.8135364082422071\n",
      "Test ACC score: 0.6807592752372735\n",
      "Test F1 score: 0.7353361945636624\n",
      "Epoch: 0151 train_loss= 0.72498 val_roc= 0.79750 val_ap= 0.81086\n",
      "Epoch: 0152 train_loss= 0.72245 val_roc= 0.79906 val_ap= 0.81200\n",
      "Epoch: 0153 train_loss= 0.72569 val_roc= 0.80045 val_ap= 0.81278\n",
      "Epoch: 0154 train_loss= 0.72182 val_roc= 0.80152 val_ap= 0.81345\n",
      "Epoch: 0155 train_loss= 0.72652 val_roc= 0.80211 val_ap= 0.81385\n",
      "Epoch: 0156 train_loss= 0.72900 val_roc= 0.80301 val_ap= 0.81441\n",
      "Epoch: 0157 train_loss= 0.72316 val_roc= 0.80410 val_ap= 0.81534\n",
      "Epoch: 0158 train_loss= 0.71942 val_roc= 0.80490 val_ap= 0.81606\n",
      "Epoch: 0159 train_loss= 0.72358 val_roc= 0.80562 val_ap= 0.81686\n",
      "Epoch: 0160 train_loss= 0.72186 val_roc= 0.80682 val_ap= 0.81794\n",
      "Test AP score: 0.8379652008847743\n",
      "Test ROC score: 0.8239191948668968\n",
      "Test ACC score: 0.6773080241587576\n",
      "Test F1 score: 0.7373595505617978\n",
      "Epoch: 0161 train_loss= 0.72411 val_roc= 0.80793 val_ap= 0.81892\n",
      "Epoch: 0162 train_loss= 0.71812 val_roc= 0.80901 val_ap= 0.81966\n",
      "Epoch: 0163 train_loss= 0.72467 val_roc= 0.81000 val_ap= 0.82025\n",
      "Epoch: 0164 train_loss= 0.72139 val_roc= 0.81075 val_ap= 0.82084\n",
      "Epoch: 0165 train_loss= 0.72244 val_roc= 0.81201 val_ap= 0.82194\n",
      "Epoch: 0166 train_loss= 0.71681 val_roc= 0.81270 val_ap= 0.82265\n",
      "Epoch: 0167 train_loss= 0.72170 val_roc= 0.81333 val_ap= 0.82314\n",
      "Epoch: 0168 train_loss= 0.72333 val_roc= 0.81456 val_ap= 0.82428\n",
      "Epoch: 0169 train_loss= 0.72116 val_roc= 0.81568 val_ap= 0.82524\n",
      "Epoch: 0170 train_loss= 0.71735 val_roc= 0.81673 val_ap= 0.82627\n",
      "Test AP score: 0.846001995385691\n",
      "Test ROC score: 0.8338128805514259\n",
      "Test ACC score: 0.6691113028472822\n",
      "Test F1 score: 0.7341421143847489\n",
      "Epoch: 0171 train_loss= 0.72323 val_roc= 0.81786 val_ap= 0.82731\n",
      "Epoch: 0172 train_loss= 0.72121 val_roc= 0.81872 val_ap= 0.82801\n",
      "Epoch: 0173 train_loss= 0.71810 val_roc= 0.81946 val_ap= 0.82880\n",
      "Epoch: 0174 train_loss= 0.71872 val_roc= 0.81987 val_ap= 0.82904\n",
      "Epoch: 0175 train_loss= 0.71910 val_roc= 0.82084 val_ap= 0.82988\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0176 train_loss= 0.71786 val_roc= 0.82170 val_ap= 0.83048\n",
      "Epoch: 0177 train_loss= 0.71741 val_roc= 0.82287 val_ap= 0.83159\n",
      "Epoch: 0178 train_loss= 0.71608 val_roc= 0.82428 val_ap= 0.83285\n",
      "Epoch: 0179 train_loss= 0.71461 val_roc= 0.82551 val_ap= 0.83417\n",
      "Epoch: 0180 train_loss= 0.71572 val_roc= 0.82647 val_ap= 0.83515\n",
      "Test AP score: 0.8544878604634787\n",
      "Test ROC score: 0.8434623879888125\n",
      "Test ACC score: 0.6708369283865401\n",
      "Test F1 score: 0.7369872457773182\n",
      "Epoch: 0181 train_loss= 0.71716 val_roc= 0.82743 val_ap= 0.83623\n",
      "Epoch: 0182 train_loss= 0.71166 val_roc= 0.82855 val_ap= 0.83734\n",
      "Epoch: 0183 train_loss= 0.71482 val_roc= 0.82900 val_ap= 0.83809\n",
      "Epoch: 0184 train_loss= 0.71381 val_roc= 0.82948 val_ap= 0.83886\n",
      "Epoch: 0185 train_loss= 0.71279 val_roc= 0.83009 val_ap= 0.84002\n",
      "Epoch: 0186 train_loss= 0.71092 val_roc= 0.83063 val_ap= 0.84097\n",
      "Epoch: 0187 train_loss= 0.70654 val_roc= 0.83107 val_ap= 0.84171\n",
      "Epoch: 0188 train_loss= 0.71248 val_roc= 0.83154 val_ap= 0.84246\n",
      "Epoch: 0189 train_loss= 0.70815 val_roc= 0.83164 val_ap= 0.84297\n",
      "Epoch: 0190 train_loss= 0.70942 val_roc= 0.83180 val_ap= 0.84347\n",
      "Test AP score: 0.8641181718861408\n",
      "Test ROC score: 0.8515277146032736\n",
      "Test ACC score: 0.6708369283865401\n",
      "Test F1 score: 0.7357118115691029\n",
      "Epoch: 0191 train_loss= 0.70617 val_roc= 0.83188 val_ap= 0.84373\n",
      "Epoch: 0192 train_loss= 0.70853 val_roc= 0.83193 val_ap= 0.84415\n",
      "Epoch: 0193 train_loss= 0.70321 val_roc= 0.83195 val_ap= 0.84440\n",
      "Epoch: 0194 train_loss= 0.70209 val_roc= 0.83213 val_ap= 0.84496\n",
      "Epoch: 0195 train_loss= 0.70711 val_roc= 0.83227 val_ap= 0.84581\n",
      "Epoch: 0196 train_loss= 0.70013 val_roc= 0.83240 val_ap= 0.84674\n",
      "Epoch: 0197 train_loss= 0.69794 val_roc= 0.83255 val_ap= 0.84778\n",
      "Epoch: 0198 train_loss= 0.69614 val_roc= 0.83237 val_ap= 0.84809\n",
      "Epoch: 0199 train_loss= 0.69404 val_roc= 0.83186 val_ap= 0.84800\n",
      "Epoch: 0200 train_loss= 0.70013 val_roc= 0.83155 val_ap= 0.84784\n",
      "Test AP score: 0.869044323743593\n",
      "Test ROC score: 0.852601950001526\n",
      "Test ACC score: 0.676876617773943\n",
      "Test F1 score: 0.7383863080684596\n"
     ]
    }
   ],
   "source": [
    "runner.erun()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8bd9e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf1.15",
   "language": "python",
   "name": "tf1.15"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
