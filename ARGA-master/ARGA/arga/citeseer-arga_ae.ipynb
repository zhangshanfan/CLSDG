{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65775001",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-08T13:21:59.771671Z",
     "start_time": "2022-05-08T13:21:55.732583Z"
    }
   },
   "outputs": [],
   "source": [
    "import settings\n",
    "from link_prediction import Link_pred_Runner\n",
    "dataname = 'citeseer'       # 'cora' or 'wiki' or 'email' or 'citeseer'\n",
    "model = 'arga_ae'     # 'arga_ae' or 'arga_vae'\n",
    "task = 'link_prediction'         # 'clustering' or 'link_prediction'\n",
    "settings = settings.get_settings(dataname, model, task)\n",
    "runner = Link_pred_Runner(settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "254bd93d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-08T13:31:54.272778Z",
     "start_time": "2022-05-08T13:22:03.002074Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\zhangshanfan\\Desktop\\对比方法\\ARGA-master\\ARGA\\arga\\model.py:143: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\zhangshanfan\\Desktop\\对比方法\\ARGA-master\\ARGA\\arga\\model.py:145: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\zhangshanfan\\Desktop\\对比方法\\ARGA-master\\ARGA\\arga\\model.py:147: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\zhangshanfan\\Desktop\\对比方法\\ARGA-master\\ARGA\\arga\\layers.py:27: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\zhangshanfan\\Desktop\\对比方法\\ARGA-master\\ARGA\\arga\\layers.py:101: The name tf.sparse_tensor_dense_matmul is deprecated. Please use tf.sparse.sparse_dense_matmul instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\zhangshanfan\\Desktop\\对比方法\\ARGA-master\\ARGA\\arga\\layers.py:79: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\zhangshanfan\\.conda\\envs\\tf1.x\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\zhangshanfan\\Desktop\\对比方法\\ARGA-master\\ARGA\\arga\\optimizer.py:28: calling weighted_cross_entropy_with_logits (from tensorflow.python.ops.nn_impl) with targets is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "targets is deprecated, use labels instead\n",
      "WARNING:tensorflow:From C:\\Users\\zhangshanfan\\Desktop\\对比方法\\ARGA-master\\ARGA\\arga\\optimizer.py:37: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\zhangshanfan\\Desktop\\对比方法\\ARGA-master\\ARGA\\arga\\optimizer.py:38: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "Epoch: 0001 train_loss= 0.81526 val_roc= 0.52553 val_ap= 0.51828\n",
      "Epoch: 0002 train_loss= 0.81494 val_roc= 0.58484 val_ap= 0.58504\n",
      "Epoch: 0003 train_loss= 0.81362 val_roc= 0.57459 val_ap= 0.55859\n",
      "Epoch: 0004 train_loss= 0.81277 val_roc= 0.56898 val_ap= 0.55203\n",
      "Epoch: 0005 train_loss= 0.81110 val_roc= 0.58829 val_ap= 0.59208\n",
      "Epoch: 0006 train_loss= 0.81022 val_roc= 0.55959 val_ap= 0.55901\n",
      "Epoch: 0007 train_loss= 0.80865 val_roc= 0.54239 val_ap= 0.55160\n",
      "Epoch: 0008 train_loss= 0.80704 val_roc= 0.59258 val_ap= 0.60027\n",
      "Epoch: 0009 train_loss= 0.80618 val_roc= 0.52506 val_ap= 0.53753\n",
      "Epoch: 0010 train_loss= 0.80375 val_roc= 0.58779 val_ap= 0.61795\n",
      "Test AP score: 0.6166272523813101\n",
      "Test ROC score: 0.624262770196836\n",
      "Epoch: 0011 train_loss= 0.80199 val_roc= 0.55274 val_ap= 0.56211\n",
      "Epoch: 0012 train_loss= 0.80069 val_roc= 0.62080 val_ap= 0.61980\n",
      "Epoch: 0013 train_loss= 0.79656 val_roc= 0.57160 val_ap= 0.59301\n",
      "Epoch: 0014 train_loss= 0.79324 val_roc= 0.65419 val_ap= 0.67040\n",
      "Epoch: 0015 train_loss= 0.79056 val_roc= 0.65406 val_ap= 0.66286\n",
      "Epoch: 0016 train_loss= 0.78547 val_roc= 0.65920 val_ap= 0.71616\n",
      "Epoch: 0017 train_loss= 0.77759 val_roc= 0.66128 val_ap= 0.70579\n",
      "Epoch: 0018 train_loss= 0.76979 val_roc= 0.63822 val_ap= 0.68055\n",
      "Epoch: 0019 train_loss= 0.76209 val_roc= 0.67772 val_ap= 0.72599\n",
      "Epoch: 0020 train_loss= 0.75015 val_roc= 0.68781 val_ap= 0.75159\n",
      "Test AP score: 0.739246779824802\n",
      "Test ROC score: 0.6878975969085859\n",
      "Epoch: 0021 train_loss= 0.74068 val_roc= 0.68460 val_ap= 0.73940\n",
      "Epoch: 0022 train_loss= 0.73048 val_roc= 0.68437 val_ap= 0.74678\n",
      "Epoch: 0023 train_loss= 0.71603 val_roc= 0.66516 val_ap= 0.72946\n",
      "Epoch: 0024 train_loss= 0.70428 val_roc= 0.68216 val_ap= 0.73802\n",
      "Epoch: 0025 train_loss= 0.69355 val_roc= 0.64566 val_ap= 0.71030\n",
      "Epoch: 0026 train_loss= 0.68296 val_roc= 0.68639 val_ap= 0.73729\n",
      "Epoch: 0027 train_loss= 0.67345 val_roc= 0.66429 val_ap= 0.73098\n",
      "Epoch: 0028 train_loss= 0.66896 val_roc= 0.67942 val_ap= 0.73642\n",
      "Epoch: 0029 train_loss= 0.66038 val_roc= 0.65451 val_ap= 0.71888\n",
      "Epoch: 0030 train_loss= 0.65527 val_roc= 0.67459 val_ap= 0.73451\n",
      "Test AP score: 0.7587868579518887\n",
      "Test ROC score: 0.6933655355633377\n",
      "Epoch: 0031 train_loss= 0.65223 val_roc= 0.71100 val_ap= 0.74759\n",
      "Epoch: 0032 train_loss= 0.64733 val_roc= 0.67773 val_ap= 0.73893\n",
      "Epoch: 0033 train_loss= 0.63689 val_roc= 0.69365 val_ap= 0.74169\n",
      "Epoch: 0034 train_loss= 0.63407 val_roc= 0.69673 val_ap= 0.74234\n",
      "Epoch: 0035 train_loss= 0.62518 val_roc= 0.70816 val_ap= 0.75551\n",
      "Epoch: 0036 train_loss= 0.61979 val_roc= 0.72109 val_ap= 0.76046\n",
      "Epoch: 0037 train_loss= 0.61363 val_roc= 0.69547 val_ap= 0.75631\n",
      "Epoch: 0038 train_loss= 0.60545 val_roc= 0.71174 val_ap= 0.76112\n",
      "Epoch: 0039 train_loss= 0.60020 val_roc= 0.73025 val_ap= 0.77289\n",
      "Epoch: 0040 train_loss= 0.59103 val_roc= 0.72043 val_ap= 0.76671\n",
      "Test AP score: 0.8010768190473633\n",
      "Test ROC score: 0.741214829126917\n",
      "Epoch: 0041 train_loss= 0.58430 val_roc= 0.71762 val_ap= 0.76934\n",
      "Epoch: 0042 train_loss= 0.57841 val_roc= 0.72258 val_ap= 0.77331\n",
      "Epoch: 0043 train_loss= 0.57341 val_roc= 0.71082 val_ap= 0.77588\n",
      "Epoch: 0044 train_loss= 0.56589 val_roc= 0.71750 val_ap= 0.77161\n",
      "Epoch: 0045 train_loss= 0.55809 val_roc= 0.71459 val_ap= 0.77028\n",
      "Epoch: 0046 train_loss= 0.54834 val_roc= 0.71174 val_ap= 0.76438\n",
      "Epoch: 0047 train_loss= 0.54528 val_roc= 0.72276 val_ap= 0.77213\n",
      "Epoch: 0048 train_loss= 0.53849 val_roc= 0.71003 val_ap= 0.77120\n",
      "Epoch: 0049 train_loss= 0.53333 val_roc= 0.73335 val_ap= 0.78233\n",
      "Epoch: 0050 train_loss= 0.52626 val_roc= 0.72421 val_ap= 0.78022\n",
      "Test AP score: 0.8191262240907398\n",
      "Test ROC score: 0.7679120879120879\n",
      "Epoch: 0051 train_loss= 0.52248 val_roc= 0.71078 val_ap= 0.76751\n",
      "Epoch: 0052 train_loss= 0.51708 val_roc= 0.73549 val_ap= 0.78928\n",
      "Epoch: 0053 train_loss= 0.51274 val_roc= 0.72910 val_ap= 0.78512\n",
      "Epoch: 0054 train_loss= 0.50680 val_roc= 0.71824 val_ap= 0.77327\n",
      "Epoch: 0055 train_loss= 0.50441 val_roc= 0.75216 val_ap= 0.79598\n",
      "Epoch: 0056 train_loss= 0.50056 val_roc= 0.74032 val_ap= 0.79786\n",
      "Epoch: 0057 train_loss= 0.49595 val_roc= 0.74242 val_ap= 0.79244\n",
      "Epoch: 0058 train_loss= 0.49379 val_roc= 0.74641 val_ap= 0.79937\n",
      "Epoch: 0059 train_loss= 0.49083 val_roc= 0.76124 val_ap= 0.80397\n",
      "Epoch: 0060 train_loss= 0.48726 val_roc= 0.75309 val_ap= 0.80060\n",
      "Test AP score: 0.8286764369022281\n",
      "Test ROC score: 0.7852240067624683\n",
      "Epoch: 0061 train_loss= 0.48516 val_roc= 0.75451 val_ap= 0.80546\n",
      "Epoch: 0062 train_loss= 0.48199 val_roc= 0.72941 val_ap= 0.79037\n",
      "Epoch: 0063 train_loss= 0.48013 val_roc= 0.76233 val_ap= 0.81425\n",
      "Epoch: 0064 train_loss= 0.47786 val_roc= 0.78237 val_ap= 0.82861\n",
      "Epoch: 0065 train_loss= 0.47607 val_roc= 0.76817 val_ap= 0.81974\n",
      "Epoch: 0066 train_loss= 0.47363 val_roc= 0.73458 val_ap= 0.79850\n",
      "Epoch: 0067 train_loss= 0.47334 val_roc= 0.76695 val_ap= 0.81139\n",
      "Epoch: 0068 train_loss= 0.47139 val_roc= 0.75967 val_ap= 0.80489\n",
      "Epoch: 0069 train_loss= 0.46964 val_roc= 0.76182 val_ap= 0.81182\n",
      "Epoch: 0070 train_loss= 0.46881 val_roc= 0.76722 val_ap= 0.81463\n",
      "Test AP score: 0.8358436117217481\n",
      "Test ROC score: 0.7899142615626131\n",
      "Epoch: 0071 train_loss= 0.46703 val_roc= 0.77219 val_ap= 0.82138\n",
      "Epoch: 0072 train_loss= 0.46553 val_roc= 0.76041 val_ap= 0.80853\n",
      "Epoch: 0073 train_loss= 0.46453 val_roc= 0.77510 val_ap= 0.82487\n",
      "Epoch: 0074 train_loss= 0.46364 val_roc= 0.76906 val_ap= 0.81987\n",
      "Epoch: 0075 train_loss= 0.46206 val_roc= 0.76489 val_ap= 0.82143\n",
      "Epoch: 0076 train_loss= 0.46107 val_roc= 0.74768 val_ap= 0.81210\n",
      "Epoch: 0077 train_loss= 0.46004 val_roc= 0.76235 val_ap= 0.81563\n",
      "Epoch: 0078 train_loss= 0.45854 val_roc= 0.76400 val_ap= 0.82020\n",
      "Epoch: 0079 train_loss= 0.45710 val_roc= 0.77386 val_ap= 0.82532\n",
      "Epoch: 0080 train_loss= 0.45624 val_roc= 0.75439 val_ap= 0.81273\n",
      "Test AP score: 0.8348586576528543\n",
      "Test ROC score: 0.7915179326168338\n",
      "Epoch: 0081 train_loss= 0.45522 val_roc= 0.76196 val_ap= 0.81820\n",
      "Epoch: 0082 train_loss= 0.45493 val_roc= 0.75610 val_ap= 0.81736\n",
      "Epoch: 0083 train_loss= 0.45379 val_roc= 0.78870 val_ap= 0.83828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0084 train_loss= 0.45348 val_roc= 0.76770 val_ap= 0.82050\n",
      "Epoch: 0085 train_loss= 0.45163 val_roc= 0.78121 val_ap= 0.83120\n",
      "Epoch: 0086 train_loss= 0.45077 val_roc= 0.76460 val_ap= 0.81783\n",
      "Epoch: 0087 train_loss= 0.44988 val_roc= 0.78773 val_ap= 0.83228\n",
      "Epoch: 0088 train_loss= 0.44935 val_roc= 0.77805 val_ap= 0.82932\n",
      "Epoch: 0089 train_loss= 0.44856 val_roc= 0.77015 val_ap= 0.82489\n",
      "Epoch: 0090 train_loss= 0.44741 val_roc= 0.78080 val_ap= 0.83548\n",
      "Test AP score: 0.843163104188835\n",
      "Test ROC score: 0.8006714164955923\n",
      "Epoch: 0091 train_loss= 0.44731 val_roc= 0.78544 val_ap= 0.82915\n",
      "Epoch: 0092 train_loss= 0.44601 val_roc= 0.77681 val_ap= 0.83357\n",
      "Epoch: 0093 train_loss= 0.44537 val_roc= 0.77521 val_ap= 0.82853\n",
      "Epoch: 0094 train_loss= 0.44421 val_roc= 0.78515 val_ap= 0.83282\n",
      "Epoch: 0095 train_loss= 0.44342 val_roc= 0.75094 val_ap= 0.81606\n",
      "Epoch: 0096 train_loss= 0.44253 val_roc= 0.78930 val_ap= 0.83729\n",
      "Epoch: 0097 train_loss= 0.44266 val_roc= 0.75653 val_ap= 0.81796\n",
      "Epoch: 0098 train_loss= 0.44154 val_roc= 0.77209 val_ap= 0.82246\n",
      "Epoch: 0099 train_loss= 0.44115 val_roc= 0.77558 val_ap= 0.82622\n",
      "Epoch: 0100 train_loss= 0.44028 val_roc= 0.79159 val_ap= 0.84042\n",
      "Test AP score: 0.848610736862135\n",
      "Test ROC score: 0.8074435454655235\n",
      "Epoch: 0101 train_loss= 0.43945 val_roc= 0.78730 val_ap= 0.83170\n",
      "Epoch: 0102 train_loss= 0.43894 val_roc= 0.77987 val_ap= 0.83291\n",
      "Epoch: 0103 train_loss= 0.43820 val_roc= 0.77564 val_ap= 0.83400\n",
      "Epoch: 0104 train_loss= 0.43746 val_roc= 0.76252 val_ap= 0.82445\n",
      "Epoch: 0105 train_loss= 0.43740 val_roc= 0.77265 val_ap= 0.83133\n",
      "Epoch: 0106 train_loss= 0.43706 val_roc= 0.78321 val_ap= 0.83314\n",
      "Epoch: 0107 train_loss= 0.43578 val_roc= 0.78540 val_ap= 0.83679\n",
      "Epoch: 0108 train_loss= 0.43537 val_roc= 0.78288 val_ap= 0.83797\n",
      "Epoch: 0109 train_loss= 0.43535 val_roc= 0.77409 val_ap= 0.83235\n",
      "Epoch: 0110 train_loss= 0.43415 val_roc= 0.78841 val_ap= 0.83314\n",
      "Test AP score: 0.8501352441980534\n",
      "Test ROC score: 0.805637000362275\n",
      "Epoch: 0111 train_loss= 0.43433 val_roc= 0.76551 val_ap= 0.82265\n",
      "Epoch: 0112 train_loss= 0.43395 val_roc= 0.80335 val_ap= 0.84952\n",
      "Epoch: 0113 train_loss= 0.43286 val_roc= 0.78837 val_ap= 0.83822\n",
      "Epoch: 0114 train_loss= 0.43292 val_roc= 0.79031 val_ap= 0.83740\n",
      "Epoch: 0115 train_loss= 0.43217 val_roc= 0.79542 val_ap= 0.84475\n",
      "Epoch: 0116 train_loss= 0.43197 val_roc= 0.78930 val_ap= 0.84530\n",
      "Epoch: 0117 train_loss= 0.43159 val_roc= 0.80514 val_ap= 0.84640\n",
      "Epoch: 0118 train_loss= 0.43103 val_roc= 0.79152 val_ap= 0.83744\n",
      "Epoch: 0119 train_loss= 0.43061 val_roc= 0.79792 val_ap= 0.83882\n",
      "Epoch: 0120 train_loss= 0.43036 val_roc= 0.79260 val_ap= 0.84251\n",
      "Test AP score: 0.8472336740440051\n",
      "Test ROC score: 0.7996570462504529\n",
      "Epoch: 0121 train_loss= 0.42971 val_roc= 0.78486 val_ap= 0.83685\n",
      "Epoch: 0122 train_loss= 0.42973 val_roc= 0.76281 val_ap= 0.82631\n",
      "Epoch: 0123 train_loss= 0.42962 val_roc= 0.76871 val_ap= 0.82936\n",
      "Epoch: 0124 train_loss= 0.42881 val_roc= 0.76675 val_ap= 0.82677\n",
      "Epoch: 0125 train_loss= 0.42814 val_roc= 0.79049 val_ap= 0.84258\n",
      "Epoch: 0126 train_loss= 0.42798 val_roc= 0.77448 val_ap= 0.83300\n",
      "Epoch: 0127 train_loss= 0.42782 val_roc= 0.78569 val_ap= 0.83870\n",
      "Epoch: 0128 train_loss= 0.42727 val_roc= 0.78562 val_ap= 0.82996\n",
      "Epoch: 0129 train_loss= 0.42692 val_roc= 0.77556 val_ap= 0.82546\n",
      "Epoch: 0130 train_loss= 0.42675 val_roc= 0.77739 val_ap= 0.82965\n",
      "Test AP score: 0.8552203108865384\n",
      "Test ROC score: 0.8063084168578674\n",
      "Epoch: 0131 train_loss= 0.42666 val_roc= 0.77861 val_ap= 0.83158\n",
      "Epoch: 0132 train_loss= 0.42620 val_roc= 0.77537 val_ap= 0.82884\n",
      "Epoch: 0133 train_loss= 0.42590 val_roc= 0.77011 val_ap= 0.83063\n",
      "Epoch: 0134 train_loss= 0.42515 val_roc= 0.78420 val_ap= 0.84031\n",
      "Epoch: 0135 train_loss= 0.42525 val_roc= 0.77622 val_ap= 0.83156\n",
      "Epoch: 0136 train_loss= 0.42531 val_roc= 0.77809 val_ap= 0.83183\n",
      "Epoch: 0137 train_loss= 0.42437 val_roc= 0.77281 val_ap= 0.83333\n",
      "Epoch: 0138 train_loss= 0.42396 val_roc= 0.78432 val_ap= 0.83744\n",
      "Epoch: 0139 train_loss= 0.42365 val_roc= 0.79881 val_ap= 0.84590\n",
      "Epoch: 0140 train_loss= 0.42363 val_roc= 0.77129 val_ap= 0.82592\n",
      "Test AP score: 0.8593840025494128\n",
      "Test ROC score: 0.8081777563096244\n",
      "Epoch: 0141 train_loss= 0.42320 val_roc= 0.78597 val_ap= 0.83809\n",
      "Epoch: 0142 train_loss= 0.42279 val_roc= 0.79227 val_ap= 0.84408\n",
      "Epoch: 0143 train_loss= 0.42248 val_roc= 0.78890 val_ap= 0.83602\n",
      "Epoch: 0144 train_loss= 0.42213 val_roc= 0.79318 val_ap= 0.84012\n",
      "Epoch: 0145 train_loss= 0.42207 val_roc= 0.79447 val_ap= 0.83920\n",
      "Epoch: 0146 train_loss= 0.42172 val_roc= 0.79132 val_ap= 0.84101\n",
      "Epoch: 0147 train_loss= 0.42150 val_roc= 0.76910 val_ap= 0.83044\n",
      "Epoch: 0148 train_loss= 0.42174 val_roc= 0.78346 val_ap= 0.83234\n",
      "Epoch: 0149 train_loss= 0.42078 val_roc= 0.77430 val_ap= 0.83209\n",
      "Epoch: 0150 train_loss= 0.42127 val_roc= 0.77405 val_ap= 0.83543\n",
      "Test AP score: 0.8625366125306391\n",
      "Test ROC score: 0.8102692911484121\n",
      "Epoch: 0151 train_loss= 0.42058 val_roc= 0.76145 val_ap= 0.82317\n",
      "Epoch: 0152 train_loss= 0.42042 val_roc= 0.79157 val_ap= 0.84244\n",
      "Epoch: 0153 train_loss= 0.42050 val_roc= 0.79524 val_ap= 0.84169\n",
      "Epoch: 0154 train_loss= 0.41991 val_roc= 0.78546 val_ap= 0.83642\n",
      "Epoch: 0155 train_loss= 0.41933 val_roc= 0.76508 val_ap= 0.83360\n",
      "Epoch: 0156 train_loss= 0.41905 val_roc= 0.76237 val_ap= 0.82912\n",
      "Epoch: 0157 train_loss= 0.41883 val_roc= 0.75158 val_ap= 0.81972\n",
      "Epoch: 0158 train_loss= 0.41923 val_roc= 0.78686 val_ap= 0.84001\n",
      "Epoch: 0159 train_loss= 0.41875 val_roc= 0.79379 val_ap= 0.83831\n",
      "Epoch: 0160 train_loss= 0.41865 val_roc= 0.77248 val_ap= 0.83317\n",
      "Test AP score: 0.8439477291830987\n",
      "Test ROC score: 0.7891897113875136\n",
      "Epoch: 0161 train_loss= 0.41824 val_roc= 0.77620 val_ap= 0.83127\n",
      "Epoch: 0162 train_loss= 0.41804 val_roc= 0.77657 val_ap= 0.83510\n",
      "Epoch: 0163 train_loss= 0.41778 val_roc= 0.78529 val_ap= 0.84255\n",
      "Epoch: 0164 train_loss= 0.41768 val_roc= 0.77793 val_ap= 0.83908\n",
      "Epoch: 0165 train_loss= 0.41769 val_roc= 0.78583 val_ap= 0.84025\n",
      "Epoch: 0166 train_loss= 0.41707 val_roc= 0.79252 val_ap= 0.84472\n",
      "Epoch: 0167 train_loss= 0.41673 val_roc= 0.79056 val_ap= 0.84051\n",
      "Epoch: 0168 train_loss= 0.41702 val_roc= 0.77925 val_ap= 0.83730\n",
      "Epoch: 0169 train_loss= 0.41679 val_roc= 0.77512 val_ap= 0.83157\n",
      "Epoch: 0170 train_loss= 0.41618 val_roc= 0.78218 val_ap= 0.83654\n",
      "Test AP score: 0.8419218946821885\n",
      "Test ROC score: 0.7835285593527351\n",
      "Epoch: 0171 train_loss= 0.41651 val_roc= 0.78247 val_ap= 0.84059\n",
      "Epoch: 0172 train_loss= 0.41583 val_roc= 0.77131 val_ap= 0.82852\n",
      "Epoch: 0173 train_loss= 0.41599 val_roc= 0.78579 val_ap= 0.83629\n",
      "Epoch: 0174 train_loss= 0.41560 val_roc= 0.77958 val_ap= 0.83910\n",
      "Epoch: 0175 train_loss= 0.41579 val_roc= 0.76537 val_ap= 0.82683\n",
      "Epoch: 0176 train_loss= 0.41563 val_roc= 0.77537 val_ap= 0.82844\n",
      "Epoch: 0177 train_loss= 0.41531 val_roc= 0.78721 val_ap= 0.84164\n",
      "Epoch: 0178 train_loss= 0.41502 val_roc= 0.77793 val_ap= 0.83496\n",
      "Epoch: 0179 train_loss= 0.41473 val_roc= 0.78239 val_ap= 0.84125\n",
      "Epoch: 0180 train_loss= 0.41485 val_roc= 0.80293 val_ap= 0.85553\n",
      "Test AP score: 0.859772915508742\n",
      "Test ROC score: 0.808960270498732\n",
      "Epoch: 0181 train_loss= 0.41428 val_roc= 0.77997 val_ap= 0.83821\n",
      "Epoch: 0182 train_loss= 0.41421 val_roc= 0.79520 val_ap= 0.84329\n",
      "Epoch: 0183 train_loss= 0.41445 val_roc= 0.79053 val_ap= 0.84190\n",
      "Epoch: 0184 train_loss= 0.41367 val_roc= 0.76974 val_ap= 0.83060\n",
      "Epoch: 0185 train_loss= 0.41379 val_roc= 0.77331 val_ap= 0.83068\n",
      "Epoch: 0186 train_loss= 0.41327 val_roc= 0.76652 val_ap= 0.82656\n",
      "Epoch: 0187 train_loss= 0.41339 val_roc= 0.80139 val_ap= 0.84520\n",
      "Epoch: 0188 train_loss= 0.41306 val_roc= 0.76439 val_ap= 0.82746\n",
      "Epoch: 0189 train_loss= 0.41275 val_roc= 0.79709 val_ap= 0.85118\n",
      "Epoch: 0190 train_loss= 0.41249 val_roc= 0.76258 val_ap= 0.82451\n",
      "Test AP score: 0.8466717727503591\n",
      "Test ROC score: 0.7946914623837701\n",
      "Epoch: 0191 train_loss= 0.41262 val_roc= 0.80584 val_ap= 0.85207\n",
      "Epoch: 0192 train_loss= 0.41237 val_roc= 0.76702 val_ap= 0.82827\n",
      "Epoch: 0193 train_loss= 0.41233 val_roc= 0.77314 val_ap= 0.83095\n",
      "Epoch: 0194 train_loss= 0.41181 val_roc= 0.80510 val_ap= 0.84889\n",
      "Epoch: 0195 train_loss= 0.41191 val_roc= 0.80077 val_ap= 0.84674\n",
      "Epoch: 0196 train_loss= 0.41158 val_roc= 0.77312 val_ap= 0.82875\n",
      "Epoch: 0197 train_loss= 0.41156 val_roc= 0.78839 val_ap= 0.84165\n",
      "Epoch: 0198 train_loss= 0.41115 val_roc= 0.76361 val_ap= 0.82696\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0199 train_loss= 0.41096 val_roc= 0.77257 val_ap= 0.83541\n",
      "Epoch: 0200 train_loss= 0.41048 val_roc= 0.78061 val_ap= 0.83823\n",
      "Test AP score: 0.8651839560317582\n",
      "Test ROC score: 0.8137278106508875\n",
      "Epoch: 0201 train_loss= 0.41063 val_roc= 0.78589 val_ap= 0.84491\n",
      "Epoch: 0202 train_loss= 0.41065 val_roc= 0.77702 val_ap= 0.83208\n",
      "Epoch: 0203 train_loss= 0.41039 val_roc= 0.78915 val_ap= 0.84351\n",
      "Epoch: 0204 train_loss= 0.41038 val_roc= 0.78067 val_ap= 0.83621\n",
      "Epoch: 0205 train_loss= 0.41033 val_roc= 0.77855 val_ap= 0.83609\n",
      "Epoch: 0206 train_loss= 0.40981 val_roc= 0.78321 val_ap= 0.83522\n",
      "Epoch: 0207 train_loss= 0.40959 val_roc= 0.79097 val_ap= 0.84278\n",
      "Epoch: 0208 train_loss= 0.40928 val_roc= 0.77636 val_ap= 0.83776\n",
      "Epoch: 0209 train_loss= 0.40957 val_roc= 0.78453 val_ap= 0.83637\n",
      "Epoch: 0210 train_loss= 0.40894 val_roc= 0.78758 val_ap= 0.84339\n",
      "Test AP score: 0.8482161467766806\n",
      "Test ROC score: 0.7915517449583385\n",
      "Epoch: 0211 train_loss= 0.40957 val_roc= 0.76087 val_ap= 0.82941\n",
      "Epoch: 0212 train_loss= 0.40881 val_roc= 0.78990 val_ap= 0.84050\n",
      "Epoch: 0213 train_loss= 0.40877 val_roc= 0.79194 val_ap= 0.84338\n",
      "Epoch: 0214 train_loss= 0.40846 val_roc= 0.79130 val_ap= 0.84113\n",
      "Epoch: 0215 train_loss= 0.40857 val_roc= 0.78272 val_ap= 0.83948\n",
      "Epoch: 0216 train_loss= 0.40829 val_roc= 0.77944 val_ap= 0.83890\n",
      "Epoch: 0217 train_loss= 0.40810 val_roc= 0.79722 val_ap= 0.84639\n",
      "Epoch: 0218 train_loss= 0.40806 val_roc= 0.79542 val_ap= 0.84470\n",
      "Epoch: 0219 train_loss= 0.40794 val_roc= 0.77337 val_ap= 0.83628\n",
      "Epoch: 0220 train_loss= 0.40763 val_roc= 0.78051 val_ap= 0.83593\n",
      "Test AP score: 0.8555806433566144\n",
      "Test ROC score: 0.8061345248158435\n",
      "Epoch: 0221 train_loss= 0.40767 val_roc= 0.79258 val_ap= 0.84403\n",
      "Epoch: 0222 train_loss= 0.40730 val_roc= 0.76107 val_ap= 0.82827\n",
      "Epoch: 0223 train_loss= 0.40711 val_roc= 0.79974 val_ap= 0.84424\n",
      "Epoch: 0224 train_loss= 0.40658 val_roc= 0.77067 val_ap= 0.83553\n",
      "Epoch: 0225 train_loss= 0.40654 val_roc= 0.78595 val_ap= 0.84307\n",
      "Epoch: 0226 train_loss= 0.40687 val_roc= 0.78849 val_ap= 0.84203\n",
      "Epoch: 0227 train_loss= 0.40667 val_roc= 0.77871 val_ap= 0.83594\n",
      "Epoch: 0228 train_loss= 0.40669 val_roc= 0.77201 val_ap= 0.83466\n",
      "Epoch: 0229 train_loss= 0.40627 val_roc= 0.78408 val_ap= 0.84128\n",
      "Epoch: 0230 train_loss= 0.40597 val_roc= 0.77017 val_ap= 0.83231\n",
      "Test AP score: 0.8572697561968965\n",
      "Test ROC score: 0.8053568409612366\n",
      "Epoch: 0231 train_loss= 0.40620 val_roc= 0.78030 val_ap= 0.83632\n",
      "Epoch: 0232 train_loss= 0.40566 val_roc= 0.77979 val_ap= 0.83751\n",
      "Epoch: 0233 train_loss= 0.40568 val_roc= 0.78624 val_ap= 0.84137\n",
      "Epoch: 0234 train_loss= 0.40550 val_roc= 0.81147 val_ap= 0.85687\n",
      "Epoch: 0235 train_loss= 0.40547 val_roc= 0.76780 val_ap= 0.83586\n",
      "Epoch: 0236 train_loss= 0.40531 val_roc= 0.77444 val_ap= 0.83557\n",
      "Epoch: 0237 train_loss= 0.40527 val_roc= 0.78781 val_ap= 0.84243\n",
      "Epoch: 0238 train_loss= 0.40534 val_roc= 0.79293 val_ap= 0.84943\n",
      "Epoch: 0239 train_loss= 0.40490 val_roc= 0.79055 val_ap= 0.84296\n",
      "Epoch: 0240 train_loss= 0.40478 val_roc= 0.76497 val_ap= 0.82857\n",
      "Test AP score: 0.8513566857990551\n",
      "Test ROC score: 0.7912667552227992\n",
      "Epoch: 0241 train_loss= 0.40483 val_roc= 0.77946 val_ap= 0.83702\n",
      "Epoch: 0242 train_loss= 0.40483 val_roc= 0.78513 val_ap= 0.83863\n",
      "Epoch: 0243 train_loss= 0.40472 val_roc= 0.77939 val_ap= 0.83653\n",
      "Epoch: 0244 train_loss= 0.40461 val_roc= 0.78364 val_ap= 0.83979\n",
      "Epoch: 0245 train_loss= 0.40425 val_roc= 0.77500 val_ap= 0.83507\n",
      "Epoch: 0246 train_loss= 0.40386 val_roc= 0.78016 val_ap= 0.83634\n",
      "Epoch: 0247 train_loss= 0.40383 val_roc= 0.76569 val_ap= 0.83236\n",
      "Epoch: 0248 train_loss= 0.40397 val_roc= 0.77166 val_ap= 0.83253\n",
      "Epoch: 0249 train_loss= 0.40388 val_roc= 0.78781 val_ap= 0.84183\n",
      "Epoch: 0250 train_loss= 0.40364 val_roc= 0.75396 val_ap= 0.82516\n",
      "Test AP score: 0.8549587119953368\n",
      "Test ROC score: 0.8011979229561647\n",
      "Epoch: 0251 train_loss= 0.40331 val_roc= 0.77760 val_ap= 0.83608\n",
      "Epoch: 0252 train_loss= 0.40388 val_roc= 0.76638 val_ap= 0.82931\n",
      "Epoch: 0253 train_loss= 0.40320 val_roc= 0.77450 val_ap= 0.83363\n",
      "Epoch: 0254 train_loss= 0.40322 val_roc= 0.78076 val_ap= 0.83678\n",
      "Epoch: 0255 train_loss= 0.40336 val_roc= 0.76765 val_ap= 0.83204\n",
      "Epoch: 0256 train_loss= 0.40307 val_roc= 0.76815 val_ap= 0.83214\n",
      "Epoch: 0257 train_loss= 0.40328 val_roc= 0.79161 val_ap= 0.84215\n",
      "Epoch: 0258 train_loss= 0.40320 val_roc= 0.80025 val_ap= 0.84962\n",
      "Epoch: 0259 train_loss= 0.40298 val_roc= 0.76475 val_ap= 0.82707\n",
      "Epoch: 0260 train_loss= 0.40277 val_roc= 0.77543 val_ap= 0.83592\n",
      "Test AP score: 0.8573467456089325\n",
      "Test ROC score: 0.8017727327617438\n",
      "Epoch: 0261 train_loss= 0.40250 val_roc= 0.77285 val_ap= 0.83169\n",
      "Epoch: 0262 train_loss= 0.40234 val_roc= 0.77954 val_ap= 0.83610\n",
      "Epoch: 0263 train_loss= 0.40220 val_roc= 0.76943 val_ap= 0.82931\n",
      "Epoch: 0264 train_loss= 0.40235 val_roc= 0.77256 val_ap= 0.83269\n",
      "Epoch: 0265 train_loss= 0.40250 val_roc= 0.77279 val_ap= 0.83380\n",
      "Epoch: 0266 train_loss= 0.40224 val_roc= 0.76770 val_ap= 0.83124\n",
      "Epoch: 0267 train_loss= 0.40158 val_roc= 0.75837 val_ap= 0.82719\n",
      "Epoch: 0268 train_loss= 0.40193 val_roc= 0.78476 val_ap= 0.84023\n",
      "Epoch: 0269 train_loss= 0.40194 val_roc= 0.76780 val_ap= 0.83095\n",
      "Epoch: 0270 train_loss= 0.40189 val_roc= 0.78387 val_ap= 0.83889\n",
      "Test AP score: 0.8508711794474838\n",
      "Test ROC score: 0.7949039971017993\n",
      "Epoch: 0271 train_loss= 0.40170 val_roc= 0.75497 val_ap= 0.82217\n",
      "Epoch: 0272 train_loss= 0.40151 val_roc= 0.74676 val_ap= 0.81998\n",
      "Epoch: 0273 train_loss= 0.40170 val_roc= 0.77506 val_ap= 0.83146\n",
      "Epoch: 0274 train_loss= 0.40145 val_roc= 0.77061 val_ap= 0.83074\n",
      "Epoch: 0275 train_loss= 0.40156 val_roc= 0.77108 val_ap= 0.83183\n",
      "Epoch: 0276 train_loss= 0.40138 val_roc= 0.75295 val_ap= 0.82221\n",
      "Epoch: 0277 train_loss= 0.40148 val_roc= 0.77500 val_ap= 0.83202\n",
      "Epoch: 0278 train_loss= 0.40121 val_roc= 0.77314 val_ap= 0.83049\n",
      "Epoch: 0279 train_loss= 0.40140 val_roc= 0.77826 val_ap= 0.83613\n",
      "Epoch: 0280 train_loss= 0.40100 val_roc= 0.78610 val_ap= 0.84201\n",
      "Test AP score: 0.8549623740038125\n",
      "Test ROC score: 0.8029658253834078\n",
      "Epoch: 0281 train_loss= 0.40088 val_roc= 0.75381 val_ap= 0.82433\n",
      "Epoch: 0282 train_loss= 0.40105 val_roc= 0.77832 val_ap= 0.83462\n",
      "Epoch: 0283 train_loss= 0.40091 val_roc= 0.76735 val_ap= 0.83275\n",
      "Epoch: 0284 train_loss= 0.40115 val_roc= 0.77341 val_ap= 0.83143\n",
      "Epoch: 0285 train_loss= 0.40096 val_roc= 0.77904 val_ap= 0.83472\n",
      "Epoch: 0286 train_loss= 0.40090 val_roc= 0.77420 val_ap= 0.83380\n",
      "Epoch: 0287 train_loss= 0.40064 val_roc= 0.77948 val_ap= 0.83510\n",
      "Epoch: 0288 train_loss= 0.40044 val_roc= 0.76679 val_ap= 0.83014\n",
      "Epoch: 0289 train_loss= 0.40037 val_roc= 0.78461 val_ap= 0.83876\n",
      "Epoch: 0290 train_loss= 0.40038 val_roc= 0.77166 val_ap= 0.83051\n",
      "Test AP score: 0.8653863108777541\n",
      "Test ROC score: 0.8189252505736022\n",
      "Epoch: 0291 train_loss= 0.40042 val_roc= 0.77308 val_ap= 0.83476\n",
      "Epoch: 0292 train_loss= 0.40012 val_roc= 0.77780 val_ap= 0.83277\n",
      "Epoch: 0293 train_loss= 0.40019 val_roc= 0.76860 val_ap= 0.83350\n",
      "Epoch: 0294 train_loss= 0.39970 val_roc= 0.75740 val_ap= 0.82520\n",
      "Epoch: 0295 train_loss= 0.40002 val_roc= 0.76755 val_ap= 0.83274\n",
      "Epoch: 0296 train_loss= 0.40009 val_roc= 0.77413 val_ap= 0.83302\n",
      "Epoch: 0297 train_loss= 0.39977 val_roc= 0.76699 val_ap= 0.83051\n",
      "Epoch: 0298 train_loss= 0.39990 val_roc= 0.78643 val_ap= 0.83869\n",
      "Epoch: 0299 train_loss= 0.39998 val_roc= 0.76083 val_ap= 0.82967\n",
      "Epoch: 0300 train_loss= 0.39997 val_roc= 0.80027 val_ap= 0.84970\n",
      "Test AP score: 0.8503514461509242\n",
      "Test ROC score: 0.7911701485327858\n",
      "Epoch: 0301 train_loss= 0.39944 val_roc= 0.77434 val_ap= 0.83465\n",
      "Epoch: 0302 train_loss= 0.39941 val_roc= 0.76675 val_ap= 0.82947\n",
      "Epoch: 0303 train_loss= 0.39950 val_roc= 0.77498 val_ap= 0.83356\n",
      "Epoch: 0304 train_loss= 0.39944 val_roc= 0.77552 val_ap= 0.83443\n",
      "Epoch: 0305 train_loss= 0.39897 val_roc= 0.78080 val_ap= 0.83788\n",
      "Epoch: 0306 train_loss= 0.39914 val_roc= 0.79408 val_ap= 0.84559\n",
      "Epoch: 0307 train_loss= 0.39938 val_roc= 0.77021 val_ap= 0.83229\n",
      "Epoch: 0308 train_loss= 0.39893 val_roc= 0.78806 val_ap= 0.84351\n",
      "Epoch: 0309 train_loss= 0.39887 val_roc= 0.76844 val_ap= 0.83468\n",
      "Epoch: 0310 train_loss= 0.39905 val_roc= 0.79223 val_ap= 0.84744\n",
      "Test AP score: 0.8514691125674663\n",
      "Test ROC score: 0.7957686269774182\n",
      "Epoch: 0311 train_loss= 0.39875 val_roc= 0.77275 val_ap= 0.83081\n",
      "Epoch: 0312 train_loss= 0.39876 val_roc= 0.79101 val_ap= 0.84458\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0313 train_loss= 0.39867 val_roc= 0.75833 val_ap= 0.82712\n",
      "Epoch: 0314 train_loss= 0.39847 val_roc= 0.75503 val_ap= 0.82539\n",
      "Epoch: 0315 train_loss= 0.39866 val_roc= 0.77585 val_ap= 0.83701\n",
      "Epoch: 0316 train_loss= 0.39845 val_roc= 0.76673 val_ap= 0.83327\n",
      "Epoch: 0317 train_loss= 0.39823 val_roc= 0.79743 val_ap= 0.84753\n",
      "Epoch: 0318 train_loss= 0.39828 val_roc= 0.79299 val_ap= 0.84654\n",
      "Epoch: 0319 train_loss= 0.39838 val_roc= 0.77322 val_ap= 0.83354\n",
      "Epoch: 0320 train_loss= 0.39863 val_roc= 0.78465 val_ap= 0.84103\n",
      "Test AP score: 0.853275418666965\n",
      "Test ROC score: 0.799971017992996\n",
      "Epoch: 0321 train_loss= 0.39837 val_roc= 0.76056 val_ap= 0.82683\n",
      "Epoch: 0322 train_loss= 0.39785 val_roc= 0.75530 val_ap= 0.82362\n",
      "Epoch: 0323 train_loss= 0.39812 val_roc= 0.75926 val_ap= 0.82765\n",
      "Epoch: 0324 train_loss= 0.39814 val_roc= 0.78727 val_ap= 0.84090\n",
      "Epoch: 0325 train_loss= 0.39797 val_roc= 0.77079 val_ap= 0.83314\n",
      "Epoch: 0326 train_loss= 0.39773 val_roc= 0.78827 val_ap= 0.84667\n",
      "Epoch: 0327 train_loss= 0.39777 val_roc= 0.80626 val_ap= 0.84778\n",
      "Epoch: 0328 train_loss= 0.39768 val_roc= 0.77391 val_ap= 0.83665\n",
      "Epoch: 0329 train_loss= 0.39796 val_roc= 0.78319 val_ap= 0.84024\n",
      "Epoch: 0330 train_loss= 0.39763 val_roc= 0.79555 val_ap= 0.84654\n",
      "Test AP score: 0.8585397348976236\n",
      "Test ROC score: 0.8072599927544982\n",
      "Epoch: 0331 train_loss= 0.39774 val_roc= 0.78730 val_ap= 0.84204\n",
      "Epoch: 0332 train_loss= 0.39773 val_roc= 0.80110 val_ap= 0.85169\n",
      "Epoch: 0333 train_loss= 0.39764 val_roc= 0.78635 val_ap= 0.84098\n",
      "Epoch: 0334 train_loss= 0.39720 val_roc= 0.77139 val_ap= 0.83726\n",
      "Epoch: 0335 train_loss= 0.39708 val_roc= 0.80430 val_ap= 0.85071\n",
      "Epoch: 0336 train_loss= 0.39715 val_roc= 0.75654 val_ap= 0.82577\n",
      "Epoch: 0337 train_loss= 0.39719 val_roc= 0.78422 val_ap= 0.84286\n",
      "Epoch: 0338 train_loss= 0.39709 val_roc= 0.78410 val_ap= 0.84510\n",
      "Epoch: 0339 train_loss= 0.39702 val_roc= 0.78377 val_ap= 0.84047\n",
      "Epoch: 0340 train_loss= 0.39733 val_roc= 0.76334 val_ap= 0.83115\n",
      "Test AP score: 0.8572107928642716\n",
      "Test ROC score: 0.8050815118946987\n",
      "Epoch: 0341 train_loss= 0.39689 val_roc= 0.77787 val_ap= 0.83431\n",
      "Epoch: 0342 train_loss= 0.39701 val_roc= 0.78236 val_ap= 0.83755\n",
      "Epoch: 0343 train_loss= 0.39683 val_roc= 0.77801 val_ap= 0.83581\n",
      "Epoch: 0344 train_loss= 0.39703 val_roc= 0.77089 val_ap= 0.82938\n",
      "Epoch: 0345 train_loss= 0.39683 val_roc= 0.77576 val_ap= 0.83589\n",
      "Epoch: 0346 train_loss= 0.39687 val_roc= 0.79505 val_ap= 0.84588\n",
      "Epoch: 0347 train_loss= 0.39671 val_roc= 0.79447 val_ap= 0.84724\n",
      "Epoch: 0348 train_loss= 0.39688 val_roc= 0.78069 val_ap= 0.84000\n",
      "Epoch: 0349 train_loss= 0.39683 val_roc= 0.77842 val_ap= 0.84101\n",
      "Epoch: 0350 train_loss= 0.39664 val_roc= 0.74092 val_ap= 0.81919\n",
      "Test AP score: 0.843123196188592\n",
      "Test ROC score: 0.7793068469991546\n",
      "Epoch: 0351 train_loss= 0.39635 val_roc= 0.77415 val_ap= 0.83882\n",
      "Epoch: 0352 train_loss= 0.39685 val_roc= 0.78115 val_ap= 0.84169\n",
      "Epoch: 0353 train_loss= 0.39647 val_roc= 0.77599 val_ap= 0.83673\n",
      "Epoch: 0354 train_loss= 0.39651 val_roc= 0.76495 val_ap= 0.83405\n",
      "Epoch: 0355 train_loss= 0.39657 val_roc= 0.78546 val_ap= 0.84405\n",
      "Epoch: 0356 train_loss= 0.39623 val_roc= 0.78470 val_ap= 0.84293\n",
      "Epoch: 0357 train_loss= 0.39662 val_roc= 0.77737 val_ap= 0.83895\n",
      "Epoch: 0358 train_loss= 0.39648 val_roc= 0.80203 val_ap= 0.84843\n",
      "Epoch: 0359 train_loss= 0.39622 val_roc= 0.76576 val_ap= 0.82964\n",
      "Epoch: 0360 train_loss= 0.39624 val_roc= 0.77343 val_ap= 0.83544\n",
      "Test AP score: 0.8589312547633138\n",
      "Test ROC score: 0.8085786740731797\n",
      "Epoch: 0361 train_loss= 0.39615 val_roc= 0.78282 val_ap= 0.84022\n",
      "Epoch: 0362 train_loss= 0.39623 val_roc= 0.79534 val_ap= 0.84582\n",
      "Epoch: 0363 train_loss= 0.39613 val_roc= 0.77962 val_ap= 0.84061\n",
      "Epoch: 0364 train_loss= 0.39646 val_roc= 0.79811 val_ap= 0.84832\n",
      "Epoch: 0365 train_loss= 0.39613 val_roc= 0.78527 val_ap= 0.84187\n",
      "Epoch: 0366 train_loss= 0.39587 val_roc= 0.79202 val_ap= 0.84449\n",
      "Epoch: 0367 train_loss= 0.39611 val_roc= 0.76819 val_ap= 0.83641\n",
      "Epoch: 0368 train_loss= 0.39628 val_roc= 0.77582 val_ap= 0.83233\n",
      "Epoch: 0369 train_loss= 0.39623 val_roc= 0.79468 val_ap= 0.84581\n",
      "Epoch: 0370 train_loss= 0.39636 val_roc= 0.77671 val_ap= 0.83426\n",
      "Test AP score: 0.8568649603727527\n",
      "Test ROC score: 0.8055259026687598\n",
      "Epoch: 0371 train_loss= 0.39594 val_roc= 0.78193 val_ap= 0.84116\n",
      "Epoch: 0372 train_loss= 0.39598 val_roc= 0.77933 val_ap= 0.83655\n",
      "Epoch: 0373 train_loss= 0.39617 val_roc= 0.77616 val_ap= 0.83475\n",
      "Epoch: 0374 train_loss= 0.39610 val_roc= 0.77878 val_ap= 0.83819\n",
      "Epoch: 0375 train_loss= 0.39561 val_roc= 0.76916 val_ap= 0.83303\n",
      "Epoch: 0376 train_loss= 0.39585 val_roc= 0.78983 val_ap= 0.84406\n",
      "Epoch: 0377 train_loss= 0.39599 val_roc= 0.79070 val_ap= 0.84436\n",
      "Epoch: 0378 train_loss= 0.39595 val_roc= 0.78336 val_ap= 0.84398\n",
      "Epoch: 0379 train_loss= 0.39599 val_roc= 0.80165 val_ap= 0.85278\n",
      "Epoch: 0380 train_loss= 0.39572 val_roc= 0.77917 val_ap= 0.84158\n",
      "Test AP score: 0.8542470200036429\n",
      "Test ROC score: 0.8021833111943002\n",
      "Epoch: 0381 train_loss= 0.39571 val_roc= 0.79751 val_ap= 0.84877\n",
      "Epoch: 0382 train_loss= 0.39565 val_roc= 0.78806 val_ap= 0.84509\n",
      "Epoch: 0383 train_loss= 0.39560 val_roc= 0.78893 val_ap= 0.84690\n",
      "Epoch: 0384 train_loss= 0.39596 val_roc= 0.78455 val_ap= 0.83801\n",
      "Epoch: 0385 train_loss= 0.39608 val_roc= 0.78117 val_ap= 0.83848\n",
      "Epoch: 0386 train_loss= 0.39559 val_roc= 0.80295 val_ap= 0.84753\n",
      "Epoch: 0387 train_loss= 0.39560 val_roc= 0.80104 val_ap= 0.85196\n",
      "Epoch: 0388 train_loss= 0.39563 val_roc= 0.77948 val_ap= 0.83573\n",
      "Epoch: 0389 train_loss= 0.39549 val_roc= 0.79340 val_ap= 0.84895\n",
      "Epoch: 0390 train_loss= 0.39549 val_roc= 0.77906 val_ap= 0.83889\n",
      "Test AP score: 0.8482950008634467\n",
      "Test ROC score: 0.790377973674677\n",
      "Epoch: 0391 train_loss= 0.39549 val_roc= 0.80533 val_ap= 0.85275\n",
      "Epoch: 0392 train_loss= 0.39522 val_roc= 0.77694 val_ap= 0.83669\n",
      "Epoch: 0393 train_loss= 0.39549 val_roc= 0.80656 val_ap= 0.85485\n",
      "Epoch: 0394 train_loss= 0.39538 val_roc= 0.77900 val_ap= 0.83655\n",
      "Epoch: 0395 train_loss= 0.39512 val_roc= 0.79924 val_ap= 0.84648\n",
      "Epoch: 0396 train_loss= 0.39539 val_roc= 0.77789 val_ap= 0.83855\n",
      "Epoch: 0397 train_loss= 0.39532 val_roc= 0.79377 val_ap= 0.83870\n",
      "Epoch: 0398 train_loss= 0.39556 val_roc= 0.80374 val_ap= 0.85057\n",
      "Epoch: 0399 train_loss= 0.39521 val_roc= 0.78752 val_ap= 0.84581\n",
      "Epoch: 0400 train_loss= 0.39523 val_roc= 0.80040 val_ap= 0.84868\n",
      "Test AP score: 0.851270416510461\n",
      "Test ROC score: 0.7942567322787103\n"
     ]
    }
   ],
   "source": [
    "runner.erun()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c11174",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf1.15",
   "language": "python",
   "name": "tf1.15"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
