{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66dcbabb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-08T13:00:31.149516Z",
     "start_time": "2022-05-08T13:00:23.716856Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import os, sys\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=RuntimeWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "#sys.path.append(os.path.join(os.path.dirname(os.path.realpath(__file__)), os.pardir))\n",
    "# For replicating the experiments\n",
    "SEED = 42\n",
    "import argparse\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import torch\n",
    "\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from model import LinTrans, LogReg\n",
    "from optimizer import loss_function\n",
    "from utils import *\n",
    "from sklearn.cluster import SpectralClustering, KMeans\n",
    "from clustering_metric import clustering_metrics\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import normalize, MinMaxScaler\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, f1_score, average_precision_score, roc_auc_score\n",
    "import pandas as pd\n",
    "from torch_geometric.datasets import Planetoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "461e64b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-08T13:00:31.196096Z",
     "start_time": "2022-05-08T13:00:31.182745Z"
    }
   },
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--gnnlayers', type=int, default=1, help=\"Number of gnn layers\")\n",
    "parser.add_argument('--linlayers', type=int, default=1, help=\"Number of hidden layers\")\n",
    "parser.add_argument('--epochs', type=int, default=300, help='Number of epochs to train.')\n",
    "parser.add_argument('--dims', type=int, default=[500], help='Number of units in hidden layer 1.')\n",
    "parser.add_argument('--lr', type=float, default=0.001, help='Initial learning rate.')\n",
    "parser.add_argument('--upth_st', type=float, default=0.0011, help='Upper Threshold start.')\n",
    "parser.add_argument('--lowth_st', type=float, default=0.1, help='Lower Threshold start.')\n",
    "parser.add_argument('--upth_ed', type=float, default=0.001, help='Upper Threshold end.')\n",
    "parser.add_argument('--lowth_ed', type=float, default=0.5, help='Lower Threshold end.')\n",
    "parser.add_argument('--upd', type=int, default=10, help='Update epoch.')\n",
    "parser.add_argument('--bs', type=int, default=10000, help='Batchsize.')\n",
    "parser.add_argument('--dataset', type=str, default='Citeseer', help='type of dataset.')\n",
    "parser.add_argument('--no-cuda', action='store_true', default=False,\n",
    "                    help='Disables CUDA training.')\n",
    "args,_ = parser.parse_known_args()\n",
    "args.cuda = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ab85f26",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-08T13:00:31.242752Z",
     "start_time": "2022-05-08T13:00:31.228769Z"
    }
   },
   "outputs": [],
   "source": [
    "def update_similarity(z, upper_threshold, lower_treshold, pos_num, neg_num):\n",
    "    f_adj = np.matmul(z, np.transpose(z))\n",
    "    cosine = f_adj\n",
    "    cosine = cosine.reshape([-1,])\n",
    "    pos_num = round(upper_threshold * len(cosine))\n",
    "    neg_num = round((1-lower_treshold) * len(cosine))\n",
    "    \n",
    "    pos_inds = np.argpartition(-cosine, pos_num)[:pos_num]\n",
    "    neg_inds = np.argpartition(cosine, neg_num)[:neg_num]\n",
    "    \n",
    "    return np.array(pos_inds), np.array(neg_inds)\n",
    "\n",
    "def update_threshold(upper_threshold, lower_treshold, up_eta, low_eta):\n",
    "    upth = upper_threshold + up_eta\n",
    "    lowth = lower_treshold + low_eta\n",
    "    return upth, lowth\n",
    "\n",
    "def load_network_data(adj_name):\n",
    "    if adj_name == 'Cora':\n",
    "        nodes_numbers = 2708\n",
    "        datasets = Planetoid('./datasets', adj_name)\n",
    "        edges = datasets[0].edge_index\n",
    "        raw_edges = pd.DataFrame([[edges[0,i].item(), edges[1,i].item()] for i in range(edges.shape[1])])\n",
    "    elif adj_name == 'Citeseer':\n",
    "        nodes_numbers = 3327\n",
    "        datasets = Planetoid('./datasets', adj_name)\n",
    "        edges = datasets[0].edge_index\n",
    "        raw_edges = pd.DataFrame([[edges[0,i].item(), edges[1,i].item()] for i in range(edges.shape[1])])\n",
    "    else:\n",
    "        print(\"Dataset is not exist!\")\n",
    "    \n",
    "    drop_self_loop = raw_edges[raw_edges[0]!=raw_edges[1]]\n",
    "    \n",
    "    graph_np = np.zeros((nodes_numbers, nodes_numbers))\n",
    "    \n",
    "    for i in range(drop_self_loop.shape[0]):\n",
    "        graph_np[drop_self_loop.iloc[i,0], drop_self_loop.iloc[i,1]]=1\n",
    "        graph_np[drop_self_loop.iloc[i,1], drop_self_loop.iloc[i,0]]=1\n",
    "    \n",
    "    adj = nx.adjacency_matrix(nx.from_numpy_matrix(graph_np))\n",
    "    \n",
    "    features = np.eye(nodes_numbers)\n",
    "    \n",
    "    return adj, features\n",
    "\n",
    "def get_scores(emb, adj_orig, edges_pos, edges_neg):\n",
    "    def sigmoid(x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    # Predict on test set of edges\n",
    "    adj_rec = np.dot(emb, emb.T)\n",
    "    preds = []\n",
    "    pos = []\n",
    "    for e in edges_pos:\n",
    "        preds.append(sigmoid(adj_rec[e[0], e[1]]))\n",
    "        pos.append(adj_orig[e[0], e[1]])\n",
    "\n",
    "    preds_neg = []\n",
    "    neg = []\n",
    "    for e in edges_neg:\n",
    "        preds_neg.append(sigmoid(adj_rec[e[0], e[1]]))\n",
    "        neg.append(adj_orig[e[0], e[1]])\n",
    "\n",
    "    preds_all = np.hstack([preds, preds_neg])\n",
    "    labels_all = np.hstack([np.ones(len(preds)), np.zeros(len(preds))])\n",
    "    \n",
    "    roc_score = roc_auc_score(labels_all, preds_all)\n",
    "    ap_score = average_precision_score(labels_all, preds_all)\n",
    "\n",
    "    return roc_score, ap_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "145f35a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-08T13:00:31.305627Z",
     "start_time": "2022-05-08T13:00:31.277466Z"
    }
   },
   "outputs": [],
   "source": [
    "def gae_for(args):\n",
    "    print(\"Using {} dataset\".format(args.dataset))\n",
    "    if args.dataset == 'Cora':\n",
    "        n_clusters = 7\n",
    "        Cluster = SpectralClustering(n_clusters=n_clusters, affinity = 'precomputed', random_state=0)\n",
    "        adj, features = load_network_data(args.dataset)\n",
    "    if args.dataset == 'Citeseer':\n",
    "        n_clusters = 6\n",
    "        Cluster = SpectralClustering(n_clusters=n_clusters, affinity = 'precomputed', random_state=0)\n",
    "        adj, features = load_network_data(args.dataset)\n",
    "\n",
    "    n_nodes, feat_dim = features.shape\n",
    "    dims = [feat_dim] + args.dims\n",
    "    \n",
    "    layers = args.linlayers\n",
    "    # Store original adjacency matrix (without diagonal entries) for later\n",
    "    \n",
    "    adj = adj - sp.dia_matrix((adj.diagonal()[np.newaxis, :], [0]), shape=adj.shape)\n",
    "    adj.eliminate_zeros()\n",
    "    adj_orig = adj\n",
    "\n",
    "    adj_train, train_edges, val_edges, val_edges_false, test_edges, test_edges_false = mask_test_edges(adj)    # val:0.05  test:0.1\n",
    "    adj = adj_train\n",
    "    n = adj.shape[0]\n",
    "\n",
    "    adj_norm_s = preprocess_graph(adj, args.gnnlayers, norm='sym', renorm=True)\n",
    "    sm_fea_s = sp.csr_matrix(features).toarray()\n",
    "    \n",
    "    print('Laplacian Smoothing...')\n",
    "    for a in adj_norm_s:\n",
    "        sm_fea_s = a.dot(sm_fea_s)\n",
    "    adj_1st = (adj + sp.eye(n)).toarray()\n",
    "\n",
    "    adj_label = torch.FloatTensor(adj_1st)\n",
    "    \n",
    "    model = LinTrans(layers, dims)\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
    "    \n",
    "    sm_fea_s = torch.FloatTensor(sm_fea_s)\n",
    "    adj_label = adj_label.reshape([-1,])\n",
    "\n",
    "    inx = sm_fea_s\n",
    "    \n",
    "    pos_num = len(adj.indices)\n",
    "    neg_num = n_nodes*n_nodes-pos_num\n",
    "\n",
    "    up_eta = (args.upth_ed - args.upth_st) / (args.epochs/args.upd)\n",
    "    low_eta = (args.lowth_ed - args.lowth_st) / (args.epochs/args.upd)\n",
    "\n",
    "    pos_inds, neg_inds = update_similarity(normalize(sm_fea_s.numpy()), args.upth_st, args.lowth_st, pos_num, neg_num)\n",
    "    upth, lowth = update_threshold(args.upth_st, args.lowth_st, up_eta, low_eta)\n",
    "\n",
    "    bs = min(args.bs, len(pos_inds))\n",
    "    length = len(pos_inds)\n",
    "    \n",
    "    pos_inds_cuda = torch.LongTensor(pos_inds)\n",
    "    best_lp = 0.\n",
    "    print('Start Training...')\n",
    "    for epoch in range(args.epochs):\n",
    "        st, ed = 0, bs\n",
    "        batch_num = 0\n",
    "        model.train()\n",
    "        length = len(pos_inds)\n",
    "        \n",
    "        while ( ed <= length ):\n",
    "            sampled_neg = torch.LongTensor(np.random.choice(neg_inds, size=ed-st))\n",
    "            sampled_inds = torch.cat((pos_inds_cuda[st:ed], sampled_neg), 0)\n",
    "            t = time.time()\n",
    "            optimizer.zero_grad()\n",
    "            xind = sampled_inds // n_nodes\n",
    "            yind = sampled_inds % n_nodes\n",
    "            x = torch.index_select(inx, 0, xind)\n",
    "            y = torch.index_select(inx, 0, yind)\n",
    "            zx = model(x)\n",
    "            zy = model(y)\n",
    "            batch_label = torch.cat((torch.ones(ed-st), torch.zeros(ed-st)))\n",
    "            batch_pred = model.dcs(zx, zy)\n",
    "            loss = loss_function(adj_preds=batch_pred, adj_labels=batch_label, n_nodes=ed-st)\n",
    "            \n",
    "            loss.backward()\n",
    "            cur_loss = loss.item()\n",
    "            optimizer.step()\n",
    "            \n",
    "            st = ed\n",
    "            batch_num += 1\n",
    "            if ed < length and ed + bs >= length:\n",
    "                ed += length - ed\n",
    "            else:\n",
    "                ed += bs\n",
    "\n",
    "        if (epoch + 1) % args.upd == 0:\n",
    "            model.eval()\n",
    "            mu = model(inx)\n",
    "            hidden_emb = mu.cpu().data.numpy()\n",
    "            upth, lowth = update_threshold(upth, lowth, up_eta, low_eta)\n",
    "            pos_inds, neg_inds = update_similarity(hidden_emb, upth, lowth, pos_num, neg_num)\n",
    "            bs = min(args.bs, len(pos_inds))\n",
    "            pos_inds_cuda = torch.LongTensor(pos_inds)\n",
    "            val_auc, val_ap = get_scores(hidden_emb, adj_orig, val_edges, val_edges_false)\n",
    "            if val_auc + val_ap >= best_lp:\n",
    "                best_lp = val_auc + val_ap\n",
    "                best_emb = hidden_emb\n",
    "            print(\"Epoch: {}, train_loss_gae={:.5f}, val_ap={:.5f}, val_auc={:.5f},time={:.5f}\".format(epoch + 1, cur_loss, val_ap, val_auc, time.time() - t))\n",
    "    \n",
    "    print(\"Optimization Finished!\")\n",
    "    auc_score, ap_score = get_scores(best_emb, adj_orig, test_edges, test_edges_false)\n",
    "    print('Test AP score: ',ap_score)\n",
    "    print('Test AUC score: ',auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af5372b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-08T13:08:15.285230Z",
     "start_time": "2022-05-08T13:00:31.338935Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Citeseer dataset\n",
      "Laplacian Smoothing...\n",
      "Start Training...\n",
      "Epoch: 10, train_loss_gae=0.70828, val_ap=0.83385, val_auc=0.75618,time=0.63792\n",
      "Epoch: 20, train_loss_gae=0.67676, val_ap=0.84716, val_auc=0.78397,time=0.76280\n",
      "Epoch: 30, train_loss_gae=0.66566, val_ap=0.84301, val_auc=0.77193,time=0.74986\n",
      "Epoch: 40, train_loss_gae=0.66002, val_ap=0.83686, val_auc=0.76378,time=0.70220\n",
      "Epoch: 50, train_loss_gae=0.65641, val_ap=0.82796, val_auc=0.75202,time=0.70395\n",
      "Epoch: 60, train_loss_gae=0.65210, val_ap=0.81867, val_auc=0.74506,time=0.61096\n",
      "Epoch: 70, train_loss_gae=0.64698, val_ap=0.81777, val_auc=0.75193,time=0.65274\n",
      "Epoch: 80, train_loss_gae=0.64151, val_ap=0.81687, val_auc=0.76095,time=0.66638\n",
      "Epoch: 90, train_loss_gae=0.63497, val_ap=0.82062, val_auc=0.77126,time=0.61666\n",
      "Epoch: 100, train_loss_gae=0.62692, val_ap=0.83147, val_auc=0.78758,time=0.66372\n",
      "Epoch: 110, train_loss_gae=0.61929, val_ap=0.84925, val_auc=0.80813,time=0.62966\n",
      "Epoch: 120, train_loss_gae=0.61283, val_ap=0.86078, val_auc=0.82101,time=0.64202\n",
      "Epoch: 130, train_loss_gae=0.60750, val_ap=0.87058, val_auc=0.83334,time=0.64874\n",
      "Epoch: 140, train_loss_gae=0.60145, val_ap=0.87572, val_auc=0.84028,time=0.60846\n",
      "Epoch: 150, train_loss_gae=0.59686, val_ap=0.87890, val_auc=0.84440,time=0.59042\n",
      "Epoch: 160, train_loss_gae=0.59263, val_ap=0.88178, val_auc=0.84809,time=0.60402\n",
      "Epoch: 170, train_loss_gae=0.58849, val_ap=0.88452, val_auc=0.85152,time=0.56339\n",
      "Epoch: 180, train_loss_gae=0.58420, val_ap=0.88659, val_auc=0.85420,time=0.56891\n",
      "Epoch: 190, train_loss_gae=0.58056, val_ap=0.88796, val_auc=0.85554,time=0.50935\n",
      "Epoch: 200, train_loss_gae=0.57758, val_ap=0.88934, val_auc=0.85713,time=0.54956\n",
      "Epoch: 210, train_loss_gae=0.57405, val_ap=0.88977, val_auc=0.85827,time=0.56375\n",
      "Epoch: 220, train_loss_gae=0.57193, val_ap=0.89037, val_auc=0.85903,time=0.59851\n",
      "Epoch: 230, train_loss_gae=0.56871, val_ap=0.89115, val_auc=0.85961,time=0.52354\n",
      "Epoch: 240, train_loss_gae=0.56595, val_ap=0.89148, val_auc=0.86000,time=0.62528\n",
      "Epoch: 250, train_loss_gae=0.56319, val_ap=0.89244, val_auc=0.86097,time=0.58396\n",
      "Epoch: 260, train_loss_gae=0.56020, val_ap=0.89293, val_auc=0.86132,time=0.55196\n",
      "Epoch: 270, train_loss_gae=0.55813, val_ap=0.89365, val_auc=0.86198,time=0.53831\n",
      "Epoch: 280, train_loss_gae=0.55550, val_ap=0.89367, val_auc=0.86169,time=0.50464\n",
      "Epoch: 290, train_loss_gae=0.55341, val_ap=0.89324, val_auc=0.86078,time=0.54927\n",
      "Epoch: 300, train_loss_gae=0.55177, val_ap=0.89363, val_auc=0.86093,time=0.54455\n",
      "Optimization Finished!\n",
      "Test AP score:  0.8750772237681996\n",
      "Test AUC score:  0.8448158434971622\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    gae_for(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a9e709",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-env",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
