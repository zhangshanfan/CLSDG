{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8e2213fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-08T08:52:51.569321Z",
     "start_time": "2022-05-08T08:52:51.563393Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "import torch\n",
    "from torch import optim\n",
    "import networkx as nx\n",
    "\n",
    "from gae.model import GCNModelVAE\n",
    "from gae.optimizer import loss_function\n",
    "from gae.utils import mask_test_edges, preprocess_graph, get_roc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7a0c03c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-08T07:48:07.369771Z",
     "start_time": "2022-05-08T07:48:07.346798Z"
    }
   },
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--model', type=str, default='gcn_vae', help=\"models used\")\n",
    "parser.add_argument('--seed', type=int, default=42, help='Random seed.')\n",
    "parser.add_argument('--epochs', type=int, default=200, help='Number of epochs to train.')\n",
    "parser.add_argument('--hidden1', type=int, default=32, help='Number of units in hidden layer 1.')\n",
    "parser.add_argument('--hidden2', type=int, default=16, help='Number of units in hidden layer 2.')\n",
    "parser.add_argument('--lr', type=float, default=0.01, help='Initial learning rate.')\n",
    "parser.add_argument('--dropout', type=float, default=0., help='Dropout rate (1 - keep probability).')\n",
    "parser.add_argument('--dataset-str', type=str, default='wiki', help='type of dataset.')\n",
    "\n",
    "args,_ = parser.parse_known_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b04fae95",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-08T07:48:07.999958Z",
     "start_time": "2022-05-08T07:48:07.977976Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_data(adj_name):\n",
    "    if adj_name == 'Cora':\n",
    "        nodes_numbers = 2708\n",
    "        datasets = Planetoid('./datasets', adj_name)\n",
    "        edges = datasets[0].edge_index\n",
    "        raw_edges = pd.DataFrame([[edges[0,i].item(), edges[1,i].item()] for i in range(edges.shape[1])])\n",
    "    elif adj_name == 'wiki':\n",
    "        nodes_numbers = 2405\n",
    "        raw_edges = pd.read_csv('datasets/graph.txt', header=None, sep='\\t')\n",
    "    elif adj_name == 'Citeseer':\n",
    "        nodes_numbers = 3327\n",
    "        datasets = Planetoid('./datasets', adj_name)\n",
    "        edges = datasets[0].edge_index\n",
    "        raw_edges = pd.DataFrame([[edges[0,i].item(), edges[1,i].item()] for i in range(edges.shape[1])])\n",
    "    elif adj_name == 'soc':\n",
    "        nodes_numbers = 2426\n",
    "        raw_edges = pd.read_csv(\"datasets/soc-hamsterster.edges\",header=None,sep=' ') - 1\n",
    "    else:\n",
    "        print(\"Dataset is not exist!\")\n",
    "    \n",
    "    drop_self_loop = raw_edges[raw_edges[0]!=raw_edges[1]]\n",
    "    \n",
    "    graph_np = np.zeros((nodes_numbers, nodes_numbers))\n",
    "    \n",
    "    for i in range(drop_self_loop.shape[0]):\n",
    "        graph_np[drop_self_loop.iloc[i,0], drop_self_loop.iloc[i,1]]=1\n",
    "        graph_np[drop_self_loop.iloc[i,1], drop_self_loop.iloc[i,0]]=1\n",
    "    \n",
    "    adj = nx.adjacency_matrix(nx.from_numpy_matrix(graph_np))\n",
    "    \n",
    "    features = torch.eye(nodes_numbers)\n",
    "    \n",
    "    return adj, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7222c058",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-08T07:48:08.691658Z",
     "start_time": "2022-05-08T07:48:08.674703Z"
    }
   },
   "outputs": [],
   "source": [
    "def gae_for(args):\n",
    "    print(\"Using {} dataset\".format(args.dataset_str))\n",
    "    adj, features = load_data(args.dataset_str)\n",
    "    \n",
    "    n_nodes, feat_dim = features.shape\n",
    "\n",
    "    # Store original adjacency matrix (without diagonal entries) for later\n",
    "    adj_orig = adj\n",
    "    adj_orig = adj_orig - sp.dia_matrix((adj_orig.diagonal()[np.newaxis, :], [0]), shape=adj_orig.shape)\n",
    "    adj_orig.eliminate_zeros()\n",
    "\n",
    "    adj_train, train_edges, val_edges, val_edges_false, test_edges, test_edges_false = mask_test_edges(adj)\n",
    "    adj = adj_train\n",
    "\n",
    "    # Some preprocessing\n",
    "    adj_norm = preprocess_graph(adj)\n",
    "    adj_label = adj_train + sp.eye(adj_train.shape[0])\n",
    "    # adj_label = sparse_to_tuple(adj_label)\n",
    "    adj_label = torch.FloatTensor(adj_label.toarray())\n",
    "\n",
    "    pos_weight = torch.tensor(float(adj.shape[0] * adj.shape[0] - adj.sum()) / adj.sum())\n",
    "    norm = adj.shape[0] * adj.shape[0] / float((adj.shape[0] * adj.shape[0] - adj.sum()) * 2)\n",
    "\n",
    "    model = GCNModelVAE(feat_dim, args.hidden1, args.hidden2, args.dropout)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
    "\n",
    "    hidden_emb = None\n",
    "    for epoch in range(args.epochs):\n",
    "        t = time.time()\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        recovered, mu, logvar = model(features, adj_norm)\n",
    "        \n",
    "        loss = loss_function(preds=recovered, labels=adj_label,\n",
    "                             mu=mu, logvar=logvar, n_nodes=n_nodes,\n",
    "                             norm=norm, pos_weight=pos_weight)\n",
    "        loss.backward()\n",
    "        cur_loss = loss.item()\n",
    "        optimizer.step()\n",
    "\n",
    "        hidden_emb = mu.data.numpy()\n",
    "        roc_curr, ap_curr = get_roc_score(hidden_emb, adj_orig, val_edges, val_edges_false)\n",
    "\n",
    "        print(\"Epoch:\", '%04d' % (epoch + 1), \"train_loss=\", \"{:.5f}\".format(cur_loss),\n",
    "              \"val_ap=\", \"{:.5f}\".format(ap_curr),\n",
    "              \"time=\", \"{:.5f}\".format(time.time() - t)\n",
    "              )\n",
    "\n",
    "    print(\"Optimization Finished!\")\n",
    "\n",
    "    roc_score, ap_score = get_roc_score(hidden_emb, adj_orig, test_edges, test_edges_false)\n",
    "    print('Test ROC score: ' + str(roc_score))\n",
    "    print('Test AP score: ' + str(ap_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6840259a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-08T07:49:04.508658Z",
     "start_time": "2022-05-08T07:48:09.354548Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using wiki dataset\n",
      "Epoch: 0001 train_loss= 1.73937 val_ap= 0.67886 time= 0.21542\n",
      "Epoch: 0002 train_loss= 1.70765 val_ap= 0.77238 time= 0.22512\n",
      "Epoch: 0003 train_loss= 1.65570 val_ap= 0.81869 time= 0.29617\n",
      "Epoch: 0004 train_loss= 1.67139 val_ap= 0.82768 time= 0.20675\n",
      "Epoch: 0005 train_loss= 1.57507 val_ap= 0.82745 time= 0.21794\n",
      "Epoch: 0006 train_loss= 1.54388 val_ap= 0.82617 time= 0.21340\n",
      "Epoch: 0007 train_loss= 1.49327 val_ap= 0.82448 time= 0.18530\n",
      "Epoch: 0008 train_loss= 1.42958 val_ap= 0.82306 time= 0.24180\n",
      "Epoch: 0009 train_loss= 1.39314 val_ap= 0.82190 time= 0.32424\n",
      "Epoch: 0010 train_loss= 1.32801 val_ap= 0.82074 time= 0.20645\n",
      "Epoch: 0011 train_loss= 1.25310 val_ap= 0.81999 time= 0.20528\n",
      "Epoch: 0012 train_loss= 1.19001 val_ap= 0.81963 time= 0.21099\n",
      "Epoch: 0013 train_loss= 1.13988 val_ap= 0.81915 time= 0.20105\n",
      "Epoch: 0014 train_loss= 1.08011 val_ap= 0.81869 time= 0.24740\n",
      "Epoch: 0015 train_loss= 1.03262 val_ap= 0.81859 time= 0.28449\n",
      "Epoch: 0016 train_loss= 0.98916 val_ap= 0.81881 time= 0.23299\n",
      "Epoch: 0017 train_loss= 0.93620 val_ap= 0.81891 time= 0.20844\n",
      "Epoch: 0018 train_loss= 0.88714 val_ap= 0.81932 time= 0.18650\n",
      "Epoch: 0019 train_loss= 0.85268 val_ap= 0.81950 time= 0.19753\n",
      "Epoch: 0020 train_loss= 0.82069 val_ap= 0.82007 time= 0.26857\n",
      "Epoch: 0021 train_loss= 0.78349 val_ap= 0.82008 time= 0.31801\n",
      "Epoch: 0022 train_loss= 0.76360 val_ap= 0.81995 time= 0.20933\n",
      "Epoch: 0023 train_loss= 0.74403 val_ap= 0.81890 time= 0.20729\n",
      "Epoch: 0024 train_loss= 0.72964 val_ap= 0.81786 time= 0.19843\n",
      "Epoch: 0025 train_loss= 0.71321 val_ap= 0.81725 time= 0.21155\n",
      "Epoch: 0026 train_loss= 0.70533 val_ap= 0.81760 time= 0.28869\n",
      "Epoch: 0027 train_loss= 0.69273 val_ap= 0.81885 time= 0.29901\n",
      "Epoch: 0028 train_loss= 0.68874 val_ap= 0.81950 time= 0.21495\n",
      "Epoch: 0029 train_loss= 0.67835 val_ap= 0.81957 time= 0.23036\n",
      "Epoch: 0030 train_loss= 0.67480 val_ap= 0.81924 time= 0.23392\n",
      "Epoch: 0031 train_loss= 0.66725 val_ap= 0.81888 time= 0.28286\n",
      "Epoch: 0032 train_loss= 0.66638 val_ap= 0.81764 time= 0.33237\n",
      "Epoch: 0033 train_loss= 0.65792 val_ap= 0.81535 time= 0.35579\n",
      "Epoch: 0034 train_loss= 0.65232 val_ap= 0.81255 time= 0.29451\n",
      "Epoch: 0035 train_loss= 0.64865 val_ap= 0.80772 time= 0.26062\n",
      "Epoch: 0036 train_loss= 0.64409 val_ap= 0.80290 time= 0.23571\n",
      "Epoch: 0037 train_loss= 0.63889 val_ap= 0.79876 time= 0.20744\n",
      "Epoch: 0038 train_loss= 0.63568 val_ap= 0.79549 time= 0.21343\n",
      "Epoch: 0039 train_loss= 0.63244 val_ap= 0.79351 time= 0.32811\n",
      "Epoch: 0040 train_loss= 0.62915 val_ap= 0.79209 time= 0.32549\n",
      "Epoch: 0041 train_loss= 0.62632 val_ap= 0.79109 time= 0.35738\n",
      "Epoch: 0042 train_loss= 0.62232 val_ap= 0.79050 time= 0.29170\n",
      "Epoch: 0043 train_loss= 0.61915 val_ap= 0.79010 time= 0.21520\n",
      "Epoch: 0044 train_loss= 0.61486 val_ap= 0.79110 time= 0.19351\n",
      "Epoch: 0045 train_loss= 0.61149 val_ap= 0.79239 time= 0.18850\n",
      "Epoch: 0046 train_loss= 0.60743 val_ap= 0.79344 time= 0.18189\n",
      "Epoch: 0047 train_loss= 0.60540 val_ap= 0.79470 time= 0.28658\n",
      "Epoch: 0048 train_loss= 0.60319 val_ap= 0.79607 time= 0.39032\n",
      "Epoch: 0049 train_loss= 0.59940 val_ap= 0.79697 time= 0.34980\n",
      "Epoch: 0050 train_loss= 0.59832 val_ap= 0.79813 time= 0.31416\n",
      "Epoch: 0051 train_loss= 0.59634 val_ap= 0.79871 time= 0.21450\n",
      "Epoch: 0052 train_loss= 0.59602 val_ap= 0.79869 time= 0.21243\n",
      "Epoch: 0053 train_loss= 0.59582 val_ap= 0.79758 time= 0.19647\n",
      "Epoch: 0054 train_loss= 0.59370 val_ap= 0.79615 time= 0.16880\n",
      "Epoch: 0055 train_loss= 0.59107 val_ap= 0.79518 time= 0.37735\n",
      "Epoch: 0056 train_loss= 0.59072 val_ap= 0.79514 time= 0.37085\n",
      "Epoch: 0057 train_loss= 0.58953 val_ap= 0.79556 time= 0.27943\n",
      "Epoch: 0058 train_loss= 0.58622 val_ap= 0.79719 time= 0.28438\n",
      "Epoch: 0059 train_loss= 0.58396 val_ap= 0.79938 time= 0.19400\n",
      "Epoch: 0060 train_loss= 0.58137 val_ap= 0.80229 time= 0.20445\n",
      "Epoch: 0061 train_loss= 0.57834 val_ap= 0.80588 time= 0.19249\n",
      "Epoch: 0062 train_loss= 0.57548 val_ap= 0.80981 time= 0.19747\n",
      "Epoch: 0063 train_loss= 0.57255 val_ap= 0.81421 time= 0.32547\n",
      "Epoch: 0064 train_loss= 0.57085 val_ap= 0.81830 time= 0.33833\n",
      "Epoch: 0065 train_loss= 0.56870 val_ap= 0.82194 time= 0.33267\n",
      "Epoch: 0066 train_loss= 0.56567 val_ap= 0.82469 time= 0.34871\n",
      "Epoch: 0067 train_loss= 0.56335 val_ap= 0.82694 time= 0.21735\n",
      "Epoch: 0068 train_loss= 0.56096 val_ap= 0.82894 time= 0.21241\n",
      "Epoch: 0069 train_loss= 0.55813 val_ap= 0.83083 time= 0.21144\n",
      "Epoch: 0070 train_loss= 0.55472 val_ap= 0.83295 time= 0.22540\n",
      "Epoch: 0071 train_loss= 0.55175 val_ap= 0.83531 time= 0.32726\n",
      "Epoch: 0072 train_loss= 0.54879 val_ap= 0.83760 time= 0.24133\n",
      "Epoch: 0073 train_loss= 0.54524 val_ap= 0.84021 time= 0.20745\n",
      "Epoch: 0074 train_loss= 0.54320 val_ap= 0.84284 time= 0.18949\n",
      "Epoch: 0075 train_loss= 0.53966 val_ap= 0.84548 time= 0.19947\n",
      "Epoch: 0076 train_loss= 0.53642 val_ap= 0.84792 time= 0.20388\n",
      "Epoch: 0077 train_loss= 0.53335 val_ap= 0.85015 time= 0.32590\n",
      "Epoch: 0078 train_loss= 0.53026 val_ap= 0.85229 time= 0.24312\n",
      "Epoch: 0079 train_loss= 0.52709 val_ap= 0.85419 time= 0.18865\n",
      "Epoch: 0080 train_loss= 0.52544 val_ap= 0.85693 time= 0.20514\n",
      "Epoch: 0081 train_loss= 0.52277 val_ap= 0.85972 time= 0.19936\n",
      "Epoch: 0082 train_loss= 0.52002 val_ap= 0.86315 time= 0.25936\n",
      "Epoch: 0083 train_loss= 0.51844 val_ap= 0.86576 time= 0.31715\n",
      "Epoch: 0084 train_loss= 0.51664 val_ap= 0.86850 time= 0.20686\n",
      "Epoch: 0085 train_loss= 0.51490 val_ap= 0.87086 time= 0.19747\n",
      "Epoch: 0086 train_loss= 0.51360 val_ap= 0.87315 time= 0.22241\n",
      "Epoch: 0087 train_loss= 0.51127 val_ap= 0.87581 time= 0.20146\n",
      "Epoch: 0088 train_loss= 0.50947 val_ap= 0.87875 time= 0.31105\n",
      "Epoch: 0089 train_loss= 0.50743 val_ap= 0.88227 time= 0.26928\n",
      "Epoch: 0090 train_loss= 0.50689 val_ap= 0.88530 time= 0.20645\n",
      "Epoch: 0091 train_loss= 0.50512 val_ap= 0.88739 time= 0.20246\n",
      "Epoch: 0092 train_loss= 0.50360 val_ap= 0.88834 time= 0.20146\n",
      "Epoch: 0093 train_loss= 0.50265 val_ap= 0.88914 time= 0.18973\n",
      "Epoch: 0094 train_loss= 0.50098 val_ap= 0.89009 time= 0.32202\n",
      "Epoch: 0095 train_loss= 0.49985 val_ap= 0.89133 time= 0.25346\n",
      "Epoch: 0096 train_loss= 0.49817 val_ap= 0.89283 time= 0.19207\n",
      "Epoch: 0097 train_loss= 0.49664 val_ap= 0.89482 time= 0.21243\n",
      "Epoch: 0098 train_loss= 0.49626 val_ap= 0.89646 time= 0.21021\n",
      "Epoch: 0099 train_loss= 0.49384 val_ap= 0.89757 time= 0.26004\n",
      "Epoch: 0100 train_loss= 0.49236 val_ap= 0.89864 time= 0.35472\n",
      "Epoch: 0101 train_loss= 0.49117 val_ap= 0.89948 time= 0.36188\n",
      "Epoch: 0102 train_loss= 0.48987 val_ap= 0.89999 time= 0.32700\n",
      "Epoch: 0103 train_loss= 0.48843 val_ap= 0.90070 time= 0.20409\n",
      "Epoch: 0104 train_loss= 0.48758 val_ap= 0.90170 time= 0.21298\n",
      "Epoch: 0105 train_loss= 0.48580 val_ap= 0.90309 time= 0.21343\n",
      "Epoch: 0106 train_loss= 0.48505 val_ap= 0.90399 time= 0.23453\n",
      "Epoch: 0107 train_loss= 0.48389 val_ap= 0.90412 time= 0.36044\n",
      "Epoch: 0108 train_loss= 0.48292 val_ap= 0.90379 time= 0.37599\n",
      "Epoch: 0109 train_loss= 0.48212 val_ap= 0.90348 time= 0.29327\n",
      "Epoch: 0110 train_loss= 0.48182 val_ap= 0.90406 time= 0.22535\n",
      "Epoch: 0111 train_loss= 0.48099 val_ap= 0.90516 time= 0.20485\n",
      "Epoch: 0112 train_loss= 0.47979 val_ap= 0.90653 time= 0.19386\n",
      "Epoch: 0113 train_loss= 0.47822 val_ap= 0.90773 time= 0.21456\n",
      "Epoch: 0114 train_loss= 0.47768 val_ap= 0.90831 time= 0.27535\n",
      "Epoch: 0115 train_loss= 0.47744 val_ap= 0.90861 time= 0.34611\n",
      "Epoch: 0116 train_loss= 0.47637 val_ap= 0.90895 time= 0.35219\n",
      "Epoch: 0117 train_loss= 0.47488 val_ap= 0.90931 time= 0.31360\n",
      "Epoch: 0118 train_loss= 0.47422 val_ap= 0.91065 time= 0.20745\n",
      "Epoch: 0119 train_loss= 0.47330 val_ap= 0.91204 time= 0.21642\n",
      "Epoch: 0120 train_loss= 0.47233 val_ap= 0.91348 time= 0.21934\n",
      "Epoch: 0121 train_loss= 0.47150 val_ap= 0.91445 time= 0.21399\n",
      "Epoch: 0122 train_loss= 0.47103 val_ap= 0.91503 time= 0.34258\n",
      "Epoch: 0123 train_loss= 0.47044 val_ap= 0.91514 time= 0.33830\n",
      "Epoch: 0124 train_loss= 0.46933 val_ap= 0.91570 time= 0.35764\n",
      "Epoch: 0125 train_loss= 0.46878 val_ap= 0.91621 time= 0.33121\n",
      "Epoch: 0126 train_loss= 0.46785 val_ap= 0.91692 time= 0.19947\n",
      "Epoch: 0127 train_loss= 0.46753 val_ap= 0.91742 time= 0.19847\n",
      "Epoch: 0128 train_loss= 0.46639 val_ap= 0.91781 time= 0.21248\n",
      "Epoch: 0129 train_loss= 0.46582 val_ap= 0.91805 time= 0.19749\n",
      "Epoch: 0130 train_loss= 0.46544 val_ap= 0.91823 time= 0.33112\n",
      "Epoch: 0131 train_loss= 0.46427 val_ap= 0.91836 time= 0.35160\n",
      "Epoch: 0132 train_loss= 0.46378 val_ap= 0.91885 time= 0.32431\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0133 train_loss= 0.46314 val_ap= 0.91928 time= 0.33494\n",
      "Epoch: 0134 train_loss= 0.46287 val_ap= 0.91953 time= 0.21094\n",
      "Epoch: 0135 train_loss= 0.46202 val_ap= 0.91963 time= 0.21642\n",
      "Epoch: 0136 train_loss= 0.46141 val_ap= 0.91992 time= 0.19720\n",
      "Epoch: 0137 train_loss= 0.46061 val_ap= 0.92026 time= 0.19893\n",
      "Epoch: 0138 train_loss= 0.45989 val_ap= 0.92071 time= 0.27084\n",
      "Epoch: 0139 train_loss= 0.45947 val_ap= 0.92107 time= 0.26871\n",
      "Epoch: 0140 train_loss= 0.45908 val_ap= 0.92141 time= 0.21672\n",
      "Epoch: 0141 train_loss= 0.45825 val_ap= 0.92159 time= 0.20146\n",
      "Epoch: 0142 train_loss= 0.45729 val_ap= 0.92146 time= 0.21443\n",
      "Epoch: 0143 train_loss= 0.45680 val_ap= 0.92139 time= 0.18475\n",
      "Epoch: 0144 train_loss= 0.45664 val_ap= 0.92170 time= 0.27262\n",
      "Epoch: 0145 train_loss= 0.45584 val_ap= 0.92199 time= 0.27652\n",
      "Epoch: 0146 train_loss= 0.45529 val_ap= 0.92216 time= 0.21943\n",
      "Epoch: 0147 train_loss= 0.45471 val_ap= 0.92239 time= 0.18170\n",
      "Epoch: 0148 train_loss= 0.45410 val_ap= 0.92259 time= 0.18950\n",
      "Epoch: 0149 train_loss= 0.45354 val_ap= 0.92251 time= 0.19689\n",
      "Epoch: 0150 train_loss= 0.45355 val_ap= 0.92240 time= 0.23428\n",
      "Epoch: 0151 train_loss= 0.45273 val_ap= 0.92232 time= 0.31162\n",
      "Epoch: 0152 train_loss= 0.45226 val_ap= 0.92241 time= 0.21503\n",
      "Epoch: 0153 train_loss= 0.45185 val_ap= 0.92260 time= 0.20413\n",
      "Epoch: 0154 train_loss= 0.45151 val_ap= 0.92260 time= 0.19752\n",
      "Epoch: 0155 train_loss= 0.45111 val_ap= 0.92267 time= 0.19955\n",
      "Epoch: 0156 train_loss= 0.45058 val_ap= 0.92262 time= 0.28315\n",
      "Epoch: 0157 train_loss= 0.44986 val_ap= 0.92246 time= 0.30989\n",
      "Epoch: 0158 train_loss= 0.44970 val_ap= 0.92225 time= 0.21642\n",
      "Epoch: 0159 train_loss= 0.44937 val_ap= 0.92216 time= 0.18996\n",
      "Epoch: 0160 train_loss= 0.44920 val_ap= 0.92231 time= 0.21529\n",
      "Epoch: 0161 train_loss= 0.44875 val_ap= 0.92257 time= 0.18274\n",
      "Epoch: 0162 train_loss= 0.44822 val_ap= 0.92280 time= 0.25229\n",
      "Epoch: 0163 train_loss= 0.44802 val_ap= 0.92274 time= 0.31364\n",
      "Epoch: 0164 train_loss= 0.44779 val_ap= 0.92285 time= 0.21175\n",
      "Epoch: 0165 train_loss= 0.44739 val_ap= 0.92294 time= 0.21362\n",
      "Epoch: 0166 train_loss= 0.44718 val_ap= 0.92279 time= 0.19985\n",
      "Epoch: 0167 train_loss= 0.44699 val_ap= 0.92292 time= 0.19232\n",
      "Epoch: 0168 train_loss= 0.44635 val_ap= 0.92282 time= 0.30377\n",
      "Epoch: 0169 train_loss= 0.44624 val_ap= 0.92275 time= 0.38104\n",
      "Epoch: 0170 train_loss= 0.44604 val_ap= 0.92291 time= 0.25731\n",
      "Epoch: 0171 train_loss= 0.44543 val_ap= 0.92328 time= 0.27297\n",
      "Epoch: 0172 train_loss= 0.44502 val_ap= 0.92348 time= 0.20745\n",
      "Epoch: 0173 train_loss= 0.44488 val_ap= 0.92363 time= 0.20104\n",
      "Epoch: 0174 train_loss= 0.44454 val_ap= 0.92331 time= 0.20346\n",
      "Epoch: 0175 train_loss= 0.44445 val_ap= 0.92335 time= 0.19947\n",
      "Epoch: 0176 train_loss= 0.44402 val_ap= 0.92367 time= 0.32875\n",
      "Epoch: 0177 train_loss= 0.44395 val_ap= 0.92385 time= 0.42294\n",
      "Epoch: 0178 train_loss= 0.44380 val_ap= 0.92398 time= 0.28688\n",
      "Epoch: 0179 train_loss= 0.44309 val_ap= 0.92375 time= 0.27895\n",
      "Epoch: 0180 train_loss= 0.44304 val_ap= 0.92350 time= 0.20139\n",
      "Epoch: 0181 train_loss= 0.44277 val_ap= 0.92342 time= 0.22238\n",
      "Epoch: 0182 train_loss= 0.44244 val_ap= 0.92359 time= 0.20682\n",
      "Epoch: 0183 train_loss= 0.44230 val_ap= 0.92358 time= 0.25200\n",
      "Epoch: 0184 train_loss= 0.44236 val_ap= 0.92363 time= 0.30379\n",
      "Epoch: 0185 train_loss= 0.44241 val_ap= 0.92346 time= 0.39513\n",
      "Epoch: 0186 train_loss= 0.44177 val_ap= 0.92319 time= 0.27055\n",
      "Epoch: 0187 train_loss= 0.44152 val_ap= 0.92294 time= 0.21941\n",
      "Epoch: 0188 train_loss= 0.44144 val_ap= 0.92308 time= 0.19747\n",
      "Epoch: 0189 train_loss= 0.44140 val_ap= 0.92330 time= 0.18372\n",
      "Epoch: 0190 train_loss= 0.44093 val_ap= 0.92333 time= 0.18020\n",
      "Epoch: 0191 train_loss= 0.44086 val_ap= 0.92316 time= 0.22113\n",
      "Epoch: 0192 train_loss= 0.44077 val_ap= 0.92291 time= 0.32900\n",
      "Epoch: 0193 train_loss= 0.44067 val_ap= 0.92264 time= 0.38996\n",
      "Epoch: 0194 train_loss= 0.44024 val_ap= 0.92259 time= 0.29551\n",
      "Epoch: 0195 train_loss= 0.44031 val_ap= 0.92282 time= 0.23926\n",
      "Epoch: 0196 train_loss= 0.44024 val_ap= 0.92295 time= 0.22156\n",
      "Epoch: 0197 train_loss= 0.43982 val_ap= 0.92272 time= 0.18720\n",
      "Epoch: 0198 train_loss= 0.43971 val_ap= 0.92250 time= 0.24515\n",
      "Epoch: 0199 train_loss= 0.43946 val_ap= 0.92230 time= 0.29970\n",
      "Epoch: 0200 train_loss= 0.43952 val_ap= 0.92240 time= 0.38838\n",
      "Optimization Finished!\n",
      "Test ROC score: 0.8935866732277165\n",
      "Test AP score: 0.9234041720193295\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    gae_for(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1c156e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-env",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
