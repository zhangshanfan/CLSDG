{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6875bf3f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-08T07:36:50.984740Z",
     "start_time": "2022-05-08T07:36:50.975726Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import torch\n",
    "from torch import optim\n",
    "\n",
    "from gae.model import GCNModelVAE\n",
    "from gae.optimizer import loss_function\n",
    "from gae.utils import load_data, mask_test_edges, preprocess_graph, get_roc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "04f45f59",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-08T07:36:51.554646Z",
     "start_time": "2022-05-08T07:36:51.531709Z"
    }
   },
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--model', type=str, default='gcn_vae', help=\"models used\")\n",
    "parser.add_argument('--seed', type=int, default=42, help='Random seed.')\n",
    "parser.add_argument('--epochs', type=int, default=200, help='Number of epochs to train.')\n",
    "parser.add_argument('--hidden1', type=int, default=32, help='Number of units in hidden layer 1.')\n",
    "parser.add_argument('--hidden2', type=int, default=16, help='Number of units in hidden layer 2.')\n",
    "parser.add_argument('--lr', type=float, default=0.01, help='Initial learning rate.')\n",
    "parser.add_argument('--dropout', type=float, default=0., help='Dropout rate (1 - keep probability).')\n",
    "parser.add_argument('--dataset-str', type=str, default='cora', help='type of dataset.')\n",
    "\n",
    "args,_ = parser.parse_known_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8e7059e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-08T07:36:52.214736Z",
     "start_time": "2022-05-08T07:36:52.187120Z"
    }
   },
   "outputs": [],
   "source": [
    "def gae_for(args):\n",
    "    print(\"Using {} dataset\".format(args.dataset_str))\n",
    "    adj, features = load_data(args.dataset_str)\n",
    "    features = torch.eye(2708)\n",
    "    \n",
    "    n_nodes, feat_dim = features.shape\n",
    "\n",
    "    # Store original adjacency matrix (without diagonal entries) for later\n",
    "    adj_orig = adj\n",
    "    adj_orig = adj_orig - sp.dia_matrix((adj_orig.diagonal()[np.newaxis, :], [0]), shape=adj_orig.shape)\n",
    "    adj_orig.eliminate_zeros()\n",
    "\n",
    "    adj_train, train_edges, val_edges, val_edges_false, test_edges, test_edges_false = mask_test_edges(adj)\n",
    "    adj = adj_train\n",
    "\n",
    "    # Some preprocessing\n",
    "    adj_norm = preprocess_graph(adj)\n",
    "    adj_label = adj_train + sp.eye(adj_train.shape[0])\n",
    "    # adj_label = sparse_to_tuple(adj_label)\n",
    "    adj_label = torch.FloatTensor(adj_label.toarray())\n",
    "\n",
    "    pos_weight = torch.tensor(float(adj.shape[0] * adj.shape[0] - adj.sum()) / adj.sum())\n",
    "    norm = adj.shape[0] * adj.shape[0] / float((adj.shape[0] * adj.shape[0] - adj.sum()) * 2)\n",
    "\n",
    "    model = GCNModelVAE(feat_dim, args.hidden1, args.hidden2, args.dropout)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
    "\n",
    "    hidden_emb = None\n",
    "    for epoch in range(args.epochs):\n",
    "        t = time.time()\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        recovered, mu, logvar = model(features, adj_norm)\n",
    "        \n",
    "        loss = loss_function(preds=recovered, labels=adj_label,\n",
    "                             mu=mu, logvar=logvar, n_nodes=n_nodes,\n",
    "                             norm=norm, pos_weight=pos_weight)\n",
    "        loss.backward()\n",
    "        cur_loss = loss.item()\n",
    "        optimizer.step()\n",
    "\n",
    "        hidden_emb = mu.data.numpy()\n",
    "        roc_curr, ap_curr = get_roc_score(hidden_emb, adj_orig, val_edges, val_edges_false)\n",
    "\n",
    "        print(\"Epoch:\", '%04d' % (epoch + 1), \"train_loss=\", \"{:.5f}\".format(cur_loss),\n",
    "              \"val_ap=\", \"{:.5f}\".format(ap_curr),\n",
    "              \"time=\", \"{:.5f}\".format(time.time() - t)\n",
    "              )\n",
    "\n",
    "    print(\"Optimization Finished!\")\n",
    "\n",
    "    roc_score, ap_score = get_roc_score(hidden_emb, adj_orig, test_edges, test_edges_false)\n",
    "    print('Test ROC score: ' + str(roc_score))\n",
    "    print('Test AP score: ' + str(ap_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0526bff6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-08T07:37:33.274790Z",
     "start_time": "2022-05-08T07:36:52.827447Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cora dataset\n",
      "Epoch: 0001 train_loss= 1.73497 val_ap= 0.64207 time= 0.19647\n",
      "Epoch: 0002 train_loss= 1.69780 val_ap= 0.70084 time= 0.20346\n",
      "Epoch: 0003 train_loss= 1.68353 val_ap= 0.71687 time= 0.20844\n",
      "Epoch: 0004 train_loss= 1.68172 val_ap= 0.72343 time= 0.20046\n",
      "Epoch: 0005 train_loss= 1.59166 val_ap= 0.71836 time= 0.20345\n",
      "Epoch: 0006 train_loss= 1.57900 val_ap= 0.71662 time= 0.21243\n",
      "Epoch: 0007 train_loss= 1.54107 val_ap= 0.71319 time= 0.19857\n",
      "Epoch: 0008 train_loss= 1.45779 val_ap= 0.70946 time= 0.20054\n",
      "Epoch: 0009 train_loss= 1.43472 val_ap= 0.70605 time= 0.19643\n",
      "Epoch: 0010 train_loss= 1.36174 val_ap= 0.70362 time= 0.21144\n",
      "Epoch: 0011 train_loss= 1.31118 val_ap= 0.70000 time= 0.20351\n",
      "Epoch: 0012 train_loss= 1.25039 val_ap= 0.69795 time= 0.19775\n",
      "Epoch: 0013 train_loss= 1.17574 val_ap= 0.69556 time= 0.21543\n",
      "Epoch: 0014 train_loss= 1.11304 val_ap= 0.69392 time= 0.19847\n",
      "Epoch: 0015 train_loss= 1.05155 val_ap= 0.69340 time= 0.20744\n",
      "Epoch: 0016 train_loss= 1.00844 val_ap= 0.69263 time= 0.19920\n",
      "Epoch: 0017 train_loss= 0.94128 val_ap= 0.69166 time= 0.19950\n",
      "Epoch: 0018 train_loss= 0.90896 val_ap= 0.69120 time= 0.21033\n",
      "Epoch: 0019 train_loss= 0.87958 val_ap= 0.69104 time= 0.22739\n",
      "Epoch: 0020 train_loss= 0.82582 val_ap= 0.69198 time= 0.20545\n",
      "Epoch: 0021 train_loss= 0.80097 val_ap= 0.69275 time= 0.21044\n",
      "Epoch: 0022 train_loss= 0.77576 val_ap= 0.69569 time= 0.22041\n",
      "Epoch: 0023 train_loss= 0.75540 val_ap= 0.69879 time= 0.21443\n",
      "Epoch: 0024 train_loss= 0.74083 val_ap= 0.70220 time= 0.20852\n",
      "Epoch: 0025 train_loss= 0.73094 val_ap= 0.70431 time= 0.20238\n",
      "Epoch: 0026 train_loss= 0.72070 val_ap= 0.70429 time= 0.19363\n",
      "Epoch: 0027 train_loss= 0.70985 val_ap= 0.70368 time= 0.20892\n",
      "Epoch: 0028 train_loss= 0.70304 val_ap= 0.70202 time= 0.20346\n",
      "Epoch: 0029 train_loss= 0.69621 val_ap= 0.70054 time= 0.20545\n",
      "Epoch: 0030 train_loss= 0.69240 val_ap= 0.69994 time= 0.20047\n",
      "Epoch: 0031 train_loss= 0.68944 val_ap= 0.70161 time= 0.19946\n",
      "Epoch: 0032 train_loss= 0.67990 val_ap= 0.70516 time= 0.20445\n",
      "Epoch: 0033 train_loss= 0.67683 val_ap= 0.70886 time= 0.20844\n",
      "Epoch: 0034 train_loss= 0.67442 val_ap= 0.71281 time= 0.20844\n",
      "Epoch: 0035 train_loss= 0.66558 val_ap= 0.71615 time= 0.20046\n",
      "Epoch: 0036 train_loss= 0.65824 val_ap= 0.72021 time= 0.19169\n",
      "Epoch: 0037 train_loss= 0.64951 val_ap= 0.72474 time= 0.19786\n",
      "Epoch: 0038 train_loss= 0.64220 val_ap= 0.73020 time= 0.20529\n",
      "Epoch: 0039 train_loss= 0.63481 val_ap= 0.73681 time= 0.20166\n",
      "Epoch: 0040 train_loss= 0.62136 val_ap= 0.74550 time= 0.20226\n",
      "Epoch: 0041 train_loss= 0.61166 val_ap= 0.75248 time= 0.22101\n",
      "Epoch: 0042 train_loss= 0.60008 val_ap= 0.75884 time= 0.19947\n",
      "Epoch: 0043 train_loss= 0.58881 val_ap= 0.76209 time= 0.21542\n",
      "Epoch: 0044 train_loss= 0.57890 val_ap= 0.76312 time= 0.20844\n",
      "Epoch: 0045 train_loss= 0.56802 val_ap= 0.76519 time= 0.20172\n",
      "Epoch: 0046 train_loss= 0.56068 val_ap= 0.76543 time= 0.19092\n",
      "Epoch: 0047 train_loss= 0.55373 val_ap= 0.76775 time= 0.20349\n",
      "Epoch: 0048 train_loss= 0.55046 val_ap= 0.76781 time= 0.19747\n",
      "Epoch: 0049 train_loss= 0.54834 val_ap= 0.76972 time= 0.20246\n",
      "Epoch: 0050 train_loss= 0.54506 val_ap= 0.77259 time= 0.20046\n",
      "Epoch: 0051 train_loss= 0.54346 val_ap= 0.77648 time= 0.19899\n",
      "Epoch: 0052 train_loss= 0.54142 val_ap= 0.78026 time= 0.19595\n",
      "Epoch: 0053 train_loss= 0.53702 val_ap= 0.78518 time= 0.20645\n",
      "Epoch: 0054 train_loss= 0.53419 val_ap= 0.78986 time= 0.19748\n",
      "Epoch: 0055 train_loss= 0.53074 val_ap= 0.79209 time= 0.20046\n",
      "Epoch: 0056 train_loss= 0.52516 val_ap= 0.79382 time= 0.19592\n",
      "Epoch: 0057 train_loss= 0.52141 val_ap= 0.79636 time= 0.20379\n",
      "Epoch: 0058 train_loss= 0.51738 val_ap= 0.79928 time= 0.21243\n",
      "Epoch: 0059 train_loss= 0.51308 val_ap= 0.80430 time= 0.20744\n",
      "Epoch: 0060 train_loss= 0.50999 val_ap= 0.80790 time= 0.19947\n",
      "Epoch: 0061 train_loss= 0.50799 val_ap= 0.80980 time= 0.20445\n",
      "Epoch: 0062 train_loss= 0.50513 val_ap= 0.81142 time= 0.20545\n",
      "Epoch: 0063 train_loss= 0.50229 val_ap= 0.81313 time= 0.20172\n",
      "Epoch: 0064 train_loss= 0.49998 val_ap= 0.81429 time= 0.20844\n",
      "Epoch: 0065 train_loss= 0.49848 val_ap= 0.81643 time= 0.19182\n",
      "Epoch: 0066 train_loss= 0.49563 val_ap= 0.81865 time= 0.18391\n",
      "Epoch: 0067 train_loss= 0.49473 val_ap= 0.82188 time= 0.22290\n",
      "Epoch: 0068 train_loss= 0.49261 val_ap= 0.82384 time= 0.20046\n",
      "Epoch: 0069 train_loss= 0.49038 val_ap= 0.82507 time= 0.19747\n",
      "Epoch: 0070 train_loss= 0.48895 val_ap= 0.82669 time= 0.20844\n",
      "Epoch: 0071 train_loss= 0.48683 val_ap= 0.82860 time= 0.20446\n",
      "Epoch: 0072 train_loss= 0.48368 val_ap= 0.83102 time= 0.20146\n",
      "Epoch: 0073 train_loss= 0.48249 val_ap= 0.83388 time= 0.20146\n",
      "Epoch: 0074 train_loss= 0.48069 val_ap= 0.83628 time= 0.20384\n",
      "Epoch: 0075 train_loss= 0.47908 val_ap= 0.83922 time= 0.20667\n",
      "Epoch: 0076 train_loss= 0.47760 val_ap= 0.84285 time= 0.19156\n",
      "Epoch: 0077 train_loss= 0.47600 val_ap= 0.84532 time= 0.19936\n",
      "Epoch: 0078 train_loss= 0.47458 val_ap= 0.84819 time= 0.20982\n",
      "Epoch: 0079 train_loss= 0.47401 val_ap= 0.85035 time= 0.20645\n",
      "Epoch: 0080 train_loss= 0.47192 val_ap= 0.85261 time= 0.20445\n",
      "Epoch: 0081 train_loss= 0.47112 val_ap= 0.85547 time= 0.18750\n",
      "Epoch: 0082 train_loss= 0.46943 val_ap= 0.85692 time= 0.20594\n",
      "Epoch: 0083 train_loss= 0.46856 val_ap= 0.85845 time= 0.20645\n",
      "Epoch: 0084 train_loss= 0.46783 val_ap= 0.85956 time= 0.20046\n",
      "Epoch: 0085 train_loss= 0.46669 val_ap= 0.86026 time= 0.18684\n",
      "Epoch: 0086 train_loss= 0.46645 val_ap= 0.86087 time= 0.20569\n",
      "Epoch: 0087 train_loss= 0.46450 val_ap= 0.86186 time= 0.19534\n",
      "Epoch: 0088 train_loss= 0.46398 val_ap= 0.86272 time= 0.21093\n",
      "Epoch: 0089 train_loss= 0.46302 val_ap= 0.86285 time= 0.20745\n",
      "Epoch: 0090 train_loss= 0.46226 val_ap= 0.86340 time= 0.20246\n",
      "Epoch: 0091 train_loss= 0.46131 val_ap= 0.86366 time= 0.20944\n",
      "Epoch: 0092 train_loss= 0.46080 val_ap= 0.86344 time= 0.20844\n",
      "Epoch: 0093 train_loss= 0.46005 val_ap= 0.86344 time= 0.20445\n",
      "Epoch: 0094 train_loss= 0.45948 val_ap= 0.86324 time= 0.20745\n",
      "Epoch: 0095 train_loss= 0.45862 val_ap= 0.86351 time= 0.17870\n",
      "Epoch: 0096 train_loss= 0.45805 val_ap= 0.86321 time= 0.21769\n",
      "Epoch: 0097 train_loss= 0.45739 val_ap= 0.86318 time= 0.19747\n",
      "Epoch: 0098 train_loss= 0.45656 val_ap= 0.86325 time= 0.20246\n",
      "Epoch: 0099 train_loss= 0.45610 val_ap= 0.86350 time= 0.20346\n",
      "Epoch: 0100 train_loss= 0.45509 val_ap= 0.86381 time= 0.19947\n",
      "Epoch: 0101 train_loss= 0.45471 val_ap= 0.86460 time= 0.20445\n",
      "Epoch: 0102 train_loss= 0.45425 val_ap= 0.86558 time= 0.19947\n",
      "Epoch: 0103 train_loss= 0.45350 val_ap= 0.86612 time= 0.20844\n",
      "Epoch: 0104 train_loss= 0.45309 val_ap= 0.86690 time= 0.20908\n",
      "Epoch: 0105 train_loss= 0.45265 val_ap= 0.86772 time= 0.20885\n",
      "Epoch: 0106 train_loss= 0.45187 val_ap= 0.86851 time= 0.20622\n",
      "Epoch: 0107 train_loss= 0.45213 val_ap= 0.86975 time= 0.21722\n",
      "Epoch: 0108 train_loss= 0.45148 val_ap= 0.87075 time= 0.18651\n",
      "Epoch: 0109 train_loss= 0.45127 val_ap= 0.87129 time= 0.21395\n",
      "Epoch: 0110 train_loss= 0.45075 val_ap= 0.87224 time= 0.20458\n",
      "Epoch: 0111 train_loss= 0.45038 val_ap= 0.87316 time= 0.20108\n",
      "Epoch: 0112 train_loss= 0.44943 val_ap= 0.87391 time= 0.19906\n",
      "Epoch: 0113 train_loss= 0.44909 val_ap= 0.87434 time= 0.20548\n",
      "Epoch: 0114 train_loss= 0.44882 val_ap= 0.87498 time= 0.21721\n",
      "Epoch: 0115 train_loss= 0.44861 val_ap= 0.87578 time= 0.22231\n",
      "Epoch: 0116 train_loss= 0.44799 val_ap= 0.87637 time= 0.22160\n",
      "Epoch: 0117 train_loss= 0.44767 val_ap= 0.87725 time= 0.22324\n",
      "Epoch: 0118 train_loss= 0.44713 val_ap= 0.87792 time= 0.20456\n",
      "Epoch: 0119 train_loss= 0.44695 val_ap= 0.87860 time= 0.19239\n",
      "Epoch: 0120 train_loss= 0.44631 val_ap= 0.87901 time= 0.18635\n",
      "Epoch: 0121 train_loss= 0.44563 val_ap= 0.87919 time= 0.19922\n",
      "Epoch: 0122 train_loss= 0.44565 val_ap= 0.87952 time= 0.19887\n",
      "Epoch: 0123 train_loss= 0.44518 val_ap= 0.87982 time= 0.21041\n",
      "Epoch: 0124 train_loss= 0.44454 val_ap= 0.88020 time= 0.21514\n",
      "Epoch: 0125 train_loss= 0.44428 val_ap= 0.88061 time= 0.19536\n",
      "Epoch: 0126 train_loss= 0.44383 val_ap= 0.88089 time= 0.18586\n",
      "Epoch: 0127 train_loss= 0.44342 val_ap= 0.88109 time= 0.20986\n",
      "Epoch: 0128 train_loss= 0.44315 val_ap= 0.88122 time= 0.19577\n",
      "Epoch: 0129 train_loss= 0.44261 val_ap= 0.88167 time= 0.21830\n",
      "Epoch: 0130 train_loss= 0.44223 val_ap= 0.88229 time= 0.22570\n",
      "Epoch: 0131 train_loss= 0.44205 val_ap= 0.88274 time= 0.19510\n",
      "Epoch: 0132 train_loss= 0.44191 val_ap= 0.88262 time= 0.23208\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0133 train_loss= 0.44096 val_ap= 0.88232 time= 0.20734\n",
      "Epoch: 0134 train_loss= 0.44085 val_ap= 0.88194 time= 0.20722\n",
      "Epoch: 0135 train_loss= 0.44029 val_ap= 0.88182 time= 0.20693\n",
      "Epoch: 0136 train_loss= 0.44036 val_ap= 0.88225 time= 0.19961\n",
      "Epoch: 0137 train_loss= 0.44008 val_ap= 0.88292 time= 0.18697\n",
      "Epoch: 0138 train_loss= 0.43963 val_ap= 0.88288 time= 0.22749\n",
      "Epoch: 0139 train_loss= 0.43921 val_ap= 0.88285 time= 0.23279\n",
      "Epoch: 0140 train_loss= 0.43905 val_ap= 0.88270 time= 0.23974\n",
      "Epoch: 0141 train_loss= 0.43867 val_ap= 0.88229 time= 0.20556\n",
      "Epoch: 0142 train_loss= 0.43822 val_ap= 0.88218 time= 0.18953\n",
      "Epoch: 0143 train_loss= 0.43811 val_ap= 0.88232 time= 0.18761\n",
      "Epoch: 0144 train_loss= 0.43791 val_ap= 0.88291 time= 0.19132\n",
      "Epoch: 0145 train_loss= 0.43739 val_ap= 0.88283 time= 0.18752\n",
      "Epoch: 0146 train_loss= 0.43691 val_ap= 0.88269 time= 0.19491\n",
      "Epoch: 0147 train_loss= 0.43685 val_ap= 0.88258 time= 0.19484\n",
      "Epoch: 0148 train_loss= 0.43656 val_ap= 0.88293 time= 0.19448\n",
      "Epoch: 0149 train_loss= 0.43640 val_ap= 0.88314 time= 0.17645\n",
      "Epoch: 0150 train_loss= 0.43581 val_ap= 0.88344 time= 0.17680\n",
      "Epoch: 0151 train_loss= 0.43570 val_ap= 0.88360 time= 0.19180\n",
      "Epoch: 0152 train_loss= 0.43574 val_ap= 0.88352 time= 0.17010\n",
      "Epoch: 0153 train_loss= 0.43548 val_ap= 0.88327 time= 0.19208\n",
      "Epoch: 0154 train_loss= 0.43518 val_ap= 0.88406 time= 0.17358\n",
      "Epoch: 0155 train_loss= 0.43472 val_ap= 0.88452 time= 0.16915\n",
      "Epoch: 0156 train_loss= 0.43448 val_ap= 0.88466 time= 0.17799\n",
      "Epoch: 0157 train_loss= 0.43425 val_ap= 0.88463 time= 0.18098\n",
      "Epoch: 0158 train_loss= 0.43424 val_ap= 0.88472 time= 0.16952\n",
      "Epoch: 0159 train_loss= 0.43403 val_ap= 0.88515 time= 0.18677\n",
      "Epoch: 0160 train_loss= 0.43378 val_ap= 0.88511 time= 0.17920\n",
      "Epoch: 0161 train_loss= 0.43344 val_ap= 0.88518 time= 0.18124\n",
      "Epoch: 0162 train_loss= 0.43329 val_ap= 0.88570 time= 0.18019\n",
      "Epoch: 0163 train_loss= 0.43306 val_ap= 0.88593 time= 0.17921\n",
      "Epoch: 0164 train_loss= 0.43267 val_ap= 0.88620 time= 0.18228\n",
      "Epoch: 0165 train_loss= 0.43245 val_ap= 0.88628 time= 0.17505\n",
      "Epoch: 0166 train_loss= 0.43224 val_ap= 0.88637 time= 0.18987\n",
      "Epoch: 0167 train_loss= 0.43228 val_ap= 0.88633 time= 0.18425\n",
      "Epoch: 0168 train_loss= 0.43195 val_ap= 0.88626 time= 0.18001\n",
      "Epoch: 0169 train_loss= 0.43174 val_ap= 0.88634 time= 0.16976\n",
      "Epoch: 0170 train_loss= 0.43168 val_ap= 0.88665 time= 0.17671\n",
      "Epoch: 0171 train_loss= 0.43137 val_ap= 0.88674 time= 0.16563\n",
      "Epoch: 0172 train_loss= 0.43142 val_ap= 0.88652 time= 0.18277\n",
      "Epoch: 0173 train_loss= 0.43109 val_ap= 0.88665 time= 0.17823\n",
      "Epoch: 0174 train_loss= 0.43103 val_ap= 0.88690 time= 0.18394\n",
      "Epoch: 0175 train_loss= 0.43065 val_ap= 0.88690 time= 0.17337\n",
      "Epoch: 0176 train_loss= 0.43068 val_ap= 0.88678 time= 0.21610\n",
      "Epoch: 0177 train_loss= 0.43038 val_ap= 0.88690 time= 0.18526\n",
      "Epoch: 0178 train_loss= 0.43017 val_ap= 0.88713 time= 0.17291\n",
      "Epoch: 0179 train_loss= 0.42991 val_ap= 0.88716 time= 0.18281\n",
      "Epoch: 0180 train_loss= 0.42989 val_ap= 0.88705 time= 0.19065\n",
      "Epoch: 0181 train_loss= 0.42977 val_ap= 0.88708 time= 0.18393\n",
      "Epoch: 0182 train_loss= 0.42946 val_ap= 0.88723 time= 0.17416\n",
      "Epoch: 0183 train_loss= 0.42936 val_ap= 0.88743 time= 0.17780\n",
      "Epoch: 0184 train_loss= 0.42933 val_ap= 0.88745 time= 0.17851\n",
      "Epoch: 0185 train_loss= 0.42899 val_ap= 0.88752 time= 0.16709\n",
      "Epoch: 0186 train_loss= 0.42903 val_ap= 0.88784 time= 0.19184\n",
      "Epoch: 0187 train_loss= 0.42878 val_ap= 0.88810 time= 0.17554\n",
      "Epoch: 0188 train_loss= 0.42853 val_ap= 0.88851 time= 0.17463\n",
      "Epoch: 0189 train_loss= 0.42838 val_ap= 0.88872 time= 0.19005\n",
      "Epoch: 0190 train_loss= 0.42835 val_ap= 0.88840 time= 0.19062\n",
      "Epoch: 0191 train_loss= 0.42817 val_ap= 0.88837 time= 0.18730\n",
      "Epoch: 0192 train_loss= 0.42813 val_ap= 0.88850 time= 0.17696\n",
      "Epoch: 0193 train_loss= 0.42803 val_ap= 0.88863 time= 0.18647\n",
      "Epoch: 0194 train_loss= 0.42774 val_ap= 0.88894 time= 0.18548\n",
      "Epoch: 0195 train_loss= 0.42789 val_ap= 0.88896 time= 0.19249\n",
      "Epoch: 0196 train_loss= 0.42760 val_ap= 0.88897 time= 0.18408\n",
      "Epoch: 0197 train_loss= 0.42751 val_ap= 0.88879 time= 0.18614\n",
      "Epoch: 0198 train_loss= 0.42735 val_ap= 0.88871 time= 0.18432\n",
      "Epoch: 0199 train_loss= 0.42743 val_ap= 0.88975 time= 0.17928\n",
      "Epoch: 0200 train_loss= 0.42713 val_ap= 0.88973 time= 0.17763\n",
      "Optimization Finished!\n",
      "Test ROC score: 0.8398582791138124\n",
      "Test AP score: 0.8814249905814024\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    gae_for(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191cd0ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-env",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
