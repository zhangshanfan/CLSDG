{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8e2213fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-08T09:17:27.536107Z",
     "start_time": "2022-05-08T09:17:27.522142Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "import torch\n",
    "from torch import optim\n",
    "import networkx as nx\n",
    "\n",
    "from gae.model import GCNModelVAE\n",
    "from gae.optimizer import loss_function\n",
    "from gae.utils import mask_test_edges, preprocess_graph, get_roc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7a0c03c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-08T09:17:28.253104Z",
     "start_time": "2022-05-08T09:17:28.233042Z"
    }
   },
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--model', type=str, default='gcn_vae', help=\"models used\")\n",
    "parser.add_argument('--seed', type=int, default=42, help='Random seed.')\n",
    "parser.add_argument('--epochs', type=int, default=200, help='Number of epochs to train.')\n",
    "parser.add_argument('--hidden1', type=int, default=32, help='Number of units in hidden layer 1.')\n",
    "parser.add_argument('--hidden2', type=int, default=16, help='Number of units in hidden layer 2.')\n",
    "parser.add_argument('--lr', type=float, default=0.01, help='Initial learning rate.')\n",
    "parser.add_argument('--dropout', type=float, default=0., help='Dropout rate (1 - keep probability).')\n",
    "parser.add_argument('--dataset-str', type=str, default='email', help='type of dataset.')\n",
    "\n",
    "args,_ = parser.parse_known_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b04fae95",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-08T09:22:00.262274Z",
     "start_time": "2022-05-08T09:22:00.250306Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_data(adj_name):\n",
    "    if adj_name == 'Cora':\n",
    "        nodes_numbers = 2708\n",
    "        datasets = Planetoid('./datasets', adj_name)\n",
    "        edges = datasets[0].edge_index\n",
    "        raw_edges = pd.DataFrame([[edges[0,i].item(), edges[1,i].item()] for i in range(edges.shape[1])])\n",
    "    elif adj_name == 'wiki':\n",
    "        nodes_numbers = 2405\n",
    "        raw_edges = pd.read_csv('datasets/graph.txt', header=None, sep='\\t')\n",
    "    elif adj_name == 'Citeseer':\n",
    "        nodes_numbers = 3327\n",
    "        datasets = Planetoid('./datasets', adj_name)\n",
    "        edges = datasets[0].edge_index\n",
    "        raw_edges = pd.DataFrame([[edges[0,i].item(), edges[1,i].item()] for i in range(edges.shape[1])])\n",
    "    elif adj_name == 'email':\n",
    "        nodes_numbers = 1133\n",
    "        raw_edges = pd.read_csv(\"datasets/ia-email-univ.mtx\",header=None,sep=' ') - 1\n",
    "    else:\n",
    "        print(\"Dataset is not exist!\")\n",
    "    \n",
    "    drop_self_loop = raw_edges[raw_edges[0]!=raw_edges[1]]\n",
    "    \n",
    "    graph_np = np.zeros((nodes_numbers, nodes_numbers))\n",
    "    \n",
    "    for i in range(drop_self_loop.shape[0]):\n",
    "        graph_np[drop_self_loop.iloc[i,0], drop_self_loop.iloc[i,1]]=1\n",
    "        graph_np[drop_self_loop.iloc[i,1], drop_self_loop.iloc[i,0]]=1\n",
    "    \n",
    "    adj = nx.adjacency_matrix(nx.from_numpy_matrix(graph_np))\n",
    "    \n",
    "    features = torch.eye(nodes_numbers)\n",
    "    \n",
    "    return adj, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7222c058",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-08T09:22:01.045637Z",
     "start_time": "2022-05-08T09:22:01.020897Z"
    }
   },
   "outputs": [],
   "source": [
    "def gae_for(args):\n",
    "    print(\"Using {} dataset\".format(args.dataset_str))\n",
    "    adj, features = load_data(args.dataset_str)\n",
    "    \n",
    "    n_nodes, feat_dim = features.shape\n",
    "\n",
    "    # Store original adjacency matrix (without diagonal entries) for later\n",
    "    adj_orig = adj\n",
    "    adj_orig = adj_orig - sp.dia_matrix((adj_orig.diagonal()[np.newaxis, :], [0]), shape=adj_orig.shape)\n",
    "    adj_orig.eliminate_zeros()\n",
    "\n",
    "    adj_train, train_edges, val_edges, val_edges_false, test_edges, test_edges_false = mask_test_edges(adj)\n",
    "    adj = adj_train\n",
    "\n",
    "    # Some preprocessing\n",
    "    adj_norm = preprocess_graph(adj)\n",
    "    adj_label = adj_train + sp.eye(adj_train.shape[0])\n",
    "    # adj_label = sparse_to_tuple(adj_label)\n",
    "    adj_label = torch.FloatTensor(adj_label.toarray())\n",
    "\n",
    "    pos_weight = torch.tensor(float(adj.shape[0] * adj.shape[0] - adj.sum()) / adj.sum())\n",
    "    norm = adj.shape[0] * adj.shape[0] / float((adj.shape[0] * adj.shape[0] - adj.sum()) * 2)\n",
    "\n",
    "    model = GCNModelVAE(feat_dim, args.hidden1, args.hidden2, args.dropout)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
    "\n",
    "    hidden_emb = None\n",
    "    for epoch in range(args.epochs):\n",
    "        t = time.time()\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        recovered, mu, logvar = model(features, adj_norm)\n",
    "        \n",
    "        loss = loss_function(preds=recovered, labels=adj_label,\n",
    "                             mu=mu, logvar=logvar, n_nodes=n_nodes,\n",
    "                             norm=norm, pos_weight=pos_weight)\n",
    "        loss.backward()\n",
    "        cur_loss = loss.item()\n",
    "        optimizer.step()\n",
    "\n",
    "        hidden_emb = mu.data.numpy()\n",
    "        roc_curr, ap_curr = get_roc_score(hidden_emb, adj_orig, val_edges, val_edges_false)\n",
    "\n",
    "        print(\"Epoch:\", '%04d' % (epoch + 1), \"train_loss=\", \"{:.5f}\".format(cur_loss),\n",
    "              \"val_ap=\", \"{:.5f}\".format(ap_curr),\n",
    "              \"time=\", \"{:.5f}\".format(time.time() - t)\n",
    "              )\n",
    "\n",
    "    print(\"Optimization Finished!\")\n",
    "\n",
    "    roc_score, ap_score = get_roc_score(hidden_emb, adj_orig, test_edges, test_edges_false)\n",
    "    print('Test ROC score: ' + str(roc_score))\n",
    "    print('Test AP score: ' + str(ap_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6840259a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-08T09:22:17.353080Z",
     "start_time": "2022-05-08T09:22:01.720918Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using soc dataset\n",
      "Epoch: 0001 train_loss= 1.72463 val_ap= 0.57052 time= 0.05286\n",
      "Epoch: 0002 train_loss= 1.68511 val_ap= 0.66478 time= 0.06113\n",
      "Epoch: 0003 train_loss= 1.68646 val_ap= 0.73518 time= 0.05784\n",
      "Epoch: 0004 train_loss= 1.71408 val_ap= 0.76006 time= 0.05585\n",
      "Epoch: 0005 train_loss= 1.67026 val_ap= 0.76865 time= 0.05086\n",
      "Epoch: 0006 train_loss= 1.62372 val_ap= 0.76952 time= 0.05884\n",
      "Epoch: 0007 train_loss= 1.56628 val_ap= 0.77000 time= 0.10572\n",
      "Epoch: 0008 train_loss= 1.53263 val_ap= 0.76914 time= 0.09375\n",
      "Epoch: 0009 train_loss= 1.47744 val_ap= 0.76835 time= 0.08777\n",
      "Epoch: 0010 train_loss= 1.42757 val_ap= 0.76736 time= 0.10172\n",
      "Epoch: 0011 train_loss= 1.39451 val_ap= 0.76580 time= 0.06084\n",
      "Epoch: 0012 train_loss= 1.30147 val_ap= 0.76415 time= 0.06283\n",
      "Epoch: 0013 train_loss= 1.26027 val_ap= 0.76227 time= 0.05633\n",
      "Epoch: 0014 train_loss= 1.18787 val_ap= 0.76096 time= 0.05606\n",
      "Epoch: 0015 train_loss= 1.12298 val_ap= 0.75992 time= 0.05503\n",
      "Epoch: 0016 train_loss= 1.06759 val_ap= 0.76043 time= 0.05658\n",
      "Epoch: 0017 train_loss= 1.02171 val_ap= 0.75998 time= 0.04859\n",
      "Epoch: 0018 train_loss= 0.97192 val_ap= 0.76029 time= 0.05878\n",
      "Epoch: 0019 train_loss= 0.93580 val_ap= 0.76134 time= 0.05567\n",
      "Epoch: 0020 train_loss= 0.89020 val_ap= 0.76204 time= 0.05361\n",
      "Epoch: 0021 train_loss= 0.84251 val_ap= 0.76324 time= 0.05353\n",
      "Epoch: 0022 train_loss= 0.81248 val_ap= 0.76448 time= 0.05465\n",
      "Epoch: 0023 train_loss= 0.78403 val_ap= 0.76626 time= 0.06066\n",
      "Epoch: 0024 train_loss= 0.76681 val_ap= 0.76852 time= 0.05474\n",
      "Epoch: 0025 train_loss= 0.74770 val_ap= 0.77057 time= 0.04950\n",
      "Epoch: 0026 train_loss= 0.74800 val_ap= 0.77218 time= 0.09966\n",
      "Epoch: 0027 train_loss= 0.72956 val_ap= 0.77313 time= 0.10151\n",
      "Epoch: 0028 train_loss= 0.71877 val_ap= 0.77308 time= 0.07986\n",
      "Epoch: 0029 train_loss= 0.71085 val_ap= 0.77181 time= 0.11013\n",
      "Epoch: 0030 train_loss= 0.70557 val_ap= 0.77167 time= 0.06976\n",
      "Epoch: 0031 train_loss= 0.70436 val_ap= 0.77145 time= 0.06205\n",
      "Epoch: 0032 train_loss= 0.69682 val_ap= 0.77165 time= 0.06500\n",
      "Epoch: 0033 train_loss= 0.69693 val_ap= 0.77209 time= 0.05386\n",
      "Epoch: 0034 train_loss= 0.68743 val_ap= 0.77347 time= 0.06084\n",
      "Epoch: 0035 train_loss= 0.68964 val_ap= 0.77468 time= 0.05685\n",
      "Epoch: 0036 train_loss= 0.68281 val_ap= 0.77513 time= 0.05386\n",
      "Epoch: 0037 train_loss= 0.68204 val_ap= 0.77586 time= 0.05585\n",
      "Epoch: 0038 train_loss= 0.67350 val_ap= 0.77548 time= 0.05522\n",
      "Epoch: 0039 train_loss= 0.67143 val_ap= 0.77359 time= 0.05485\n",
      "Epoch: 0040 train_loss= 0.66937 val_ap= 0.77212 time= 0.05386\n",
      "Epoch: 0041 train_loss= 0.66543 val_ap= 0.77079 time= 0.05086\n",
      "Epoch: 0042 train_loss= 0.66024 val_ap= 0.76903 time= 0.05253\n",
      "Epoch: 0043 train_loss= 0.65776 val_ap= 0.76806 time= 0.04987\n",
      "Epoch: 0044 train_loss= 0.65297 val_ap= 0.76492 time= 0.07121\n",
      "Epoch: 0045 train_loss= 0.65192 val_ap= 0.75908 time= 0.09424\n",
      "Epoch: 0046 train_loss= 0.64582 val_ap= 0.75290 time= 0.08684\n",
      "Epoch: 0047 train_loss= 0.64293 val_ap= 0.74428 time= 0.09233\n",
      "Epoch: 0048 train_loss= 0.64027 val_ap= 0.73801 time= 0.11655\n",
      "Epoch: 0049 train_loss= 0.63587 val_ap= 0.73505 time= 0.09588\n",
      "Epoch: 0050 train_loss= 0.63128 val_ap= 0.73251 time= 0.14143\n",
      "Epoch: 0051 train_loss= 0.62888 val_ap= 0.73136 time= 0.08333\n",
      "Epoch: 0052 train_loss= 0.62606 val_ap= 0.73112 time= 0.07269\n",
      "Epoch: 0053 train_loss= 0.62185 val_ap= 0.73124 time= 0.07882\n",
      "Epoch: 0054 train_loss= 0.62111 val_ap= 0.73213 time= 0.09021\n",
      "Epoch: 0055 train_loss= 0.61891 val_ap= 0.73465 time= 0.08519\n",
      "Epoch: 0056 train_loss= 0.61478 val_ap= 0.73767 time= 0.06477\n",
      "Epoch: 0057 train_loss= 0.61276 val_ap= 0.74115 time= 0.05799\n",
      "Epoch: 0058 train_loss= 0.60936 val_ap= 0.74450 time= 0.05932\n",
      "Epoch: 0059 train_loss= 0.60503 val_ap= 0.74931 time= 0.05764\n",
      "Epoch: 0060 train_loss= 0.60274 val_ap= 0.75263 time= 0.06005\n",
      "Epoch: 0061 train_loss= 0.59857 val_ap= 0.75662 time= 0.05485\n",
      "Epoch: 0062 train_loss= 0.59326 val_ap= 0.76006 time= 0.05585\n",
      "Epoch: 0063 train_loss= 0.58792 val_ap= 0.76805 time= 0.05585\n",
      "Epoch: 0064 train_loss= 0.58526 val_ap= 0.77798 time= 0.05286\n",
      "Epoch: 0065 train_loss= 0.58360 val_ap= 0.78539 time= 0.05485\n",
      "Epoch: 0066 train_loss= 0.57766 val_ap= 0.79338 time= 0.05485\n",
      "Epoch: 0067 train_loss= 0.57607 val_ap= 0.79922 time= 0.05485\n",
      "Epoch: 0068 train_loss= 0.57497 val_ap= 0.80091 time= 0.05286\n",
      "Epoch: 0069 train_loss= 0.57514 val_ap= 0.80022 time= 0.04887\n",
      "Epoch: 0070 train_loss= 0.57419 val_ap= 0.79800 time= 0.10173\n",
      "Epoch: 0071 train_loss= 0.57429 val_ap= 0.79534 time= 0.11070\n",
      "Epoch: 0072 train_loss= 0.57329 val_ap= 0.79504 time= 0.09076\n",
      "Epoch: 0073 train_loss= 0.57188 val_ap= 0.79928 time= 0.10671\n",
      "Epoch: 0074 train_loss= 0.56846 val_ap= 0.80538 time= 0.07337\n",
      "Epoch: 0075 train_loss= 0.56864 val_ap= 0.81191 time= 0.14705\n",
      "Epoch: 0076 train_loss= 0.56756 val_ap= 0.81451 time= 0.08820\n",
      "Epoch: 0077 train_loss= 0.56436 val_ap= 0.81487 time= 0.07944\n",
      "Epoch: 0078 train_loss= 0.56209 val_ap= 0.81392 time= 0.06065\n",
      "Epoch: 0079 train_loss= 0.56125 val_ap= 0.81353 time= 0.09698\n",
      "Epoch: 0080 train_loss= 0.56107 val_ap= 0.81632 time= 0.10427\n",
      "Epoch: 0081 train_loss= 0.55886 val_ap= 0.82169 time= 0.06568\n",
      "Epoch: 0082 train_loss= 0.55689 val_ap= 0.82738 time= 0.05600\n",
      "Epoch: 0083 train_loss= 0.55674 val_ap= 0.83247 time= 0.06108\n",
      "Epoch: 0084 train_loss= 0.55572 val_ap= 0.83429 time= 0.05501\n",
      "Epoch: 0085 train_loss= 0.55421 val_ap= 0.83582 time= 0.06195\n",
      "Epoch: 0086 train_loss= 0.55342 val_ap= 0.83595 time= 0.05501\n",
      "Epoch: 0087 train_loss= 0.55260 val_ap= 0.83582 time= 0.05349\n",
      "Epoch: 0088 train_loss= 0.55157 val_ap= 0.83756 time= 0.05458\n",
      "Epoch: 0089 train_loss= 0.54991 val_ap= 0.84132 time= 0.06383\n",
      "Epoch: 0090 train_loss= 0.54891 val_ap= 0.84621 time= 0.07281\n",
      "Epoch: 0091 train_loss= 0.54806 val_ap= 0.84960 time= 0.06511\n",
      "Epoch: 0092 train_loss= 0.54717 val_ap= 0.85144 time= 0.07234\n",
      "Epoch: 0093 train_loss= 0.54497 val_ap= 0.85013 time= 0.06855\n",
      "Epoch: 0094 train_loss= 0.54349 val_ap= 0.84978 time= 0.07484\n",
      "Epoch: 0095 train_loss= 0.54345 val_ap= 0.84951 time= 0.10971\n",
      "Epoch: 0096 train_loss= 0.54171 val_ap= 0.85222 time= 0.10871\n",
      "Epoch: 0097 train_loss= 0.54087 val_ap= 0.85572 time= 0.12587\n",
      "Epoch: 0098 train_loss= 0.53959 val_ap= 0.85915 time= 0.11068\n",
      "Epoch: 0099 train_loss= 0.53892 val_ap= 0.85903 time= 0.17689\n",
      "Epoch: 0100 train_loss= 0.53827 val_ap= 0.85733 time= 0.10664\n",
      "Epoch: 0101 train_loss= 0.53791 val_ap= 0.85451 time= 0.09642\n",
      "Epoch: 0102 train_loss= 0.53538 val_ap= 0.85308 time= 0.07686\n",
      "Epoch: 0103 train_loss= 0.53547 val_ap= 0.85336 time= 0.08796\n",
      "Epoch: 0104 train_loss= 0.53504 val_ap= 0.85582 time= 0.12990\n",
      "Epoch: 0105 train_loss= 0.53345 val_ap= 0.85907 time= 0.05630\n",
      "Epoch: 0106 train_loss= 0.53275 val_ap= 0.85909 time= 0.06263\n",
      "Epoch: 0107 train_loss= 0.53265 val_ap= 0.85774 time= 0.06266\n",
      "Epoch: 0108 train_loss= 0.53154 val_ap= 0.85628 time= 0.06469\n",
      "Epoch: 0109 train_loss= 0.53094 val_ap= 0.85345 time= 0.05434\n",
      "Epoch: 0110 train_loss= 0.53107 val_ap= 0.85325 time= 0.06068\n",
      "Epoch: 0111 train_loss= 0.53029 val_ap= 0.85406 time= 0.05765\n",
      "Epoch: 0112 train_loss= 0.52789 val_ap= 0.85693 time= 0.05286\n",
      "Epoch: 0113 train_loss= 0.52791 val_ap= 0.86072 time= 0.05485\n",
      "Epoch: 0114 train_loss= 0.52759 val_ap= 0.86332 time= 0.05485\n",
      "Epoch: 0115 train_loss= 0.52685 val_ap= 0.86289 time= 0.06882\n",
      "Epoch: 0116 train_loss= 0.52514 val_ap= 0.86207 time= 0.05685\n",
      "Epoch: 0117 train_loss= 0.52449 val_ap= 0.86142 time= 0.05386\n",
      "Epoch: 0118 train_loss= 0.52349 val_ap= 0.86115 time= 0.05386\n",
      "Epoch: 0119 train_loss= 0.52386 val_ap= 0.86253 time= 0.09175\n",
      "Epoch: 0120 train_loss= 0.52223 val_ap= 0.86356 time= 0.10871\n",
      "Epoch: 0121 train_loss= 0.52154 val_ap= 0.86513 time= 0.09574\n",
      "Epoch: 0122 train_loss= 0.51990 val_ap= 0.86590 time= 0.10001\n",
      "Epoch: 0123 train_loss= 0.51917 val_ap= 0.86614 time= 0.07877\n",
      "Epoch: 0124 train_loss= 0.51823 val_ap= 0.86625 time= 0.15690\n",
      "Epoch: 0125 train_loss= 0.51711 val_ap= 0.86514 time= 0.10073\n",
      "Epoch: 0126 train_loss= 0.51777 val_ap= 0.86422 time= 0.08988\n",
      "Epoch: 0127 train_loss= 0.51570 val_ap= 0.86440 time= 0.05989\n",
      "Epoch: 0128 train_loss= 0.51455 val_ap= 0.86532 time= 0.09850\n",
      "Epoch: 0129 train_loss= 0.51436 val_ap= 0.86678 time= 0.10371\n",
      "Epoch: 0130 train_loss= 0.51333 val_ap= 0.86703 time= 0.07017\n",
      "Epoch: 0131 train_loss= 0.51216 val_ap= 0.86572 time= 0.06290\n",
      "Epoch: 0132 train_loss= 0.51208 val_ap= 0.86446 time= 0.05768\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0133 train_loss= 0.51031 val_ap= 0.86342 time= 0.06765\n",
      "Epoch: 0134 train_loss= 0.50972 val_ap= 0.86425 time= 0.05965\n",
      "Epoch: 0135 train_loss= 0.50842 val_ap= 0.86489 time= 0.06004\n",
      "Epoch: 0136 train_loss= 0.50812 val_ap= 0.86511 time= 0.05969\n",
      "Epoch: 0137 train_loss= 0.50715 val_ap= 0.86585 time= 0.06164\n",
      "Epoch: 0138 train_loss= 0.50630 val_ap= 0.86585 time= 0.05606\n",
      "Epoch: 0139 train_loss= 0.50630 val_ap= 0.86661 time= 0.05596\n",
      "Epoch: 0140 train_loss= 0.50570 val_ap= 0.86702 time= 0.06371\n",
      "Epoch: 0141 train_loss= 0.50408 val_ap= 0.86748 time= 0.05758\n",
      "Epoch: 0142 train_loss= 0.50349 val_ap= 0.86752 time= 0.05102\n",
      "Epoch: 0143 train_loss= 0.50372 val_ap= 0.86765 time= 0.05801\n",
      "Epoch: 0144 train_loss= 0.50395 val_ap= 0.86848 time= 0.08178\n",
      "Epoch: 0145 train_loss= 0.50239 val_ap= 0.86926 time= 0.10083\n",
      "Epoch: 0146 train_loss= 0.50101 val_ap= 0.87013 time= 0.09133\n",
      "Epoch: 0147 train_loss= 0.50166 val_ap= 0.87122 time= 0.09110\n",
      "Epoch: 0148 train_loss= 0.50151 val_ap= 0.87200 time= 0.06846\n",
      "Epoch: 0149 train_loss= 0.50050 val_ap= 0.87237 time= 0.11177\n",
      "Epoch: 0150 train_loss= 0.49973 val_ap= 0.87187 time= 0.13786\n",
      "Epoch: 0151 train_loss= 0.49908 val_ap= 0.87286 time= 0.09167\n",
      "Epoch: 0152 train_loss= 0.49910 val_ap= 0.87274 time= 0.05747\n",
      "Epoch: 0153 train_loss= 0.49911 val_ap= 0.87293 time= 0.10049\n",
      "Epoch: 0154 train_loss= 0.49725 val_ap= 0.87336 time= 0.08380\n",
      "Epoch: 0155 train_loss= 0.49702 val_ap= 0.87411 time= 0.08936\n",
      "Epoch: 0156 train_loss= 0.49681 val_ap= 0.87443 time= 0.06366\n",
      "Epoch: 0157 train_loss= 0.49612 val_ap= 0.87443 time= 0.06572\n",
      "Epoch: 0158 train_loss= 0.49513 val_ap= 0.87473 time= 0.06163\n",
      "Epoch: 0159 train_loss= 0.49485 val_ap= 0.87523 time= 0.05773\n",
      "Epoch: 0160 train_loss= 0.49492 val_ap= 0.87632 time= 0.05849\n",
      "Epoch: 0161 train_loss= 0.49357 val_ap= 0.87711 time= 0.05641\n",
      "Epoch: 0162 train_loss= 0.49314 val_ap= 0.87719 time= 0.05342\n",
      "Epoch: 0163 train_loss= 0.49340 val_ap= 0.87769 time= 0.05485\n",
      "Epoch: 0164 train_loss= 0.49192 val_ap= 0.87877 time= 0.05386\n",
      "Epoch: 0165 train_loss= 0.49192 val_ap= 0.87928 time= 0.07281\n",
      "Epoch: 0166 train_loss= 0.49091 val_ap= 0.87936 time= 0.05785\n",
      "Epoch: 0167 train_loss= 0.49107 val_ap= 0.87971 time= 0.05286\n",
      "Epoch: 0168 train_loss= 0.49028 val_ap= 0.88018 time= 0.05785\n",
      "Epoch: 0169 train_loss= 0.48991 val_ap= 0.88171 time= 0.04987\n",
      "Epoch: 0170 train_loss= 0.48978 val_ap= 0.88357 time= 0.07879\n",
      "Epoch: 0171 train_loss= 0.48886 val_ap= 0.88421 time= 0.09475\n",
      "Epoch: 0172 train_loss= 0.48843 val_ap= 0.88465 time= 0.09475\n",
      "Epoch: 0173 train_loss= 0.48800 val_ap= 0.88514 time= 0.10073\n",
      "Epoch: 0174 train_loss= 0.48783 val_ap= 0.88442 time= 0.07879\n",
      "Epoch: 0175 train_loss= 0.48802 val_ap= 0.88419 time= 0.05984\n",
      "Epoch: 0176 train_loss= 0.48746 val_ap= 0.88491 time= 0.06084\n",
      "Epoch: 0177 train_loss= 0.48598 val_ap= 0.88642 time= 0.05785\n",
      "Epoch: 0178 train_loss= 0.48670 val_ap= 0.88767 time= 0.05585\n",
      "Epoch: 0179 train_loss= 0.48549 val_ap= 0.88792 time= 0.06044\n",
      "Epoch: 0180 train_loss= 0.48560 val_ap= 0.88804 time= 0.05671\n",
      "Epoch: 0181 train_loss= 0.48493 val_ap= 0.88813 time= 0.05532\n",
      "Epoch: 0182 train_loss= 0.48520 val_ap= 0.88819 time= 0.05470\n",
      "Epoch: 0183 train_loss= 0.48437 val_ap= 0.88882 time= 0.05463\n",
      "Epoch: 0184 train_loss= 0.48457 val_ap= 0.89063 time= 0.04739\n",
      "Epoch: 0185 train_loss= 0.48278 val_ap= 0.89091 time= 0.05660\n",
      "Epoch: 0186 train_loss= 0.48322 val_ap= 0.89157 time= 0.05466\n",
      "Epoch: 0187 train_loss= 0.48284 val_ap= 0.89143 time= 0.05434\n",
      "Epoch: 0188 train_loss= 0.48220 val_ap= 0.89100 time= 0.04968\n",
      "Epoch: 0189 train_loss= 0.48192 val_ap= 0.89144 time= 0.07904\n",
      "Epoch: 0190 train_loss= 0.48125 val_ap= 0.89223 time= 0.11149\n",
      "Epoch: 0191 train_loss= 0.48175 val_ap= 0.89316 time= 0.10429\n",
      "Epoch: 0192 train_loss= 0.48109 val_ap= 0.89330 time= 0.10635\n",
      "Epoch: 0193 train_loss= 0.48088 val_ap= 0.89336 time= 0.05848\n",
      "Epoch: 0194 train_loss= 0.47983 val_ap= 0.89359 time= 0.06478\n",
      "Epoch: 0195 train_loss= 0.47972 val_ap= 0.89428 time= 0.05492\n",
      "Epoch: 0196 train_loss= 0.48001 val_ap= 0.89417 time= 0.05136\n",
      "Epoch: 0197 train_loss= 0.47919 val_ap= 0.89408 time= 0.05546\n",
      "Epoch: 0198 train_loss= 0.47894 val_ap= 0.89402 time= 0.05400\n",
      "Epoch: 0199 train_loss= 0.47878 val_ap= 0.89450 time= 0.06022\n",
      "Epoch: 0200 train_loss= 0.47804 val_ap= 0.89517 time= 0.05457\n",
      "Optimization Finished!\n",
      "Test ROC score: 0.8828112111775104\n",
      "Test AP score: 0.9141479884083249\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    gae_for(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d2cdb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-env",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
