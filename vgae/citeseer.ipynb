{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8e2213fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-08T07:56:08.631240Z",
     "start_time": "2022-05-08T07:56:08.615278Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "import torch\n",
    "from torch import optim\n",
    "import networkx as nx\n",
    "from torch_geometric.datasets import Planetoid\n",
    "\n",
    "from gae.model import GCNModelVAE\n",
    "from gae.optimizer import loss_function\n",
    "from gae.utils import mask_test_edges, preprocess_graph, get_roc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7a0c03c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-08T07:56:09.133895Z",
     "start_time": "2022-05-08T07:56:09.114581Z"
    }
   },
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--model', type=str, default='gcn_vae', help=\"models used\")\n",
    "parser.add_argument('--seed', type=int, default=42, help='Random seed.')\n",
    "parser.add_argument('--epochs', type=int, default=200, help='Number of epochs to train.')\n",
    "parser.add_argument('--hidden1', type=int, default=32, help='Number of units in hidden layer 1.')\n",
    "parser.add_argument('--hidden2', type=int, default=16, help='Number of units in hidden layer 2.')\n",
    "parser.add_argument('--lr', type=float, default=0.01, help='Initial learning rate.')\n",
    "parser.add_argument('--dropout', type=float, default=0., help='Dropout rate (1 - keep probability).')\n",
    "parser.add_argument('--dataset-str', type=str, default='Citeseer', help='type of dataset.')\n",
    "\n",
    "args,_ = parser.parse_known_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "481b5867",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-08T07:56:09.773144Z",
     "start_time": "2022-05-08T07:56:09.759089Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_data(adj_name):\n",
    "    if adj_name == 'Cora':\n",
    "        nodes_numbers = 2708\n",
    "        datasets = Planetoid('./datasets', adj_name)\n",
    "        edges = datasets[0].edge_index\n",
    "        raw_edges = pd.DataFrame([[edges[0,i].item(), edges[1,i].item()] for i in range(edges.shape[1])])\n",
    "    elif adj_name == 'Citeseer':\n",
    "        nodes_numbers = 3327\n",
    "        datasets = Planetoid('./datasets', adj_name)\n",
    "        edges = datasets[0].edge_index\n",
    "        raw_edges = pd.DataFrame([[edges[0,i].item(), edges[1,i].item()] for i in range(edges.shape[1])])\n",
    "    elif adj_name == 'wiki':\n",
    "        nodes_numbers = 2405\n",
    "        raw_edges = pd.read_csv('datasets/graph.txt', header=None, sep='\\t')\n",
    "    else:\n",
    "        print(\"Dataset is not exist!\")\n",
    "    \n",
    "    drop_self_loop = raw_edges[raw_edges[0]!=raw_edges[1]]\n",
    "    \n",
    "    graph_np = np.zeros((nodes_numbers, nodes_numbers))\n",
    "    \n",
    "    for i in range(drop_self_loop.shape[0]):\n",
    "        graph_np[drop_self_loop.iloc[i,0], drop_self_loop.iloc[i,1]]=1\n",
    "        graph_np[drop_self_loop.iloc[i,1], drop_self_loop.iloc[i,0]]=1\n",
    "    \n",
    "    adj = nx.adjacency_matrix(nx.from_numpy_matrix(graph_np))\n",
    "    \n",
    "    features = torch.eye(nodes_numbers)\n",
    "    \n",
    "    return adj, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7222c058",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-08T07:56:10.463276Z",
     "start_time": "2022-05-08T07:56:10.443045Z"
    }
   },
   "outputs": [],
   "source": [
    "def gae_for(args):\n",
    "    print(\"Using {} dataset\".format(args.dataset_str))\n",
    "    adj, features = load_data(args.dataset_str)\n",
    "    \n",
    "    n_nodes, feat_dim = features.shape\n",
    "\n",
    "    # Store original adjacency matrix (without diagonal entries) for later\n",
    "    adj_orig = adj\n",
    "    adj_orig = adj_orig - sp.dia_matrix((adj_orig.diagonal()[np.newaxis, :], [0]), shape=adj_orig.shape)\n",
    "    adj_orig.eliminate_zeros()\n",
    "\n",
    "    adj_train, train_edges, val_edges, val_edges_false, test_edges, test_edges_false = mask_test_edges(adj)\n",
    "    adj = adj_train\n",
    "\n",
    "    # Some preprocessing\n",
    "    adj_norm = preprocess_graph(adj)\n",
    "    adj_label = adj_train + sp.eye(adj_train.shape[0])\n",
    "    # adj_label = sparse_to_tuple(adj_label)\n",
    "    adj_label = torch.FloatTensor(adj_label.toarray())\n",
    "\n",
    "    pos_weight = torch.tensor(float(adj.shape[0] * adj.shape[0] - adj.sum()) / adj.sum())\n",
    "    norm = adj.shape[0] * adj.shape[0] / float((adj.shape[0] * adj.shape[0] - adj.sum()) * 2)\n",
    "\n",
    "    model = GCNModelVAE(feat_dim, args.hidden1, args.hidden2, args.dropout)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
    "\n",
    "    hidden_emb = None\n",
    "    for epoch in range(args.epochs):\n",
    "        t = time.time()\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        recovered, mu, logvar = model(features, adj_norm)\n",
    "        \n",
    "        loss = loss_function(preds=recovered, labels=adj_label,\n",
    "                             mu=mu, logvar=logvar, n_nodes=n_nodes,\n",
    "                             norm=norm, pos_weight=pos_weight)\n",
    "        loss.backward()\n",
    "        cur_loss = loss.item()\n",
    "        optimizer.step()\n",
    "\n",
    "        hidden_emb = mu.data.numpy()\n",
    "        roc_curr, ap_curr = get_roc_score(hidden_emb, adj_orig, val_edges, val_edges_false)\n",
    "\n",
    "        print(\"Epoch:\", '%04d' % (epoch + 1), \"train_loss=\", \"{:.5f}\".format(cur_loss),\n",
    "              \"val_ap=\", \"{:.5f}\".format(ap_curr),\n",
    "              \"time=\", \"{:.5f}\".format(time.time() - t)\n",
    "              )\n",
    "\n",
    "    print(\"Optimization Finished!\")\n",
    "\n",
    "    roc_score, ap_score = get_roc_score(hidden_emb, adj_orig, test_edges, test_edges_false)\n",
    "    print('Test ROC score: ' + str(roc_score))\n",
    "    print('Test AP score: ' + str(ap_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6840259a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-08T07:57:35.612608Z",
     "start_time": "2022-05-08T07:56:11.053935Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Citeseer dataset\n",
      "Epoch: 0001 train_loss= 1.73496 val_ap= 0.54567 time= 0.30102\n",
      "Epoch: 0002 train_loss= 1.72790 val_ap= 0.57563 time= 0.31863\n",
      "Epoch: 0003 train_loss= 1.70738 val_ap= 0.61210 time= 0.44780\n",
      "Epoch: 0004 train_loss= 1.66278 val_ap= 0.65622 time= 0.59904\n",
      "Epoch: 0005 train_loss= 1.65923 val_ap= 0.67667 time= 0.45955\n",
      "Epoch: 0006 train_loss= 1.61362 val_ap= 0.68720 time= 0.31438\n",
      "Epoch: 0007 train_loss= 1.62774 val_ap= 0.69397 time= 0.33111\n",
      "Epoch: 0008 train_loss= 1.58066 val_ap= 0.69798 time= 0.43384\n",
      "Epoch: 0009 train_loss= 1.55686 val_ap= 0.69915 time= 0.57991\n",
      "Epoch: 0010 train_loss= 1.50854 val_ap= 0.70172 time= 0.46565\n",
      "Epoch: 0011 train_loss= 1.48676 val_ap= 0.70141 time= 0.32072\n",
      "Epoch: 0012 train_loss= 1.39649 val_ap= 0.69957 time= 0.33610\n",
      "Epoch: 0013 train_loss= 1.35461 val_ap= 0.69835 time= 0.35940\n",
      "Epoch: 0014 train_loss= 1.30349 val_ap= 0.69756 time= 0.46204\n",
      "Epoch: 0015 train_loss= 1.25709 val_ap= 0.69671 time= 0.34834\n",
      "Epoch: 0016 train_loss= 1.17117 val_ap= 0.69642 time= 0.29868\n",
      "Epoch: 0017 train_loss= 1.12827 val_ap= 0.69564 time= 0.42539\n",
      "Epoch: 0018 train_loss= 1.08239 val_ap= 0.69384 time= 0.41090\n",
      "Epoch: 0019 train_loss= 1.04849 val_ap= 0.69313 time= 0.30636\n",
      "Epoch: 0020 train_loss= 1.00049 val_ap= 0.69244 time= 0.31601\n",
      "Epoch: 0021 train_loss= 0.94318 val_ap= 0.69271 time= 0.43583\n",
      "Epoch: 0022 train_loss= 0.92757 val_ap= 0.69332 time= 0.42985\n",
      "Epoch: 0023 train_loss= 0.86705 val_ap= 0.69320 time= 0.32812\n",
      "Epoch: 0024 train_loss= 0.83949 val_ap= 0.69492 time= 0.34109\n",
      "Epoch: 0025 train_loss= 0.81328 val_ap= 0.69601 time= 0.43982\n",
      "Epoch: 0026 train_loss= 0.80084 val_ap= 0.69979 time= 0.43960\n",
      "Epoch: 0027 train_loss= 0.76088 val_ap= 0.70297 time= 0.31561\n",
      "Epoch: 0028 train_loss= 0.74639 val_ap= 0.70899 time= 0.30319\n",
      "Epoch: 0029 train_loss= 0.72750 val_ap= 0.71785 time= 0.47373\n",
      "Epoch: 0030 train_loss= 0.72200 val_ap= 0.72752 time= 0.39899\n",
      "Epoch: 0031 train_loss= 0.70156 val_ap= 0.73528 time= 0.32706\n",
      "Epoch: 0032 train_loss= 0.68472 val_ap= 0.74008 time= 0.33938\n",
      "Epoch: 0033 train_loss= 0.67214 val_ap= 0.74254 time= 0.58380\n",
      "Epoch: 0034 train_loss= 0.66114 val_ap= 0.74264 time= 0.55232\n",
      "Epoch: 0035 train_loss= 0.65213 val_ap= 0.74217 time= 0.38677\n",
      "Epoch: 0036 train_loss= 0.64363 val_ap= 0.74218 time= 0.30766\n",
      "Epoch: 0037 train_loss= 0.63686 val_ap= 0.74367 time= 0.37035\n",
      "Epoch: 0038 train_loss= 0.62557 val_ap= 0.74626 time= 0.53178\n",
      "Epoch: 0039 train_loss= 0.61290 val_ap= 0.75013 time= 0.55664\n",
      "Epoch: 0040 train_loss= 0.60089 val_ap= 0.75504 time= 0.36603\n",
      "Epoch: 0041 train_loss= 0.59215 val_ap= 0.75765 time= 0.32314\n",
      "Epoch: 0042 train_loss= 0.58284 val_ap= 0.75964 time= 0.38625\n",
      "Epoch: 0043 train_loss= 0.57664 val_ap= 0.75928 time= 0.55065\n",
      "Epoch: 0044 train_loss= 0.56737 val_ap= 0.75826 time= 0.53876\n",
      "Epoch: 0045 train_loss= 0.56190 val_ap= 0.75794 time= 0.35601\n",
      "Epoch: 0046 train_loss= 0.55750 val_ap= 0.75870 time= 0.32966\n",
      "Epoch: 0047 train_loss= 0.55030 val_ap= 0.76020 time= 0.39179\n",
      "Epoch: 0048 train_loss= 0.54599 val_ap= 0.76236 time= 0.59068\n",
      "Epoch: 0049 train_loss= 0.54276 val_ap= 0.76359 time= 0.52124\n",
      "Epoch: 0050 train_loss= 0.53581 val_ap= 0.76569 time= 0.38030\n",
      "Epoch: 0051 train_loss= 0.52902 val_ap= 0.76817 time= 0.33495\n",
      "Epoch: 0052 train_loss= 0.52378 val_ap= 0.77014 time= 0.41090\n",
      "Epoch: 0053 train_loss= 0.51869 val_ap= 0.77128 time= 0.57977\n",
      "Epoch: 0054 train_loss= 0.51198 val_ap= 0.77233 time= 0.51961\n",
      "Epoch: 0055 train_loss= 0.50702 val_ap= 0.77292 time= 0.38796\n",
      "Epoch: 0056 train_loss= 0.50312 val_ap= 0.77261 time= 0.31536\n",
      "Epoch: 0057 train_loss= 0.49942 val_ap= 0.77093 time= 0.37238\n",
      "Epoch: 0058 train_loss= 0.49752 val_ap= 0.76990 time= 0.52898\n",
      "Epoch: 0059 train_loss= 0.49347 val_ap= 0.76851 time= 0.34961\n",
      "Epoch: 0060 train_loss= 0.49195 val_ap= 0.76686 time= 0.36240\n",
      "Epoch: 0061 train_loss= 0.49013 val_ap= 0.76579 time= 0.43647\n",
      "Epoch: 0062 train_loss= 0.48806 val_ap= 0.76529 time= 0.43641\n",
      "Epoch: 0063 train_loss= 0.48701 val_ap= 0.76566 time= 0.33598\n",
      "Epoch: 0064 train_loss= 0.48353 val_ap= 0.76712 time= 0.34526\n",
      "Epoch: 0065 train_loss= 0.48057 val_ap= 0.76910 time= 0.47703\n",
      "Epoch: 0066 train_loss= 0.47839 val_ap= 0.77180 time= 0.41336\n",
      "Epoch: 0067 train_loss= 0.47641 val_ap= 0.77379 time= 0.29299\n",
      "Epoch: 0068 train_loss= 0.47362 val_ap= 0.77602 time= 0.32470\n",
      "Epoch: 0069 train_loss= 0.47272 val_ap= 0.77766 time= 0.49303\n",
      "Epoch: 0070 train_loss= 0.47068 val_ap= 0.77888 time= 0.34682\n",
      "Epoch: 0071 train_loss= 0.46855 val_ap= 0.78030 time= 0.31819\n",
      "Epoch: 0072 train_loss= 0.46679 val_ap= 0.78178 time= 0.35006\n",
      "Epoch: 0073 train_loss= 0.46521 val_ap= 0.78359 time= 0.51573\n",
      "Epoch: 0074 train_loss= 0.46454 val_ap= 0.78486 time= 0.32414\n",
      "Epoch: 0075 train_loss= 0.46314 val_ap= 0.78679 time= 0.31147\n",
      "Epoch: 0076 train_loss= 0.46183 val_ap= 0.78851 time= 0.44859\n",
      "Epoch: 0077 train_loss= 0.46119 val_ap= 0.78956 time= 0.57282\n",
      "Epoch: 0078 train_loss= 0.45981 val_ap= 0.78997 time= 0.46505\n",
      "Epoch: 0079 train_loss= 0.45938 val_ap= 0.79080 time= 0.32659\n",
      "Epoch: 0080 train_loss= 0.45735 val_ap= 0.79079 time= 0.34103\n",
      "Epoch: 0081 train_loss= 0.45690 val_ap= 0.79041 time= 0.39113\n",
      "Epoch: 0082 train_loss= 0.45618 val_ap= 0.79102 time= 0.59976\n",
      "Epoch: 0083 train_loss= 0.45518 val_ap= 0.79217 time= 0.47673\n",
      "Epoch: 0084 train_loss= 0.45496 val_ap= 0.79204 time= 0.32513\n",
      "Epoch: 0085 train_loss= 0.45420 val_ap= 0.79293 time= 0.33411\n",
      "Epoch: 0086 train_loss= 0.45259 val_ap= 0.79346 time= 0.32513\n",
      "Epoch: 0087 train_loss= 0.45187 val_ap= 0.79362 time= 0.57745\n",
      "Epoch: 0088 train_loss= 0.45130 val_ap= 0.79431 time= 0.50565\n",
      "Epoch: 0089 train_loss= 0.45072 val_ap= 0.79539 time= 0.44056\n",
      "Epoch: 0090 train_loss= 0.45033 val_ap= 0.79702 time= 0.32912\n",
      "Epoch: 0091 train_loss= 0.44903 val_ap= 0.79787 time= 0.31682\n",
      "Epoch: 0092 train_loss= 0.44881 val_ap= 0.79874 time= 0.48358\n",
      "Epoch: 0093 train_loss= 0.44843 val_ap= 0.79941 time= 0.58275\n",
      "Epoch: 0094 train_loss= 0.44766 val_ap= 0.80038 time= 0.46711\n",
      "Epoch: 0095 train_loss= 0.44686 val_ap= 0.80136 time= 0.31491\n",
      "Epoch: 0096 train_loss= 0.44683 val_ap= 0.80209 time= 0.34304\n",
      "Epoch: 0097 train_loss= 0.44542 val_ap= 0.80283 time= 0.45778\n",
      "Epoch: 0098 train_loss= 0.44597 val_ap= 0.80366 time= 0.56105\n",
      "Epoch: 0099 train_loss= 0.44471 val_ap= 0.80419 time= 0.46231\n",
      "Epoch: 0100 train_loss= 0.44435 val_ap= 0.80470 time= 0.32896\n",
      "Epoch: 0101 train_loss= 0.44404 val_ap= 0.80515 time= 0.32713\n",
      "Epoch: 0102 train_loss= 0.44353 val_ap= 0.80585 time= 0.35032\n",
      "Epoch: 0103 train_loss= 0.44322 val_ap= 0.80668 time= 0.50853\n",
      "Epoch: 0104 train_loss= 0.44272 val_ap= 0.80732 time= 0.34494\n",
      "Epoch: 0105 train_loss= 0.44234 val_ap= 0.80835 time= 0.32214\n",
      "Epoch: 0106 train_loss= 0.44160 val_ap= 0.80912 time= 0.42686\n",
      "Epoch: 0107 train_loss= 0.44170 val_ap= 0.80953 time= 0.44880\n",
      "Epoch: 0108 train_loss= 0.44078 val_ap= 0.80979 time= 0.32812\n",
      "Epoch: 0109 train_loss= 0.44060 val_ap= 0.81013 time= 0.31715\n",
      "Epoch: 0110 train_loss= 0.44017 val_ap= 0.81026 time= 0.46675\n",
      "Epoch: 0111 train_loss= 0.43977 val_ap= 0.81016 time= 0.42187\n",
      "Epoch: 0112 train_loss= 0.43978 val_ap= 0.81008 time= 0.33510\n",
      "Epoch: 0113 train_loss= 0.43948 val_ap= 0.81018 time= 0.32912\n",
      "Epoch: 0114 train_loss= 0.43896 val_ap= 0.81070 time= 0.47573\n",
      "Epoch: 0115 train_loss= 0.43871 val_ap= 0.81100 time= 0.40691\n",
      "Epoch: 0116 train_loss= 0.43878 val_ap= 0.81168 time= 0.32812\n",
      "Epoch: 0117 train_loss= 0.43803 val_ap= 0.81174 time= 0.33510\n",
      "Epoch: 0118 train_loss= 0.43783 val_ap= 0.81200 time= 0.49268\n",
      "Epoch: 0119 train_loss= 0.43728 val_ap= 0.81221 time= 0.38497\n",
      "Epoch: 0120 train_loss= 0.43704 val_ap= 0.81210 time= 0.34209\n",
      "Epoch: 0121 train_loss= 0.43703 val_ap= 0.81248 time= 0.37799\n",
      "Epoch: 0122 train_loss= 0.43631 val_ap= 0.81256 time= 0.54577\n",
      "Epoch: 0123 train_loss= 0.43623 val_ap= 0.81276 time= 0.53434\n",
      "Epoch: 0124 train_loss= 0.43593 val_ap= 0.81297 time= 0.39470\n",
      "Epoch: 0125 train_loss= 0.43582 val_ap= 0.81304 time= 0.33810\n",
      "Epoch: 0126 train_loss= 0.43556 val_ap= 0.81376 time= 0.38996\n",
      "Epoch: 0127 train_loss= 0.43521 val_ap= 0.81296 time= 0.58016\n",
      "Epoch: 0128 train_loss= 0.43531 val_ap= 0.81306 time= 0.47648\n",
      "Epoch: 0129 train_loss= 0.43463 val_ap= 0.81297 time= 0.35768\n",
      "Epoch: 0130 train_loss= 0.43434 val_ap= 0.81276 time= 0.33080\n",
      "Epoch: 0131 train_loss= 0.43424 val_ap= 0.81310 time= 0.37931\n",
      "Epoch: 0132 train_loss= 0.43396 val_ap= 0.81379 time= 0.54803\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0133 train_loss= 0.43401 val_ap= 0.81264 time= 0.49036\n",
      "Epoch: 0134 train_loss= 0.43377 val_ap= 0.81231 time= 0.37223\n",
      "Epoch: 0135 train_loss= 0.43309 val_ap= 0.81235 time= 0.31754\n",
      "Epoch: 0136 train_loss= 0.43312 val_ap= 0.81154 time= 0.41118\n",
      "Epoch: 0137 train_loss= 0.43255 val_ap= 0.81101 time= 0.55997\n",
      "Epoch: 0138 train_loss= 0.43244 val_ap= 0.81122 time= 0.50244\n",
      "Epoch: 0139 train_loss= 0.43239 val_ap= 0.81194 time= 0.37400\n",
      "Epoch: 0140 train_loss= 0.43227 val_ap= 0.81204 time= 0.31434\n",
      "Epoch: 0141 train_loss= 0.43207 val_ap= 0.81217 time= 0.36655\n",
      "Epoch: 0142 train_loss= 0.43191 val_ap= 0.81158 time= 0.54404\n",
      "Epoch: 0143 train_loss= 0.43167 val_ap= 0.81124 time= 0.53211\n",
      "Epoch: 0144 train_loss= 0.43141 val_ap= 0.81090 time= 0.39095\n",
      "Epoch: 0145 train_loss= 0.43121 val_ap= 0.81087 time= 0.31335\n",
      "Epoch: 0146 train_loss= 0.43129 val_ap= 0.81120 time= 0.33757\n",
      "Epoch: 0147 train_loss= 0.43094 val_ap= 0.81128 time= 0.46771\n",
      "Epoch: 0148 train_loss= 0.43070 val_ap= 0.81119 time= 0.37819\n",
      "Epoch: 0149 train_loss= 0.43062 val_ap= 0.81120 time= 0.32727\n",
      "Epoch: 0150 train_loss= 0.43043 val_ap= 0.81091 time= 0.34693\n",
      "Epoch: 0151 train_loss= 0.43034 val_ap= 0.81082 time= 0.50325\n",
      "Epoch: 0152 train_loss= 0.42993 val_ap= 0.81078 time= 0.31159\n",
      "Epoch: 0153 train_loss= 0.42970 val_ap= 0.81098 time= 0.31786\n",
      "Epoch: 0154 train_loss= 0.42955 val_ap= 0.81087 time= 0.36495\n",
      "Epoch: 0155 train_loss= 0.42959 val_ap= 0.81108 time= 0.49268\n",
      "Epoch: 0156 train_loss= 0.42946 val_ap= 0.81149 time= 0.31550\n",
      "Epoch: 0157 train_loss= 0.42921 val_ap= 0.81121 time= 0.33322\n",
      "Epoch: 0158 train_loss= 0.42901 val_ap= 0.81085 time= 0.43736\n",
      "Epoch: 0159 train_loss= 0.42892 val_ap= 0.81080 time= 0.43484\n",
      "Epoch: 0160 train_loss= 0.42886 val_ap= 0.80996 time= 0.32413\n",
      "Epoch: 0161 train_loss= 0.42869 val_ap= 0.80985 time= 0.33438\n",
      "Epoch: 0162 train_loss= 0.42870 val_ap= 0.80993 time= 0.48369\n",
      "Epoch: 0163 train_loss= 0.42831 val_ap= 0.81115 time= 0.43587\n",
      "Epoch: 0164 train_loss= 0.42828 val_ap= 0.81125 time= 0.31416\n",
      "Epoch: 0165 train_loss= 0.42795 val_ap= 0.81238 time= 0.33646\n",
      "Epoch: 0166 train_loss= 0.42786 val_ap= 0.81199 time= 0.48650\n",
      "Epoch: 0167 train_loss= 0.42770 val_ap= 0.81220 time= 0.54354\n",
      "Epoch: 0168 train_loss= 0.42755 val_ap= 0.81173 time= 0.50244\n",
      "Epoch: 0169 train_loss= 0.42746 val_ap= 0.81127 time= 0.35457\n",
      "Epoch: 0170 train_loss= 0.42726 val_ap= 0.81085 time= 0.34451\n",
      "Epoch: 0171 train_loss= 0.42747 val_ap= 0.81082 time= 0.52800\n",
      "Epoch: 0172 train_loss= 0.42709 val_ap= 0.81212 time= 0.58376\n",
      "Epoch: 0173 train_loss= 0.42691 val_ap= 0.81290 time= 0.48778\n",
      "Epoch: 0174 train_loss= 0.42707 val_ap= 0.81311 time= 0.34284\n",
      "Epoch: 0175 train_loss= 0.42661 val_ap= 0.81253 time= 0.32398\n",
      "Epoch: 0176 train_loss= 0.42664 val_ap= 0.81197 time= 0.49967\n",
      "Epoch: 0177 train_loss= 0.42669 val_ap= 0.81191 time= 0.64358\n",
      "Epoch: 0178 train_loss= 0.42631 val_ap= 0.81204 time= 0.48118\n",
      "Epoch: 0179 train_loss= 0.42641 val_ap= 0.81260 time= 0.34070\n",
      "Epoch: 0180 train_loss= 0.42611 val_ap= 0.81326 time= 0.35776\n",
      "Epoch: 0181 train_loss= 0.42627 val_ap= 0.81326 time= 0.40986\n",
      "Epoch: 0182 train_loss= 0.42582 val_ap= 0.81321 time= 0.63893\n",
      "Epoch: 0183 train_loss= 0.42599 val_ap= 0.81412 time= 0.51256\n",
      "Epoch: 0184 train_loss= 0.42586 val_ap= 0.81425 time= 0.33927\n",
      "Epoch: 0185 train_loss= 0.42572 val_ap= 0.81409 time= 0.37015\n",
      "Epoch: 0186 train_loss= 0.42557 val_ap= 0.81415 time= 0.44795\n",
      "Epoch: 0187 train_loss= 0.42524 val_ap= 0.81321 time= 0.60373\n",
      "Epoch: 0188 train_loss= 0.42540 val_ap= 0.81337 time= 0.46158\n",
      "Epoch: 0189 train_loss= 0.42493 val_ap= 0.81331 time= 0.39196\n",
      "Epoch: 0190 train_loss= 0.42509 val_ap= 0.81406 time= 0.38222\n",
      "Epoch: 0191 train_loss= 0.42508 val_ap= 0.81419 time= 0.43947\n",
      "Epoch: 0192 train_loss= 0.42502 val_ap= 0.81431 time= 0.42250\n",
      "Epoch: 0193 train_loss= 0.42487 val_ap= 0.81427 time= 0.35503\n",
      "Epoch: 0194 train_loss= 0.42491 val_ap= 0.81431 time= 0.38099\n",
      "Epoch: 0195 train_loss= 0.42447 val_ap= 0.81414 time= 0.48097\n",
      "Epoch: 0196 train_loss= 0.42443 val_ap= 0.81418 time= 0.46331\n",
      "Epoch: 0197 train_loss= 0.42464 val_ap= 0.81420 time= 0.36294\n",
      "Epoch: 0198 train_loss= 0.42449 val_ap= 0.81460 time= 0.40189\n",
      "Epoch: 0199 train_loss= 0.42431 val_ap= 0.81460 time= 0.47122\n",
      "Epoch: 0200 train_loss= 0.42422 val_ap= 0.81462 time= 0.32183\n",
      "Optimization Finished!\n",
      "Test ROC score: 0.7653423499577345\n",
      "Test AP score: 0.8273144028288274\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    gae_for(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc7889a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-env",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
